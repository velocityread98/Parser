{
  "source_file": "/content/drive/MyDrive/percolation_studies.pdf",
  "total_pages": 221,
  "pages": [
    {
      "page_number": 1,
      "elements": [
        {
          "label": "para",
          "bbox": [
            80,
            26,
            270,
            53
          ],
          "text": "Lecture Notes in Physics",
          "reading_order": 0
        },
        {
          "label": "para",
          "bbox": [
            79,
            214,
            377,
            242
          ],
          "text": "Anders Malthe-Sørenssen",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            291,
            564,
            601
          ],
          "text": "Percolation\nTheory Using",
          "reading_order": 2
        },
        {
          "label": "foot",
          "bbox": [
            80,
            815,
            206,
            833
          ],
          "text": "OPEN ACCESS",
          "reading_order": 3
        },
        {
          "label": "foot",
          "bbox": [
            383,
            804,
            530,
            844
          ],
          "text": "2 Springer",
          "reading_order": 4
        }
      ]
    },
    {
      "page_number": 2,
      "elements": [
        {
          "label": "title",
          "bbox": [
            72,
            98,
            331,
            125
          ],
          "text": "Lecture Notes in Physics",
          "reading_order": 0
        },
        {
          "label": "sec",
          "bbox": [
            72,
            133,
            173,
            146
          ],
          "text": "Founding Editors",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            152,
            157,
            170
          ],
          "text": "Wolf Beiglböck",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            170,
            145,
            188
          ],
          "text": "Jürgen Ehlers",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            195,
            136,
            208
          ],
          "text": "Klaus Hepp",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            215,
            215,
            225
          ],
          "text": "Hans-Arwed Weidenmüller",
          "reading_order": 5
        },
        {
          "label": "sec",
          "bbox": [
            72,
            258,
            189,
            277
          ],
          "text": "Volume 1029",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            322,
            152,
            340
          ],
          "text": "Series Editors",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            349,
            224,
            359
          ],
          "text": "Roberta Citro, Salerno, Italy",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            72,
            367,
            260,
            385
          ],
          "text": "Peter Hänggi, Augsburg, Germany",
          "reading_order": 9
        },
        {
          "label": "para",
          "bbox": [
            72,
            385,
            233,
            403
          ],
          "text": "Betti Hartmann, London, UK",
          "reading_order": 10
        },
        {
          "label": "para",
          "bbox": [
            72,
            410,
            271,
            423
          ],
          "text": "Morten Hjorth-Jensen, Oslo, Norway",
          "reading_order": 11
        },
        {
          "label": "para",
          "bbox": [
            72,
            430,
            272,
            443
          ],
          "text": "Maciej Lewenstein, Barcelona, Spain",
          "reading_order": 12
        },
        {
          "label": "para",
          "bbox": [
            72,
            448,
            260,
            465
          ],
          "text": "Satya N. Majumdar, Orsay, France",
          "reading_order": 13
        },
        {
          "label": "para",
          "bbox": [
            72,
            465,
            331,
            484
          ],
          "text": "Luciano Rezzolla, Frankfurt am Main, Germany",
          "reading_order": 14
        },
        {
          "label": "para",
          "bbox": [
            72,
            491,
            254,
            504
          ],
          "text": "Angel Rubio, Hamburg, Germany",
          "reading_order": 15
        },
        {
          "label": "para",
          "bbox": [
            72,
            510,
            260,
            524
          ],
          "text": "Wolfgang Schleich, Ulm, Germany",
          "reading_order": 16
        },
        {
          "label": "para",
          "bbox": [
            72,
            528,
            261,
            546
          ],
          "text": "Stefan Theisen, Potsdam, Germany",
          "reading_order": 17
        },
        {
          "label": "para",
          "bbox": [
            72,
            546,
            260,
            564
          ],
          "text": "James Wells, Ann Arbor, MI, USA",
          "reading_order": 18
        },
        {
          "label": "para",
          "bbox": [
            72,
            572,
            233,
            582
          ],
          "text": "Gary P. Zank, Huntsville, USA",
          "reading_order": 19
        }
      ]
    },
    {
      "page_number": 3,
      "elements": [
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            179
          ],
          "text": "The series Lecture Notes in Physics (LNP), founded in 1969, reports new develop-\nments in physics research and teaching - quickly and informally, but with a high\nquality and the explicit aim to summarize and communicate current knowledge in\nan accessible way. Books published in this series are conceived as bridging material\nbetween advanced graduate textbooks and the forefront of research and to serve\nthree purposes:",
          "reading_order": 0
        },
        {
          "label": "list",
          "bbox": [
            88,
            196,
            520,
            225
          ],
          "text": "to be a compact and modern up-to-date source of reference on a well-defined\ntopic;",
          "reading_order": 1
        },
        {
          "label": "list",
          "bbox": [
            88,
            225,
            520,
            259
          ],
          "text": "to serve as an accessible introduction to the field to postgraduate students and\nnon-specialist researchers from related areas;",
          "reading_order": 2
        },
        {
          "label": "list",
          "bbox": [
            88,
            259,
            512,
            287
          ],
          "text": "to be a source of advanced teaching material for specialized seminars, course\nand schools.",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            304,
            520,
            354
          ],
          "text": "Both monographs and multi-author volumes will be considered for publication.\nEdited volumes should however consist of a very limited number of contributions\nonly. Proceedings will not be considered for LNP.",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            357,
            520,
            421
          ],
          "text": "Volumes published in LNP are disseminated both in print and in electronic for-\nmats, the electronic archive being available at springerlink.com. The series content\nis indexed, abstracted and referenced by many abstracting and information services,\nbibliographic networks, subscription agencies, library networks, and consortia.",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            421,
            512,
            451
          ],
          "text": "Proposals should be sent to a member of the Editorial Board, or directly to the\nresponsible editor at Springer:",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            465,
            161,
            483
          ],
          "text": "Dr Lisa Scalone",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            483,
            251,
            501
          ],
          "text": "lisa.scalone@springernature.com",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 4,
      "elements": [
        {
          "label": "para",
          "bbox": [
            72,
            98,
            331,
            125
          ],
          "text": "Anders Malthe-Sørenssen",
          "reading_order": 0
        },
        {
          "label": "para",
          "bbox": [
            72,
            215,
            493,
            297
          ],
          "text": "Percolation Theory Using\nPython",
          "reading_order": 1
        },
        {
          "label": "foot",
          "bbox": [
            107,
            770,
            218,
            806
          ],
          "text": "Springer",
          "reading_order": 2
        }
      ]
    },
    {
      "page_number": 5,
      "elements": [
        {
          "label": "para",
          "bbox": [
            72,
            80,
            197,
            93
          ],
          "text": "Anders Malthe-Sørenssen",
          "reading_order": 0
        },
        {
          "label": "para",
          "bbox": [
            72,
            98,
            109,
            107
          ],
          "text": "Physics",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            107,
            278,
            134
          ],
          "text": "University of Oslo - Center for Computing\nin Science Education",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            134,
            134,
            152
          ],
          "text": "Oslo, Norwa",
          "reading_order": 3
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_005_figure_004.png)",
          "figure_path": "figures/percolation_studies_page_005_figure_004.png",
          "bbox": [
            72,
            410,
            152,
            439
          ],
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            465,
            153,
            474
          ],
          "text": "ISSN 0075-8450",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            242,
            465,
            394,
            475
          ],
          "text": "ISSN 1616-6361 (electronic)",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            474,
            197,
            492
          ],
          "text": "Lecture Notes in Physics",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            492,
            197,
            501
          ],
          "text": "ISBN 978-3-031-59899-9",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            242,
            492,
            422,
            501
          ],
          "text": "ISBN 978-3-031-59900-2 (eBook)",
          "reading_order": 9
        },
        {
          "label": "para",
          "bbox": [
            72,
            501,
            287,
            519
          ],
          "text": "https://doi.org/10.1007/978-3-031-59900-2",
          "reading_order": 10
        },
        {
          "label": "para",
          "bbox": [
            72,
            528,
            485,
            541
          ],
          "text": "© The Editor(s) (if applicable) and The Author(s) 2024. This book is an open access publication",
          "reading_order": 11
        },
        {
          "label": "para",
          "bbox": [
            72,
            543,
            520,
            600
          ],
          "text": "Open Access This book is licensed under the terms of the Creative Commons Attribution 4.0 Inter-\nnational License ( http://creativecommons.org/licenses/by/4.0/ ), which permits use, sharing, adaptation,\ndistribution and reproduction in any medium or format, as long as you give appropriate credit to the\noriginal author(s) and the source, provide a link to the Creative Commons license and indicate if changes\nwere made.",
          "reading_order": 12
        },
        {
          "label": "para",
          "bbox": [
            72,
            600,
            520,
            649
          ],
          "text": "The images or other third party material in this book are included in the book’s Creative Commons\nlicense, unless indicated otherwise in a credit line to the material. If material is not included in the book’s\nCreative Commons license and your intended use is not permitted by statutory regulation or exceeds the\npermitted use, you will need to obtain permission directly from the copyright holder.",
          "reading_order": 13
        },
        {
          "label": "para",
          "bbox": [
            72,
            651,
            520,
            696
          ],
          "text": "The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication\ndoes not imply, even in the absence of a specific statement, that such names are exempt from the relevant\nprotective laws and regulations and therefore free for general use.\nThe publisher, the authors and the editors are safe to assume that the advice and information in this book",
          "reading_order": 14
        },
        {
          "label": "para",
          "bbox": [
            72,
            696,
            520,
            746
          ],
          "text": "are believed to be true and accurate at the date of publication. Neither the publisher nor the authors or\nthe editors give a warranty, expressed or implied, with respect to the material contained herein or for any\nerrors or omissions that may have been made. The publisher remains neutral with regard to jurisdictional\nclaims in published maps and institutional affiliations.",
          "reading_order": 15
        },
        {
          "label": "para",
          "bbox": [
            72,
            760,
            475,
            782
          ],
          "text": "This Springer imprint is published by the registered company Springer Nature Switzerland AG\nThe registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland",
          "reading_order": 16
        },
        {
          "label": "para",
          "bbox": [
            72,
            796,
            296,
            806
          ],
          "text": "If disposing of this product, please recycle the paper",
          "reading_order": 17
        }
      ]
    },
    {
      "page_number": 6,
      "elements": [
        {
          "label": "sec",
          "bbox": [
            72,
            98,
            143,
            116
          ],
          "text": "Preface",
          "reading_order": 0
        },
        {
          "label": "para",
          "bbox": [
            72,
            259,
            520,
            340
          ],
          "text": "This textbook was developed for the course Fys4460 Disordered media and\npercolation theory. The course was developed in 2004 and taught every year since at\nthe University of Oslo. The original idea of the course was to provide an introduction\nto basic aspects of scaling theory to a cross-disciplinary group of students. Both\ngeoscience and physics students have successfully taken the course.",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            340,
            520,
            465
          ],
          "text": "This book follows the underlying philosophy that learning a subject is a hands-\non activity that requires student activities. The course that used the book was\nproject driven. The students solved a set of extensive computational and theoretical\nexercises and were supported by lectures that provided the theoretical background\nand group sessions with a learning assistant. The exercises used in the course have\nbeen woven into the text, but are also given as a long project description in an\nappendix. This textbook provides much of the same information that was provided\nin the lectures.",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            465,
            520,
            663
          ],
          "text": "I believe that in order to learn a subject such as scaling, the student needs to gain\nhands-on experience with real data. The student should learn to generate, analyze\nand understand data and models. The focus is not to generate perfect data. Instead,\nwe aim to teach the student how to make sense of imperfect data. The data presented\nin the book and the data that students may generate using the supplied programs are\ntherefore not from very long simulations, but instead from simulations that take a\nfew minutes on an ordinary computer. The experience from this course has been\nthat students learn most effectively by being guided through the process of building\nmodels and generating data. Some details of the computer programs have therefore\nbeen provided in the text, and we strive to use a similar notation in the computer\ncode and in the mathematics in order to make the transfer from mathematics to\ncomputational modeling as simple as possible.",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            663,
            520,
            761
          ],
          "text": "Another aspect of the book is that it tries to be complete in exposition and worked\nexamples. Not only are the theoretical arguments carried out in detail. The computer\ncodes needed to generate data are provided in such a form that they can be run and\ncan generate the data in the examples. This provides students with a complete set of\nworked examples that contain theory, modeling (the transfer from theory to model),\nimplementation, analysis and the resulting connection between theory and analysis.",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            761,
            520,
            806
          ],
          "text": "In the full course, this textbook was only one half of the curriculum. For\nthe first 10 years the first part of the course focused on random walks and the\nlast part focused on random growth processes. For the second 10 years of the",
          "reading_order": 5
        },
        {
          "label": "foot",
          "bbox": [
            511,
            824,
            520,
            842
          ],
          "text": "v",
          "reading_order": 6
        }
      ]
    },
    {
      "page_number": 7,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            80,
            58
          ],
          "text": "vi",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            484,
            44,
            512,
            58
          ],
          "text": "Prefac",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            224
          ],
          "text": "course, the course switched to be a course on cross-scale modeling of porous\nmedia. The first half of the course focused on molecular dynamics modeling of\nhomogeneous systems in order to build an understanding of concepts from statistical\nphysics from computational examples. The second part of the course used molecular\ndynamics simulations to model nanoscale porous media with focus on fluid transport\n(diffusion) and fluid flow in a nanoporous system and elastic properties of the porous\nmatrix. Percolation theory was then introduced as a method to upscale the nanoscale\nsystems, and we measured correlation functions, flow and diffusion problems across\nscales.",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            224,
            520,
            306
          ],
          "text": "The course on percolation theory which formed the basis for this textbook was\ninspired by a course given by Amnon Aharony on random systems several times in\nthe 1990s. This course was a great inspiration for all students and faculty and the\ncourse served as an inspiration for this course and for this text. Thank you for your\ngreat inspiration Amnon.",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            306,
            520,
            432
          ],
          "text": "This book is written as a practical textbook introduction to the field of percolation\ntheory with particular emphasis on containing all the computational methods needed\nto study percolation theory. Thus, we have included computer code where it is\nneeded. The textbook does not aim to provide a complete set of references to\npercolation theory. Instead, only a few key references are included for students who\nwant to explore more. There are many other good texts and reviews that provide a\ndetailed set of references and a more historical description of the development of\nthe field.",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            438,
            520,
            582
          ],
          "text": "This textbook is the result of the contributions from many students in the course.\nOriginally, the textbook was written with examples in matlab. However, as Python\ngradually have developed into the tool of choice for scientific computing, also the\ncode in this course was updated. This was first done by Svenn-Arne Dragly, and\nsome of the translations from matlab to Python was originally done by him. Later\ncontributions from, e.g., Ø yvind Sch ø yen on the translation of matlab to Python\ncode for diffusion are also acknowledged. Thank you to all the students who have\ncontributed in this course. It has been great fun to teach it because of your input and\ninspiration. I am greatly indebted to you!",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            582,
            520,
            743
          ],
          "text": "Thank you also to my mentors Jens Feder, Torstein J ø ssang and Bj ø rn Jamtveit\nwho built up a cross-disciplinary research environment between physics, computer\nscience and geoscience — the Center for the Physics of Geological Processes. You\nhave always supported my work and inspired me to be a better researcher and a\nbetter teacher. Also thank you to my mentor in teaching, textbooks and computing,\nthe late Hans Petter Langtangen. Without you, this book would never have been\nrealized. Your vision, voice and spirit live on in us who worked with you. And\nthank you to my colleague Morten Hjorth-Jensen who has built up the group in\ncomputational physics at the University of Oslo, who generously included me in\nthis group, and who has by example inspired me to be a better teacher.",
          "reading_order": 6
        }
      ]
    },
    {
      "page_number": 8,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            107,
            58
          ],
          "text": "Preface",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            511,
            44,
            520,
            58
          ],
          "text": "vii",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            128
          ],
          "text": "This textbook was written using doconce—a document translation and format-\nting tool that allows simple integration of text, mathematics and computer code\ndeveloped by Hans Petter Langtangen.",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            143,
            147,
            161
          ],
          "text": "Oslo, Norway",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            376,
            143,
            520,
            161
          ],
          "text": "Anders Malthe-Sørenssen",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            161,
            152,
            179
          ],
          "text": "February 2024",
          "reading_order": 5
        }
      ]
    },
    {
      "page_number": 9,
      "elements": [
        {
          "label": "tab",
          "bbox": [
            72,
            98,
            528,
            788
          ],
          "text": "<table><tr><td>1</td><td>Introduction to Percolation ….. 1</td></tr><tr><td>1.1 Basic Concepts in Percolation ….. 5</td><td>5</td></tr><tr><td>1.2 Percolation Probability ….. 8</td><td>8</td></tr><tr><td>1.3 Spanning Cluster ….. 10</td><td>10</td></tr><tr><td>1.4 Percolation in Small Systems ….. 12</td><td>12</td></tr><tr><td>1.5 Further Reading ….. 15</td><td>15</td></tr><tr><td>2</td><td>One-Dimensional Percolation ….. 17</td><td>17</td></tr><tr><td>2.1 Percolation Probability ….. 18</td><td>18</td></tr><tr><td>2.2 Cluster Number Density ….. 28</td><td>28</td></tr><tr><td>2.3 Spanning Cluster ….. 29</td><td>29</td></tr><tr><td>2.4 Correlation Length ….. 26</td><td>33</td></tr><tr><td>3</td><td>Infinite-Dimensional Percolation ….. 33</td><td>33</td></tr><tr><td>3.1 Percolation Threshold ….. 34</td><td>34</td></tr><tr><td>3.2 Spanning Cluster ….. 35</td><td>38</td></tr><tr><td>3.3 Average Cluster Size ….. 36</td><td>38</td></tr><tr><td>3.4 Cluster Number Density ….. 37</td><td>39</td></tr><tr><td>4</td><td>Finite-Dimensional Percolation ….. 40</td><td>41</td></tr><tr><td>4.1 Cluster Number Density ….. 41</td><td>42</td></tr><tr><td>4.2 Consequences of the Scaling Ansatz ….. 42</td><td>43</td></tr><tr><td>4.3 Percolation Thresholds ….. 43</td><td>44</td></tr><tr><td>5</td><td>Geometry of Clusters ….. 45</td><td>46</td></tr><tr><td>5.1 Geometry of Finite Clusters ….. 46</td><td>47</td></tr><tr><td>5.2 Characteristic Cluster Size ….. 47</td><td>48</td></tr><tr><td>5.3 Geometry of the Spanning Cluster ….. 48</td><td>49</td></tr><tr><td>5.4 Spanning Cluster Above p c ….. 49</td><td>41</td></tr></table>",
          "reading_order": 0
        },
        {
          "label": "foot",
          "bbox": [
            510,
            824,
            520,
            842
          ],
          "text": "ix",
          "reading_order": 1
        }
      ]
    },
    {
      "page_number": 10,
      "elements": [
        {
          "label": "tab",
          "bbox": [
            72,
            80,
            528,
            609
          ],
          "text": "<table><tr><td>Renormalization</td><td>101</td></tr><tr><td>7.1 The Renormalization Mapping</td><td>102</td></tr><tr><td>7.2 Examples ....................................................... 108</td><td>108</td></tr><tr><td>8 Subset Geometry .......................................................... 119</td><td>119</td></tr><tr><td>8.1 Singly Connected Bonds ..................................................... 119</td><td>119</td></tr><tr><td>8.2 Self-Avoiding Paths on the Cluster ....................................... 121</td><td>121</td></tr><tr><td>8.3 Renormalization Calculation ....................................... 125</td><td>125</td></tr><tr><td>8.4 Deterministic Fractal Models ....................................... 126</td><td>126</td></tr><tr><td>8.5 Lacunarity ....................................................... 128</td><td>128</td></tr><tr><td>Flow in Disordered Media ....................................... 135</td><td>135</td></tr><tr><td>9.1 Introduction to Disorder ....................................... 135</td><td>135</td></tr><tr><td>9.2 Conductivity and Permeability ....................................... 136</td><td>136</td></tr><tr><td>9.3 Conductance of a Percolation Lattice ....................................... 138</td><td>138</td></tr><tr><td>9.4 Scaling Arguments for Conductance and Conductivity ....................... 147</td><td>147</td></tr><tr><td>9.5 Renormalization Calculation ....................................... 151</td><td>151</td></tr><tr><td>9.6 Finite Size Scaling ....................................... 152</td><td>152</td></tr><tr><td>9.7 Internal Distribution of Currents ....................................... 155</td><td>155</td></tr><tr><td>9.8 Real Conductivity ....................................... 158</td><td>158</td></tr><tr><td>Elastic Properties of Disordered Media ....................................... 163</td><td>163</td></tr><tr><td>10.1 Rigidity Percolation ....................................... 163</td><td>163</td></tr><tr><td>Diffusion in Disordered Media ....................................... 171</td><td>171</td></tr><tr><td>11.1 Diffusion and Random Walks in Homogeneous Media ....................... 171</td><td>171</td></tr><tr><td>11.2 Random Walks on Clusters ....................................... 175</td><td>175</td></tr><tr><td>Dynamic Processes in Disordered Media ....................... 195</td><td>195</td></tr><tr><td>12.1 Introduction ....................................... 195</td><td>195</td></tr><tr><td>12.2 Diffusion Fronts ....................................... 196</td><td>196</td></tr><tr><td>12.3 Invasion Percolation ....................................... 198</td><td>198</td></tr><tr><td>References ....................................................... 209</td><td>209</td></tr><tr><td>Index ....................................................... 211</td><td>209</td></tr></table>",
          "reading_order": 0
        },
        {
          "label": "cap",
          "bbox": [
            72,
            44,
            80,
            62
          ],
          "text": "x",
          "reading_order": 1
        }
      ]
    },
    {
      "page_number": 11,
      "elements": [
        {
          "label": "sec",
          "bbox": [
            72,
            98,
            331,
            116
          ],
          "text": "Introduction to Percolation",
          "reading_order": 0
        },
        {
          "label": "para",
          "bbox": [
            528,
            98,
            546,
            134
          ],
          "text": "1",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            304,
            520,
            403
          ],
          "text": "In this chapter we motivate the study of disordered media through the example of\na porous system. The basic terms in percolation theory are introduced, and you\nlearn how to generate, visualize and measure on percolation systems in Python.\nWe demonstrate how to find exact results for small systems in two dimensions by\naddressing all configurations of the system, and show that this approach becomes\nunfeasible for large system sizes.",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            403,
            520,
            548
          ],
          "text": "Percolation is the study of connectivity of random media and of other properties\nof connected subsets of random media [ 8 , 30 , 37 ] . Figure 1.1 illustrates a porous\nmaterial—a material with holes, pores, of various sizes. This is an example of a\nrandom material with built-in disorder. In this book, we will address the physical\nproperties of such media, develop the underlying mathematical theory and the\ncomputational and statistical methods needed to discuss the physical properties of\nrandom media. In order to do that, we will develop a simplified model system,\na model porous medium, for which we can develop a well-founded mathematical\ntheory, and then afterwards we can apply this model to realistic random systems.",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            564,
            520,
            761
          ],
          "text": "A Porous Medium as a Model of a Disordered Material The porous medium\nillustrated in the figure serves as a useful, fundamental model for random media\nin general. What characterizes the porous material in Fig. 1.1 ? The porous material\nconsists of regions with and without material. It is therefore an extreme, binary\nversion of a random medium. An actual physical porous material will be generated\nby some physical process, which will affect the properties of the porous medium\nin some way. For example, if the material is generated by sedimentary deposition,\ndetails of the deposition process may affect the shape and connectivity of the pores,\nor later fracturing may generate straight, open cracks in addition to more round\npores. These features are always present in the complex geometries found in nature,\nand they will generate correlations in the randomness of the material. While these\ncorrelations can be addressed in detailed, specific studies of random materials, we",
          "reading_order": 4
        },
        {
          "label": "foot",
          "bbox": [
            72,
            806,
            396,
            845
          ],
          "text": "© The Author(s) 2024\nA. Malthe-Sørenssen, Percolation Theory Using Python, Lecture Notes\nin Physics 1029, https://doi.org/10.1007/978-3-031-59900-2_1",
          "reading_order": 5
        }
      ]
    },
    {
      "page_number": 12,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            80,
            62
          ],
          "text": "2",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            374,
            44,
            520,
            62
          ],
          "text": "1 Introduction to Percolation",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_012_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_012_figure_002.png",
          "bbox": [
            107,
            80,
            475,
            431
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            446,
            520,
            470
          ],
          "text": "Fig. 1.1 Illustration of a porous material from a simulation of nanoporous silicate (SiO $_2$ ). The\ncolors inside the pores illustrates the distance to the nearest part of the solid",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            501,
            520,
            529
          ],
          "text": "will here instead start with a simpler class of materials — uncorrelated random,\nporous materials .",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            546,
            520,
            757
          ],
          "text": "A Simplified Model of a Porous Medium We will here introduce a simplified\nmodel for a random porous material. We divide the material into cubes (3d) or\nsquares (2d), called sites , of size $d$ . Each site can be either filled or empty. We can\nuse this method to characterize an actual porous medium, as illustrated in Fig. 1.1 ,\nor we can use it as a model for a random porous medium if we fill each site with\na probability $p$ . On average, the volume of the solid part of the material will be\n$V_s=p V$ , where $V$ is the volume of the system, and the volume of the pores will\nbe $V_p=(1-p)V$ . We usually call the relative volume of the pores, the porosity ,\n$\\phi=V_p/V$ , of the material. The solid is called the matrix and the relative volume\nof the matrix, $V_s/V$ is called the solid fraction, which is denoted by $c=V_s/V$ . In\nthis case, we see that $p$ corresponds to the solid fraction. Initially, we will assume\nthat on the scale of lattice cells, the probabilities for sites to be filled are statistically\nindependent — we will study an uncorrelated random medium .",
          "reading_order": 5
        }
      ]
    },
    {
      "page_number": 13,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            217,
            62
          ],
          "text": "1 Introduction to Percolation",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            511,
            44,
            520,
            58
          ],
          "text": "3",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_013_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_013_figure_002.png",
          "bbox": [
            72,
            89,
            520,
            286
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            295,
            520,
            325
          ],
          "text": "Fig. 1.2 Illustration of an array of $4\\times4$ random numbers, and the set sites for different values of\n$p$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            357,
            520,
            451
          ],
          "text": "Generating a Random Medium in Python Figure 1.2 illustrates a two-\ndimensional system of $4\\times 4$ cells. The cells are filled with a probability $p$ . We\nwill call the filled cells occupied or set, and they are colored black. To generate such\na matrix with first generate a matrix z with elements $z_i$ that are uniform random\nnumbers between 0 and 1. A given site i is set if $z_i \\leq p$ and it is empty otherwise.\nThis is implemented by",
          "reading_order": 4
        },
        {
          "label": "code",
          "bbox": [
            79,
            465,
            296,
            542
          ],
          "text": "import numpy as np\nimport matplotlib.pyplot as plt\np = 0.25\nz = np.random.rand(4,4)\nm = z<p\nplt.imshow(m)",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            554,
            520,
            636
          ],
          "text": "The resulting matrices are shown in Fig. 1.2 for various values of $p$ . The left\nfigure illustrates the random values in the matrix, $z$ , and the right figures the set sites\nfor various values of $p$ . You can think of this process as similar a to changing the\nwater level in a landscape ( $z_i$ ) and observing what parts of a landscape is below\nwater ( $z_i\\leq p$ ).",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            651,
            520,
            793
          ],
          "text": "Connectivity in a Random Medium Percolation is the study of connectivity. The\nsimplest question we can ask is: When does a path form from one side of the\nsample to the other? By when, we mean at what value of $p$ . For the particular\nrealizations of the matrix $m$ in Fig. 1.2 we see that the answer depends on how\nwe define connectivity. If we want to make a path along the set (black) sites from\none side to another, we must decide on when two sites are connected. Here, we will\ntypically use nearest neighbor connectivity : Two sites in a square (cubic) lattice are\nconnected if they are nearest neighbors. In the square lattice in Fig. 1.2 , each site has\n$Z=4$ nearest neighbors and $Z=8$ next-nearest neighbors, where the number $Z$",
          "reading_order": 7
        }
      ]
    },
    {
      "page_number": 14,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            80,
            62
          ],
          "text": "4",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            374,
            44,
            520,
            62
          ],
          "text": "1 Introduction to Percolation",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            259
          ],
          "text": "is called the coordination number. We see that with nearest-neighbor connectivity,\nwe get a path from the bottom to the top when $p=0.7$ , but with next-nearest\nneighbor connectivity we would get a path from the bottom to the top already at\n$p=0.4$ . We call the value $p_c$ , the lowest value of $p$ where we get a connected path\nfrom one side to another (from the top to the bottom, from the left to the right, or\nboth) the percolation threshold . For a given realization of the matrix, there is well-\ndefined value for $p_c$ , but another realization would give another realization of $p_c$ .\nWe therefore need to either use statistical averages to characterize the properties of\nthe percolation system, or we need to refer to a theoretical — thermodynamic — limit,\nsuch as the value for $p_c$ in an infinitely large system. When we use $p_c$ here, we will\nusually refer to the thermodynamic value.",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            259,
            520,
            483
          ],
          "text": "In this book, we will develop theories describing various physical properties\nof the percolation system as a function of $p$ . We will characterize the sizes of\nconnected regions, the size of the region connecting one side to another, the size\nof the region that contributes to transport (fluid, thermal or electrical transport), and\nother geometrical properties of the system. Most of the features we study will be\nuniversal, that is, independent of many of the details of the system. From Fig. 1.2\nwe see that $p_c$ depends on the details. For example, it depends on the definition of\nconnectivity. It would also depend on the type of lattice used: square, triangular,\nhexagonal, etc. The value of $p_c$ is specific. However, many other properties of\nthe system are general. For example, how the conductivity of the porous medium\ndepends on $p$ near $p_c$ does not depend on the type of lattice or the choice of\nconnectivity rule. It is universal. This means that we can choose a system which\nis simple to study in order to gain intuition about the general features, and then\napply that intuition to the special cases afterwards.",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            483,
            520,
            690
          ],
          "text": "While the connectivity or type of lattice does not matter, some things do matter.\nFor example, the dimensionality matters: The behavior of a percolation system is\ndifferent in one, two and three dimensions. However, the most important changes in\nbehavior occur between one and two dimensions, where the difference is dramatic,\nwhereas the difference between two and three dimensions is more of a degree that\nwe can easily handle. Actually, the percolation problem becomes simpler again in\nhigher dimensions. In two dimensions, it is possible for a path to around a hole\nand still have connectivity. But it is not possible to have connectivity of both the\npores and the solid in the same direction at the same time. This is possible in\nthree dimensions: A two-dimensional creature would have problems with having\na digestive tract, as it would divide the creature in two, but in three dimensions\nthis is fully possible. Here, we will therefore focus on two and three-dimensional\nsystems.",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            696,
            520,
            806
          ],
          "text": "We will first address percolation in one and infinite dimensions, since we can\nsolve the problems exactly in these cases. We will then address percolation in two\ndimensions, where there are no exact solutions. However, we will see that if we\nassume that the distribution of cluster sizes has a particular scaling form, we can\nstill address the problem in two dimensions and make powerful predictions. We will\nalso see that close to the percolation threshold the porous medium has a self-affine\nscaling structure — it is a fractal. This property has important consequences for the",
          "reading_order": 5
        }
      ]
    },
    {
      "page_number": 15,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            234,
            62
          ],
          "text": "1.1 Basic Concepts in Percolation",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            511,
            44,
            520,
            58
          ],
          "text": "5",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            128
          ],
          "text": "physical properties of random systems. We will also see how this is reflected in a\nsystematic change of scales, a renormalization procedure, which is a general tool\nthat can applied to rescaling in many areas.",
          "reading_order": 2
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            161,
            322,
            179
          ],
          "text": "1.1 Basic Concepts in Percolation",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            196,
            520,
            277
          ],
          "text": "Let us start by studying a specific example of a random medium. We will generate\nan $L\\times L$ lattice of points, called sites, that are occupied with probability $p$ . This\ncorresponds to a coarse-grained porous medium with a porosity $\\phi=p$ , if we\nassume that the occupied sites are holes in the porous material and look at the\nconnectivity of the pores in the material.",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            88,
            277,
            475,
            290
          ],
          "text": "We can generate a realization of a square $L\\times L$ system in python using",
          "reading_order": 5
        },
        {
          "label": "code",
          "bbox": [
            79,
            304,
            278,
            394
          ],
          "text": "import numpy as np\nimport matplotlib.pyplot as p\nL = 20\np = 0.5\nz = np.random.rand(L,L)\nm = z<p\nplt.imshow(m, origin='lower')",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            403,
            520,
            451
          ],
          "text": "The resulting matrix is illustrated in Fig. 1.3 . However, this visualization does not\nprovide us with any insight into the connectivity of the sites in this system. Let us\ninstead analyze the connected regions in the system.",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            88,
            483,
            145,
            501
          ],
          "text": "Definition",
          "reading_order": 8
        },
        {
          "label": "list",
          "bbox": [
            105,
            510,
            502,
            541
          ],
          "text": "two sites are connected if they are nearest neighbors (there are 4 nearest\nneighbors on a square lattice)",
          "reading_order": 9
        },
        {
          "label": "list",
          "bbox": [
            104,
            541,
            287,
            555
          ],
          "text": "a cluster is a set of connected site",
          "reading_order": 10
        },
        {
          "label": "list",
          "bbox": [
            104,
            555,
            457,
            574
          ],
          "text": "a cluster is spanning if it spans from one side to the opposite side",
          "reading_order": 11
        },
        {
          "label": "list",
          "bbox": [
            104,
            574,
            403,
            591
          ],
          "text": "a cluster that is spanning is called the spanning cluster",
          "reading_order": 12
        },
        {
          "label": "list",
          "bbox": [
            104,
            591,
            459,
            609
          ],
          "text": "a system is percolating if there is a spanning cluster in the system",
          "reading_order": 13
        },
        {
          "label": "para",
          "bbox": [
            72,
            645,
            520,
            710
          ],
          "text": "Fortunately, there are built-in functions in python that finds connected regions\nin an image. $^1$ The function measurements.label finds clusters based on a\ngiven connectivity. For example, with a coordination number $Z=4$ , that is nearest\nneighbor connectivity, we find",
          "reading_order": 14
        },
        {
          "label": "code",
          "bbox": [
            80,
            725,
            340,
            747
          ],
          "text": "from scipy.ndimage import measurements\nlw, num = measurements.label(m)",
          "reading_order": 15
        },
        {
          "label": "fnote",
          "bbox": [
            72,
            778,
            520,
            806
          ],
          "text": "1 Notice that these program lines will need the libraries numpy, matplotlib.pyplot and\nmeasurements to be loaded. We will assume you have done this in the following.",
          "reading_order": 16
        }
      ]
    },
    {
      "page_number": 16,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            80,
            62
          ],
          "text": "6",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            374,
            44,
            520,
            62
          ],
          "text": "1 Introduction to Percolation",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_016_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_016_figure_002.png",
          "bbox": [
            72,
            80,
            520,
            286
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            295,
            412,
            313
          ],
          "text": "Fig. 1.3 Illustration of the index array for a $10 \\times 10$ system for $p=0.45$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            340,
            520,
            450
          ],
          "text": "This function returns the matrix lw , which for each site in the original array tells\nwhat cluster it belongs to. Clusters are numbered sequentially, and each cluster is\ngiven an index number. All the sites with the same index number belong to the\nsame cluster. The resulting array is shown in Fig. 1.3 , where the index number for\neach site is shown and a color is used to indicate the clusters. Notice that there is a\ndistribution of cluster sizes, but no cluster is large enough to reach from one side to\nanother, and as a result the system does not percolate.",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            450,
            520,
            483
          ],
          "text": "In order to visualize the clusters effectively, we give the various clusters different\ncolors.",
          "reading_order": 5
        },
        {
          "label": "code",
          "bbox": [
            79,
            492,
            287,
            510
          ],
          "text": "plt.imshow(lw, origin='lower')",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            519,
            520,
            596
          ],
          "text": "Unfortunately, this colors the clusters gradually from the bottom up. This is a\nproperty of the underlying algorithm: Clusters are indexed starting from the top-\nleft of the matrix (which is the bottom-left of the image). Hence, clusters that are\nclose to each other will get similar colors and can therefore be difficult to discern\nunless we shuffle the colormap. We can fix this by shuffling the labeling:",
          "reading_order": 7
        },
        {
          "label": "code",
          "bbox": [
            79,
            609,
            340,
            663
          ],
          "text": "b = np.arange(lw.max() + 1)\nnp.random.shuffle(b)\nshuffledLw = b[lw]\nplt.imshow(shuffledLw, origin='lower')",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            72,
            672,
            520,
            734
          ],
          "text": "The resulting image is shown to the right in Fig. 1.3 . (Notice that in these figures\nwe have reversed the ordering of the $y$ -axis. Usually, the first row is in the top-left\ncorner in your plots, but when we use the keyword lower the first row is in the\nbottom-left).",
          "reading_order": 9
        },
        {
          "label": "para",
          "bbox": [
            72,
            734,
            520,
            770
          ],
          "text": "It may also be useful to color the clusters based on the size of the clusters, where\nsize refers to the number of sites in a cluster. We can do this using",
          "reading_order": 10
        },
        {
          "label": "code",
          "bbox": [
            80,
            779,
            494,
            806
          ],
          "text": "area = measurements.sum(m, lw, index=np.arange(lw.max() + 1))\nareaImg = area[lw]",
          "reading_order": 11
        }
      ]
    },
    {
      "page_number": 17,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            234,
            62
          ],
          "text": "1.1 Basic Concepts in Percolation",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            511,
            44,
            520,
            62
          ],
          "text": "7",
          "reading_order": 1
        },
        {
          "label": "code",
          "bbox": [
            79,
            80,
            322,
            109
          ],
          "text": "plt.imshow(areaImg, origin='lower')\nplt.colorbar()",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            116,
            520,
            152
          ],
          "text": "Let us now study the effect of p on the set of connected clusters. We vary the\nvalue of p for the same underlying random matrix, and plot the resulting images:",
          "reading_order": 3
        },
        {
          "label": "code",
          "bbox": [
            79,
            161,
            511,
            376
          ],
          "text": "import numpy as np\nimport matplotlib.pylab as plt\nfrom scipy.ndimage import measurements\nplt.figure(figsize=(10,8))\nL = 100\npv = [0.2,0.3,0.4,0.5,0.6,0.7]\nz = np.random.rand(L, L)\nfor i in range(len(pv)):\np = pv[i]\nm = z<p\nlw, num = measurements.label(m)\narea = measurements.sum(m, lw, index=np.arange(lw.max() + 1))\nareaImg = area[lw]\nplt.subplot(2,3,i+1)\ntit = 'p-'+&tr(p)\nplt.imshow(areaImg, origin='lower')\nplt.title(tit)",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            384,
            520,
            465
          ],
          "text": "Figure 1.4 shows the clusters for a $100\\times100$ system for $p$ ranging from $0.2$ to $0.7$\nin steps of $0.1$ . We see that the clusters increase in size as $p$ increases. At $p=0.6$\nthere is one large cluster spanning the entire region. We have a percolating cluster ,\nand we call the cluster that spans the system the spanning cluster . The transition is\nvery rapid from $p=0.5$ to $p=0.6$ . We therefore look at this region in more detail",
          "reading_order": 5
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_017_figure_006.png)",
          "figure_path": "figures/percolation_studies_page_017_figure_006.png",
          "bbox": [
            63,
            492,
            520,
            788
          ],
          "reading_order": 6
        },
        {
          "label": "cap",
          "bbox": [
            72,
            795,
            413,
            806
          ],
          "text": "Fig. 1.4 Plot of the clusters in a $100\\times100$ system for various values of $p$",
          "reading_order": 7
        }
      ]
    },
    {
      "page_number": 18,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            80,
            62
          ],
          "text": "8",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            374,
            44,
            512,
            62
          ],
          "text": "1 Introduction to Percolation",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_018_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_018_figure_002.png",
          "bbox": [
            72,
            80,
            520,
            224
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            232,
            413,
            250
          ],
          "text": "Fig. 1.5 Plot of the clusters in a $100 \\times 100$ system for various values of $p$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            277,
            520,
            340
          ],
          "text": "in Fig. 1.5 . We see that the size of the largest cluster increases rapidly as $p$ reaches a\nvalue around 0.6, which corresponds to $p_c$ for this system. At this point, the largest\ncluster spans the entire system. For the two-dimensional system illustrated here we\nknow that in an infinite lattice the percolation threshold is $p_c\\simeq 0.5927$ .",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            340,
            520,
            439
          ],
          "text": "The aim of this book is to develop a theory to describe how this random porous\nmedium behaves close to $p_c$ . We will characterize properties such as the density of\nthe spanning cluster, the geometry of the spanning cluster, and the conductivity and\nelastic properties of the spanning cluster. We will address the distribution of cluster\nsizes and how various parts of the clusters are important for particular physical\nprocesses. We start by characterizing the behavior of the spanning cluster near $p_c$ .",
          "reading_order": 5
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            465,
            278,
            484
          ],
          "text": "1.2 Percolation Probability",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            501,
            520,
            629
          ],
          "text": "When does the system percolate? When there exists a path connecting one side to\nanother. This occurs at some value $p=p_c$ . However, in a finite system, like the\nsystem we simulated above, the value we find for $p_c$ will vary with each realization.\nIt may be slightly above or slightly below the $p_c$ we find in an infinite sample. Later,\nwe will develop a theory to understand how the effective $p_c$ in a finite system varies\nfrom the thermodynamic $p_c$ . But already now we realize that as we perform different\nnumerical experiments, we will measure various values of $p_c$ . We can characterize\nthis behavior by introducing a probability $\\Pi(p,L)$ :",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            88,
            663,
            502,
            711
          ],
          "text": "Percolation Probability The percolation probability $\\Pi(p,L)$ is the probabil-\nity for there to be a connected path from one side to another side as a function\nof p in a system of size L.",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            72,
            752,
            520,
            801
          ],
          "text": "We can measure $\\Pi(p,L)$ in a finite sample of size $L\\times L$ , by generating many\nrandom matrices. For each matrix, we perform a cluster analysis for a sequence of\n$p_i$ values. For each $p_i$ we find all the clusters. We then check if any of the clusters",
          "reading_order": 9
        }
      ]
    },
    {
      "page_number": 19,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            198,
            62
          ],
          "text": "1.2 Percolation Probability",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            511,
            44,
            520,
            62
          ],
          "text": "9",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            206
          ],
          "text": "are present both on the left and on the right side of the lattice. In that case, they are\nspanning (We could also have included a test for clusters spanning from the top to\nthe bottom, but this does not change the statistics significantly). In this case, there is\na spanning cluster — the system percolates. We count how many times, $N_i$ , a system\npercolates for a given $p_i$ and then divide by the total number of experiment, $N$ ,\nto estimate the probability for percolation for a given $p_i$ , $\\Pi(p_i,L)\\simeq N_i/N$ . We\nimplement this as follows. First, we generate a sequence of 100 $p_i$ values from 0.35\nto 1.0:",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            79,
            224,
            278,
            234
          ],
          "text": "p = np.linspace(0.35,1.0,100)",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            241,
            467,
            259
          ],
          "text": "Then we prepare an array for $N_{i}$ with the same number of elements as $p_{i}$ :",
          "reading_order": 4
        },
        {
          "label": "code",
          "bbox": [
            80,
            268,
            197,
            296
          ],
          "text": "nx = len(p)\nPi = np.zeros(nx)",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            304,
            269,
            322
          ],
          "text": "We will generate $N=1000$ samples",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            79,
            331,
            134,
            349
          ],
          "text": "N = 1000",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            358,
            520,
            468
          ],
          "text": "We will then loop over all samples, and for each sample we generate a new random\nmatrix. The for each value of $p_i$ we perform the cluster analysis as we did above.\nWe use the function measurements.label to label the clusters. Then we find\nthe intersection between the labels on the left and the right side of the system and\nstore in perc_x . If the length of the set of intersections is larger than zero, there\nis at least one percolating cluster, and we find the label of the spanning cluster(s) in\nperc :",
          "reading_order": 8
        },
        {
          "label": "code",
          "bbox": [
            79,
            482,
            358,
            520
          ],
          "text": "lw,num = measurements.label(z)\nperc_x = np.intersect1d(lw[0,:],lw[-1,:})\nperc = perc_x[np.where(perc_x>0)]",
          "reading_order": 9
        },
        {
          "label": "para",
          "bbox": [
            72,
            528,
            520,
            592
          ],
          "text": "Now, we are ready to implement this into a complete program. For a given value\nof $p$ , we count in how many simulations $N_p(p)$ there is a path spanning from one\nside to another and estimate $\\bar{\\varPi}(p) \\simeq N_p(p)/N$ , where $N$ is the total number of\nsimulations/samples. This is implemented in the following program:",
          "reading_order": 10
        },
        {
          "label": "code",
          "bbox": [
            79,
            600,
            412,
            806
          ],
          "text": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.ndimage import measurements\np = np.linspace(0.4,1.0,100)\nnx = len(p)\nNi = np.zeros(nx)\nP = np.zeros(nx)\nN = 1000\nL = 100\nfor i in range(N):\nz = np.random.rand(L,L)\nfor ip in range(nx):\nm = z<p[ip]\nlw, num = measurements.label(m)\nperc_x = np.intersect1d(lw[0,:],1w[-1,:])",
          "reading_order": 11
        }
      ]
    },
    {
      "page_number": 20,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            84,
            62
          ],
          "text": "10",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            374,
            44,
            520,
            62
          ],
          "text": "1 Introduction to Percolation",
          "reading_order": 1
        },
        {
          "label": "code",
          "bbox": [
            79,
            80,
            358,
            179
          ],
          "text": "perc = perc_x[np.where(perc_x>0)]\nif (len(perc)>0):\nNi[ip] = Ni[ip] + 1\nPi = Ni/N\nplt.plot(p,Pi)\nplt.xlabel(’$p$’)\nplt.ylabel(’$\\Pi$’)",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            188,
            520,
            233
          ],
          "text": "The resulting plot of $\\Pi(p,L)$ is seen in Fig. 1.6 . The figure shows the resulting\nplots as a function of system size $L$ . We see that as the system size increases,\n$\\Pi(p,L)$ approaches a step function at $p=p_c$ .",
          "reading_order": 3
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            266,
            238,
            281
          ],
          "text": "1.3 Spanning Cluster",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            295,
            520,
            378
          ],
          "text": "The probability $\\varPi(p,L)$ describes the probability for there to be a spanning cluster,\nbut what about the spanning cluster itself, how can we characterize it? We see from\nFig. that the spanning cluster grows quickly around $p=p_c$ . Let us therefore\ncharacterize the cluster by its size, $M_S$ , or by its density, $P(p,L)=M_S/L^2$ , which\ncorresponds to the probability for a site to belong the spanning cluster.",
          "reading_order": 5
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_020_figure_006.png)",
          "figure_path": "figures/percolation_studies_page_020_figure_006.png",
          "bbox": [
            80,
            412,
            511,
            680
          ],
          "reading_order": 6
        },
        {
          "label": "cap",
          "bbox": [
            72,
            689,
            520,
            716
          ],
          "text": "Fig. 1.6 Plot of $\\varPi(p,L)$ , the probability for there to be a connected path from one side to anther,\nas a function of $p$ for various system sizes $L$ , and $P(p,L)$ , the density of the spanning cluster",
          "reading_order": 7
        }
      ]
    },
    {
      "page_number": 21,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            179,
            62
          ],
          "text": "1.3 Spanning Cluster",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            511,
            44,
            520,
            62
          ],
          "text": "1",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            88,
            98,
            502,
            134
          ],
          "text": "Density of the Spanning Cluster The probability $P(p,L)$ for a site to belong\nto a spanning cluster is called the density of the spanning cluster.",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            170,
            520,
            251
          ],
          "text": "We can measure $P(p,L)$ by counting the mass $M_i$ of the spanning cluster as\na function of $p_i$ for various values of $p_i$ . We can find the mass of the spanning\ncluster by finding a cluster that spans the system (there may be more than one) as\nwe did above, and then measure the number of sites in the cluster using area =\nmeasurements.sum(m, lw, perc) .",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            251,
            520,
            316
          ],
          "text": "We do this in the same program as we developed above. For each $p_i$ , we see if\na cluster is spanning from one side to another, and if it is, we add the mass of this\ncluster to $M_S(p_i)$ . We implement these features in the following program, which\nmeasures both $\\Pi(p,L)$ and $P(p,L)$ for a given value of $L$ :",
          "reading_order": 4
        },
        {
          "label": "code",
          "bbox": [
            79,
            330,
            421,
            716
          ],
          "text": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.ndimage import measurements\np = np.linspace(0.4,1.0,100)\nnx = len(p)\nNi = np.zeros(nx)\nP = np.zeros(nx)\nN = 1000\nL = 100\nfor i in range(N):\nz = np.random.rand(L,L)\nfor ip in range(nx):\nm = z<p[ip]\nlw, num = measurements.label(m)\nperc_x = np.intersect1d(lw[0,:],lw[-1,:])\nperc = perc_x[np.where(perc_x>0)]\nif (len(perc)>0):\nNi[ip] = Ni[ip] + 1\narea = measurements.sum(m, lw, perc[0]\nP[ip] = P[ip] + area\nPi = Ni/N\nP = P/(N*L*L)\nplt.subplot(2,1,1)\nplt.plot(p,Pi)\nplt.ylabel(\"$\\Pi(p)$\")\nplt.subplot(2,1,2)\nplt.plot(p,P)\nplt.ylabel(\"P(p)\")\nplt.xlabel(\"p\")",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            725,
            520,
            806
          ],
          "text": "The resulting plot of $P(p,L)$ is shown in the bottom of Fig. 1.6 . We see that\n$P(p,L)$ changes rapidly around $p=p_c$ , and that it grows slowly — approximately\nlinearly — as $p\\to 1$ . We can understand this linear behavior: When $p$ is near 1\npractically all the set sites are connected and are part of the spanning cluster. In this\nlimit, the density of the spanning cluster is therefore proportional to the number of",
          "reading_order": 6
        }
      ]
    },
    {
      "page_number": 22,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            83,
            62
          ],
          "text": "12",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            374,
            44,
            512,
            62
          ],
          "text": "1 Introduction to Percolation",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            128
          ],
          "text": "sites that are present, which again is proportional to $p$ . We will now develop a theory\nfor the observations of $\\Pi(p,L),~P(p,L)$ and other features of the percolation\nsystem. First, we see what insights we can gain from small, finite systems.",
          "reading_order": 2
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            161,
            315,
            179
          ],
          "text": "1.4 Percolation in Small Systems",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            196,
            520,
            241
          ],
          "text": "First, we will address the two-dimensional system directly. We will study a $L\\times L$\nsystem, and the various physical properties of it. We will start with $L=1$ and $L=2$\nand then try to generalize.",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            259,
            520,
            322
          ],
          "text": "$L=1$ First, let us address $L=1$ . In this case, the system percolates if the\nsite is present, which has a probability $p$ . The percolation probability is therefore\n$\\Pi(p,1)=p$ . Similarly, the probability for a site to belong to the spanning cluster\nis $p$ and therefore $P(p,1)=p$ .",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            340,
            520,
            421
          ],
          "text": "$L=2$ Then, let us examine $L=2$ . This is still simple, but we now have to\ndevelop a more advanced strategy than for $L=1$ . Our strategy will be to list all\npossible outcomes, find the probability for each outcome, and then use this to find\nthe probability for the various physical properties we are interested in. The possible\nconfigurations are shown in Fig. 1.7 .",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            421,
            520,
            707
          ],
          "text": "Our plan is to use a basic result from probability theory: If we want to calculate\nthe probability of an event $A$ , we can do this by summing the probability of $A$ given\n$B$ multiplied by the probability for $B$ over all possible outcomes $B$ (as long as the\nset of outcomes $B$ span the space of all outcomes and are mutually exclusive, that\nis, that they have no intersection). In this case:\n\\[P(A)=\\sum_{B} P(A|B)P(B)~,\\eqno(1.1)\\]\nwhere we have used the notation $P(A|B)$ to denote the conditional probability of\n$A$ given that $B$ occurs. We can use this to calculate properties such as $\\Pi(p,L)$ and\n$P(p,L)$ by summing over all possible configurations $c$ of the system:\n\\[\\Pi(p,L)=\\sum_{c} \\Pi(p,L|c)P(c)~,\\eqno(1.2)\\]\nwhere $\\Pi(p,L|c)$ is the value of $\\Pi$ for the particular configuration $c$ , and $P(c)$ is\nthe probability of this configuration.",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            707,
            520,
            806
          ],
          "text": "The configurations for $L=2$ have been numbered from $c=1$ to $c=16$\nin Fig. 1.7 . However, configurations that are either mirror images or rotations of\neach other will have the same probability and the same physical properties since\npercolation can take place both in the $x$ and the $y$ directions. It is therefore only\nnecessary to group the configurations into 6 different classes, $k$ , as illustrated in the\nbottom of Fig. 1.7 , but we then need to include the multiplicity, $g_k$ , for each class",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 23,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            233,
            62
          ],
          "text": "1.4 Percolation in Small Systems",
          "reading_order": 0
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_023_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_023_figure_002.png",
          "bbox": [
            116,
            80,
            466,
            412
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            419,
            513,
            443
          ],
          "text": "Fig. 1.7 The possible configurations for a $L=2$ site percolation lattice in two-dimensions. The\nconfigurations are indexed using the cluster configuration number $c$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            474,
            421,
            537
          ],
          "text": "when we calculate probabilities. The probability $\\varPi(p,L)$ is then\n$$\\varPi(p,L)=\\sum_{k}g_{k}\\varPi(p,L|k)P(k)~.$$",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            554,
            511,
            583
          ],
          "text": "Table 1.1 lists the classes, the number of configurations in each class, the probability\nof one such configuration in a class, and the value of $\\Pi(p,L|k)$ for this class.",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            583,
            520,
            650
          ],
          "text": "We should check that we have actually listed all possible configurations. In\ngeneral, the number of configurations for an $L\\times L$ system is $2^{L^2}$ . The total number\nof configurations is $1+4+2+4+4+1=16$ , which is equal to $2^4$ as it should.\nWe have therefore included all the configurations.",
          "reading_order": 6
        },
        {
          "label": "cap",
          "bbox": [
            72,
            680,
            197,
            734
          ],
          "text": "List 1.1 List of classes,\nconfigurations in each class\nand the probability of one\nsuch configuration",
          "reading_order": 7
        },
        {
          "label": "tab",
          "bbox": [
            376,
            680,
            520,
            797
          ],
          "text": "<table><tr><td>c</td><td>g k</td><td>P ( k )</td><td>Π ( p, L | k )</td></tr><tr><td>1</td><td>1</td><td>p 0 (1 − p ) 4</td><td>0</td></tr><tr><td>2</td><td>4</td><td>p 1 (1 − p ) 3</td><td>0</td></tr><tr><td>3</td><td>4</td><td>p 2 (1 − p ) 2</td><td>1</td></tr><tr><td>4</td><td>2</td><td>p 2 (1 − p ) 2</td><td>0</td></tr><tr><td>5</td><td>4</td><td>p 3 (1 − p ) 1</td><td>1</td></tr><tr><td>6</td><td>1</td><td>p 4 (1 − p ) 0</td><td>1</td></tr></table>",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 24,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            83,
            58
          ],
          "text": "14",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            374,
            44,
            512,
            62
          ],
          "text": "1 Introduction to Percolation",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_024_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_024_figure_002.png",
          "bbox": [
            72,
            80,
            520,
            439
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            454,
            376,
            465
          ],
          "text": "Fig. Plot of $\\Pi(p,L)$ for $L=1$ and $L=2$ as a function of $p$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            88,
            492,
            520,
            573
          ],
          "text": "We can then find the probability for $\\Pi$ by direct calculation of the sum:\n$$\\begin{aligned}\n& \\Pi=0 \\cdot 1 \\cdot p^{0}(1-p)^{4}+0 \\cdot 4 \\cdot p^{1}(1-p)^{3}+1 \\cdot 4 \\cdot p^{2}(1-p)^{2} \\\\\n&+0 \\cdot 2 \\cdot p^{2}(1-p)^{2}+1 \\cdot 4 \\cdot p^{3}(1-p)^{1}+1 \\cdot 1 \\cdot p^{4}(1-p)^{0} .\n\\end{aligned}\\qquad(1.4)$$",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            588,
            520,
            681
          ],
          "text": "The exact value for $\\varPi(p,L=2)$ is therefore:\n$$\\varPi(p,L=2)=4 p^2(1-p)^2+4 p^3(1-p)^1+p^4(1-p)^0~,\\eqno{(1.6)}$$\nwhich we can simplify further if we want. The shape of $\\varPi(p,L)$ for $L=1$ , and\n$L=2$ is shown in Fig. 1.8 .",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            698,
            518,
            779
          ],
          "text": "We $\\Pi(p_c)=1/2$ Setting p c We could characterize $p=p_c$ as the number for which . For $L=1$ , we then get $\\Pi(p_c)=p_c=1/2$ . And for $L=2$ , we find $4p^2_c(1-p_c)^{1}+p^4_c(1-p_c)^0=1/2$ , which gives $p_c(L=2)\\simeq 0.4588$ .\nMaybe we can just continue doing this type of calculation for higher and higher $L$\nand we will get a better and better approximation for $p_c$ ?",
          "reading_order": 6
        }
      ]
    },
    {
      "page_number": 25,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            108,
            58
          ],
          "text": "Exercise",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            511,
            44,
            520,
            62
          ],
          "text": "5",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            179
          ],
          "text": "Extending to Larger Systems We notice that for finite $L$ , $\\Pi(p, L)$ will be a\npolynomial of order $\\mathcal{O}(L^2)$ - it is in principle a function we can calculate. However,\nthe number of possible configurations is $2^{L^2}$ which increases very rapidly with\n$L$ . It is therefore not realistic to use this technique for calculating the percolation\nprobabilities. We will need to have more powerful techniques, or simpler problems,\nin order to perform exact calculations.",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            179,
            520,
            277
          ],
          "text": "However, we can still learn much from a discussion of finite $L$ . For example, we\nnotice that\n\\[\n   \\Pi(p, L) \\simeq Lp^{L} + c_1 p^{L+1} + \\ldots + c_n p^{L^2}~, \\eqno(1.7)\n    \\]\nin the limit of $p \\ll 1$ . The leading order term when $p \\to 0$ is therefore $Lp^L$ .",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            88,
            277,
            520,
            331
          ],
          "text": "Similarly, we find that for $p\\rightarrow1$ , the leading order term is approximately\n$$\n\\Pi(p,L)\\simeq 1-(1-p)^{L}~.\\eqno(1.8)\n$$",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            340,
            520,
            376
          ],
          "text": "These two results gives us an indication about how the percolation probability\n$\\varPi(p,L)$ is approaching the step function when $L\\to\\infty$ .",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            376,
            520,
            405
          ],
          "text": "Similarly, we can calculate $P(p,L)$ for $L=2$ . However, we leave the calculation\nof the $L=3$ and the $P(p,L)$ system to the exercises.",
          "reading_order": 6
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            438,
            233,
            453
          ],
          "text": "1.5 Further Reading",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            465,
            520,
            582
          ],
          "text": "There are good general introduction texts to percolation theory such as the popular\nbooks by Stauffer and Aharony [ 37 ] , by Sahimi [ 30 ] , by Christensen and Moloney\n[ 8 ] , and the classical book by Grimmet [ 14 ] . Mathematical aspects are addressed\nby Kesten [ 21 ] and phase transitions in general are introduced by e.g. Stanley [ 35 ] .\nApplications of percolation theory are found in many fields such as in geoscience\n[ 22 ] , porous media [ 18 ] or social networks [ 33 ] and many more. We encourage you\nto explore these books for a more theoretical introduction to percolation theory.",
          "reading_order": 8
        },
        {
          "label": "sec",
          "bbox": [
            72,
            615,
            135,
            627
          ],
          "text": "Exercises",
          "reading_order": 9
        },
        {
          "label": "para",
          "bbox": [
            72,
            645,
            278,
            663
          ],
          "text": "Exercise 1.1 (Percolation for L=3)",
          "reading_order": 10
        },
        {
          "label": "para",
          "bbox": [
            72,
            680,
            287,
            695
          ],
          "text": "(a) Find $P(p,L)$ for $L=1$ and $L=2$.",
          "reading_order": 11
        },
        {
          "label": "para",
          "bbox": [
            71,
            698,
            358,
            711
          ],
          "text": "(b) Categorize all possible configurations for $L=3$ .",
          "reading_order": 12
        },
        {
          "label": "para",
          "bbox": [
            72,
            714,
            304,
            727
          ],
          "text": "(c) Find $\\Pi (p,L)$ and $P(p,L)$ for $L=3$.",
          "reading_order": 13
        }
      ]
    },
    {
      "page_number": 26,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            83,
            58
          ],
          "text": "16",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            374,
            44,
            520,
            62
          ],
          "text": "1 Introduction to Percolation",
          "reading_order": 1
        },
        {
          "label": "sec",
          "bbox": [
            72,
            80,
            396,
            98
          ],
          "text": "Exercise 1.2 (Counting Configurations in Small Systems)",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            115,
            396,
            128
          ],
          "text": "(a) Write a program to find all the configurations for $L=2$ .",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            71,
            128,
            520,
            161
          ],
          "text": "(b) Use this program to find $\\Pi(p,L=2)$ and $P(p,L=2)$ . Compare with the\nexact results from the previous exercise.",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            161,
            448,
            179
          ],
          "text": "(c) Use you program to find $\\Pi(p, L)$ and $P(p, L)$ for $L=3,4$ and 5",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            196,
            511,
            225
          ],
          "text": "Exercise 1.3 (Percolation in Small Systems in 3d) In this exercise we will stud\nthe three-dimensional site percolation system for small system sizes.",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            241,
            344,
            259
          ],
          "text": "(a) How many configurations are there for L=2?",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            71,
            259,
            358,
            277
          ],
          "text": "(b) Categorize all possible configurations for $L=2$.",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            72,
            277,
            304,
            290
          ],
          "text": "(c) Find $\\Pi (p,L)$ and $P(p,L)$ for $L=2$.",
          "reading_order": 9
        },
        {
          "label": "para",
          "bbox": [
            71,
            293,
            514,
            322
          ],
          "text": "(d) Compare your results with your result for the two-dimensional system. Com\nment on similarities and differences.",
          "reading_order": 10
        },
        {
          "label": "para",
          "bbox": [
            72,
            636,
            520,
            701
          ],
          "text": "Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0\nInternational License ( http://creativecommons.org/licenses/by/4.0/ ), which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as long as you give appropriate\ncredit to the original author(s) and the source, provide a link to the Creative Commons license and\nindicate if changes were made.",
          "reading_order": 11
        },
        {
          "label": "para",
          "bbox": [
            72,
            701,
            518,
            770
          ],
          "text": "The images or other third party material in this chapter are included in the chapter’s Creative\nCommons license, unless indicated otherwise in a credit line to the material. If material is not\nincluded in the chapter’s Creative Commons license and your intended use is not permitted by\nstatutory regulation or exceeds the permitted use, you will need to obtain permission directly from\nthe copyright holder.",
          "reading_order": 12
        }
      ]
    },
    {
      "page_number": 27,
      "elements": [
        {
          "label": "sec",
          "bbox": [
            72,
            98,
            358,
            116
          ],
          "text": "One-Dimensional Percolation",
          "reading_order": 0
        },
        {
          "label": "para",
          "bbox": [
            528,
            107,
            546,
            134
          ],
          "text": "2",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            304,
            520,
            387
          ],
          "text": "The percolation problem can be solved exactly in two limits: in the one-dimensional\nand the infinite dimensional cases. Here, we will first address the one-dimensional\nsystem. While the one-dimensional system does not allow us to study the full com-\nplexity of the percolation problem, many of the concepts and measures introduced\nto study the one-dimensional problem can generalized to higher dimensions.",
          "reading_order": 2
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            420,
            278,
            439
          ],
          "text": "2.1 Percolation Probability",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            448,
            520,
            555
          ],
          "text": "Let us first address percolation in a one-dimensional lattice of $L$ sites. In this case,\nthere is a spanning cluster if and only if all the sites are occupied. If only a single site\nis empty, the connecting path will be broken and there will not be any connecting\npath from one side to the other. The percolation probability is therefore\n\\[\n\\Pi(p, L)=p^{L}~. \\eqno(2.1)\n\\]",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            564,
            385,
            636
          ],
          "text": "This has a trivial behavior when $L\\to \\infty $\n$$\\varPi(p,\\infty)=\\left\\{\\begin{array}{l}0\\;\\text{ when } p<1\\\\1\\;\\text{ when } p=1\\end{array}.\\right.  $$",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            645,
            520,
            725
          ],
          "text": "This shows that the percolation threshold is $p_c=1$ in one dimension. However,\nthe one-dimensional system is anomalous, and in higher dimensions we will\nalways have $p_c<1$ , so that we can study the system both above and below $p_c$ .\nUnfortunately, for the one-dimensional system we can only study the system below\n$p_c$ .",
          "reading_order": 6
        },
        {
          "label": "foot",
          "bbox": [
            72,
            806,
            174,
            816
          ],
          "text": "© The Author(s) 2024",
          "reading_order": 7
        },
        {
          "label": "watermark",
          "bbox": [
            72,
            816,
            396,
            833
          ],
          "text": "A. Malthe-Sørenssen, Percolation Theory Using Python, Lecture Notes",
          "reading_order": 8
        },
        {
          "label": "watermark",
          "bbox": [
            72,
            833,
            360,
            845
          ],
          "text": "in Physics 1029, https://doi.org/10.1007/978-3-031-59900-2_2",
          "reading_order": 9
        },
        {
          "label": "foot",
          "bbox": [
            511,
            806,
            520,
            816
          ],
          "text": "7",
          "reading_order": 10
        }
      ]
    },
    {
      "page_number": 28,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            84,
            62
          ],
          "text": "18",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            358,
            44,
            520,
            62
          ],
          "text": "2 One-Dimensional Percolation",
          "reading_order": 1
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            80,
            287,
            98
          ],
          "text": "2.2 Cluster Number Density",
          "reading_order": 2
        },
        {
          "label": "sub_sub_sec",
          "bbox": [
            72,
            107,
            315,
            125
          ],
          "text": "Definition of Cluster Number Density",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            143,
            520,
            224
          ],
          "text": "In the simulations in Fig. 1.4 we saw that the percolation system was characterized\nby a wide distribution of clusters — regions of connected sites. The clusters have\nvarying shape and size. If we increase $p$ to approach $p_c$ we saw that the clusters\nincreased in size until they reached the system size. We can use the one-dimensional\nsystem to learn more about the behavior of clusters as $p$ approaches $p_c$ .",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            224,
            520,
            367
          ],
          "text": "Figure 2.1 illustrates a realization of an $L=16$ percolation system in one\ndimension below $p_c=1$ . In this case there are 5 clusters of sizes: 1,1,4,2,1\nmeasured as the number of sites in each cluster. The clusters are numbered, indexed,\nfrom 1 to 5 as we did for the numerical simulations in two dimensions. How can we\ncharacterize the clusters in a system? In percolation theory we characterize cluster\nsizes by asking a particular question: If you point at a (random) site in the lattice,\nwhat is the probability for this site to belong to a cluster of size $s$ ?\n$$P(\\text{site is part of cluster of size } s)=sn(s,\\, p)~.\\eqno(2.3)$$",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            385,
            520,
            496
          ],
          "text": "It is common to use the notation $sn(s,\\,p)$ for this probability for a given site to\nbelong to a cluster of size $s$ . Why is it divided into two parts, $s$ and $n(s,\\,p)$ ? Because\nwe must divide the question into two parts: (1) What is the probability for a given\nsite to be a specific site in a cluster of size $s$ , and (2) how many such specific sites\nare there in a cluster? What do we mean by a specific site? For the cluster with\nindex 3 in Fig. 2.1 there are 4 sites. We could therefore ask the question: What is\nthe probability for a site to be the left-most site in a cluster of size $s$ ? This is what",
          "reading_order": 6
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_028_figure_007.png)",
          "figure_path": "figures/percolation_studies_page_028_figure_007.png",
          "bbox": [
            54,
            519,
            528,
            761
          ],
          "reading_order": 7
        },
        {
          "label": "cap",
          "bbox": [
            72,
            770,
            520,
            815
          ],
          "text": "Fig. 2.1 Realization of a $L=16$ percolation system in one dimension. Separate clusters are\nillustrated by the indexes, shown as numbers inside the sites. Occupied sites are marked with gray\nsquares",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 29,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            210,
            62
          ],
          "text": "2.2 Cluster Number Density",
          "reading_order": 0
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            540
          ],
          "text": "we mean with a specific site. We could ask the same question about the second left-\nmost, the third left-most and so on. We call the probability for a site to belong to a\nspecific site in a cluster of size $s$ (such as the left-most site in the cluster) the cluster\nnumber density , and we use the notation $n(s,\\,p)$ for this. To find the probability\n$sn(s,\\,p)$ for a site to belong to any of the $s$ sites in a cluster of size $s$ we must sum\nthe probabilities for each of the specific sites. This is illustrated for the case of a\ncluster of size 4:\n$$P(\\text{site to be in cluster of size 4})$$\n$$= P(\\text{site to be left-most site in cluster of size 4})$$\n$$+ P(\\text{site to be second left-most site in cluster of size 4})$$\n$$+ P(\\text{site to be third left-most site in cluster of size 4})$$\n$$+ P(\\text{site to be fourth left-most site in cluster of size 4})$$\n$$= 4P(\\text{site to be left-most site in cluster of size 4})\\;,$$\nbecause each of these probabilities are the same. What is the probability for a site to\nbe the left-most site in a cluster of size $s$ in one dimension? In order for it to be in\na cluster of size $s$ , the site must be present, which has probability $p$ , and then $s-1$\nsites must also be present to the right of it, which has probability $p^{s-1}$ . In addition,\nthe site to the left must be empty (illustrated by an X in Fig. 2.1 bottom part), which\nhas probability $(1-p)$ and the site to the right of the fourth site (illustrated by an\nX in Fig. 2.1 bottom part), which also has probability $(1-p)$ . Since the occupation\nprobabilities for each site are independent, the probability for the site to be the left-\nmost site in a cluster of size $s$ is the product of these probabilities:",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            555,
            358,
            573
          ],
          "text": "This is the cluster number density in one dimension.",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            88,
            609,
            502,
            672
          ],
          "text": "Cluster Number Density The cluster number density $n(s,\\,p)$ is the probabil-\nity for a site to be a particular site in a cluster of size $s$ . For example, in one\ndimension, $n(s,\\,p)$ can be interpreted as the probability for a site to be the\nleft-most site in a cluster of size $s$ .",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            707,
            520,
            807
          ],
          "text": "We should check that $sn(s,\\,p)$ really is a normalized probability. How should\nit be normalized? We know that if we point at a random site in the system, the\nprobability for that site to be occupied is $p$ . An occupied site is then either a part of\na finite cluster of some size $s$ or it is part of the infinite cluster. The probability for\na site to be a part of the infinite cluster we called $P$ . This means that we have the\nfollowing normalization condition:",
          "reading_order": 5
        }
      ]
    },
    {
      "page_number": 30,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            81,
            58
          ],
          "text": "20",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            358,
            44,
            512,
            62
          ],
          "text": "2 One-Dimensional Percolation",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            88,
            98,
            502,
            224
          ],
          "text": "Normalization of the Cluster Number Density A site is occupied with\nprobability $p$ . An occupied site is either part of a finite cluster of size $s$\nwith probability $sn(s,\\, p)$ or it is part of the infinite (spanning) cluster with\nprobability $P(p)$ :\n$$p=\\sum_{s=1}^{\\infty} sn(s,\\, p)+P(p)\\;.\\eqno(2.5)$$",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            267,
            520,
            537
          ],
          "text": "Let us check that this is indeed the case for the one-dimensional expression for\n$n(s,\\,p)$ by calculating the sum:\n$$ \\sum_{s=1}^{\\infty}sn(s,\\, p)=\\sum_{s=1}^{\\infty}sp^s(1-p)^2=(1-p)^2p\\sum_{s=1}^{\\infty}sp^{s-1}~,\\eqno(2.6)$$\nwhere we will now employ a common trick:\n$$\\sum_{s=1}^{\\infty}sp^{s-1}=\\frac{\\mathrm{d}}{\\mathrm{d}p}\\sum_{s=0}^{\\infty}p^s=\\frac{\\mathrm{d}}{\\mathrm{d}p}\\frac{1}{1-p}=(1-p)^{-2}~,\\eqno(2.7)$$\nwhich gives\n$$\\sum_{s=1}^{\\infty}sn(s,\\, p)=(1-p)^2\\,p\\sum_{s=1}^{\\infty}sp^{s-1}=(1-p)^2\\,p\\,(1-p)^{-2}=p~.\\eqno(2.8)$$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            546,
            520,
            575
          ],
          "text": "Since $P=0$ when $p<0$ we see that the probability is normalized. We can use\nsimilar tricks to calculate moments of any order.",
          "reading_order": 4
        },
        {
          "label": "sec",
          "bbox": [
            72,
            609,
            327,
            627
          ],
          "text": "Measuring the Cluster Number Density",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            645,
            520,
            737
          ],
          "text": "In order to gain further insight into the distribution of cluster sizes, let us study\nFig. 2.1 in more detail. There are 3 clusters of size $s=1$ , one cluster of size $s=2$ ,\nand one cluster of size $s=4$ . We could therefore introduce a histogram of cluster\nsizes, which is what we would do if we studied the cluster distribution numerically.\nLet us write $N_s$ as the number of clusters of size $s$ so that $N_1=3$ , $N_2=1$ , $N_3=0$\nand $N_4=1$ .",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            741,
            520,
            806
          ],
          "text": "How can we estimate $sn(s,p)$ , the probability for a given site to be part of a\ncluster of size $s$ , from $N_{s}$ ? The probability for a site to belong to cluster of size\n$s$ can be estimated by the number of sites belonging to a cluster of size $s$ divided\nby the total number of sites. The number of sites belonging to a cluster of size $s$",
          "reading_order": 7
        }
      ]
    },
    {
      "page_number": 31,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            210,
            62
          ],
          "text": "2.2 Cluster Number Density",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            502,
            44,
            512,
            58
          ],
          "text": "2",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            268
          ],
          "text": "is $sN_{s}$ , and the total number of sites is $L^d$ , where $L$ is the system size and $d$ is\nthe dimensionality. (Here, $d=1$ ). This means that we can estimate the probability\n$sn(s,\\,p)$ from\n$$\\overline{sn(s,\\,p)}=\\frac{sN_{s}}{L^d}~,$$\nwhere we use a bar to show that this is an estimated quantity and not the actual\nprobability. We divide by $s$ on both sides, and find\n$$\\overline{n(s,\\,p)}=\\frac{N_{s}}{L^d}~.$$",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            277,
            520,
            341
          ],
          "text": "This argument and the result are valid in any dimension, not only for $d=1$ . We\ncan also see why this quantity is called the cluster number density: it is the number\nof clusters divided by the volume measured in number of sites. We have therefore\nfound a method to estimate the cluster number density:",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            88,
            376,
            502,
            474
          ],
          "text": "Measuring the Cluster Number Density We can measure $n(s,p)$ in a\nsimulation by measuring $N_{s}$ , the number of clusters of size $s$ , and then\ncalculate $n(s,\\, p)$ from\n$$\\overline{n(s,\\,p)}=\\frac{N_{s}}{L^d}\\;.\\eqno(2.11)$$",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            80,
            510,
            520,
            716
          ],
          "text": "$$\\begin{aligned}\n& \\text { For the clusters in Fig. 2.1 we find that } \\\\\n& \\qquad \\overline{n(1, p)}=\\frac{N_{1}}{L^{1}}=\\frac{3}{16}, \\\\\n& \\qquad \\overline{n(2, p)}=\\frac{N_{2}}{L^{1}}=\\frac{1}{16}, \\\\\n& \\qquad \\overline{n(3, p)}=\\frac{N_{3}}{L^{1}}=\\frac{0}{16}, \\\\\n& \\qquad \\overline{n(4, p)}=\\frac{N_{4}}{L^{1}}=\\frac{1}{16},\n\\end{aligned}\\qquad\\qquad\\qquad\\qquad(2.12)$$",
          "reading_order": 5
        }
      ]
    },
    {
      "page_number": 32,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            80,
            58
          ],
          "text": "2",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            358,
            44,
            520,
            62
          ],
          "text": "2 One-Dimensional Percolation",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            224
          ],
          "text": "which is our estimate of $n(s,\\,p)$ based on this single realization. We check the\nconsistency of the result by ensuring that the estimated probabilities also are\nnormalized:\n$$\\sum_{s}\\overline{sn(s,\\,p)}=1\\cdot\\frac{3}{16}+2\\cdot\\frac{1}{16}+3\\cdot0+4\\cdot\\frac{1}{16}=\\frac{9}{16}=\\overline{p}\\;,\\eqno(2.16)$$\nwhere $\\overline{p}$ is estimated from the number of present sites divided by the total number\nof sites.",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            224,
            520,
            340
          ],
          "text": "In order to produce good statistical estimates for $n(s,\\,p)$ , we must sample from\nmany random realization of the system. If we sample from $M$ realizations, and\nthen measure the total number of clusters of size $s$ , $N_{s}(M)$ , summed over all the\nrealizations, we estimate the cluster number density from\n$$\n\\overline{n(s,\\, p)}=\\frac{N_{s}(M)}{M L^{d}}\\;.\\eqno(2.17)\n$$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            349,
            520,
            412
          ],
          "text": "Notice that all simulations are for finite $L$ , and we would therefore expect deviations\ndue to a finite $L$ as well as due to the finite number of samples. However, we expect\nthe estimated $\\overline{n(s,~p; L)}$ to approach the underlying $n(s,~p)$ as $M$ and $L$ approaches\ninfinity.",
          "reading_order": 4
        },
        {
          "label": "sec",
          "bbox": [
            72,
            445,
            315,
            460
          ],
          "text": "Shape of the Cluster Number Density",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            480,
            520,
            528
          ],
          "text": "We found that the cluster number density in one dimension is\n\\[n(s,p)=(1-p)^2 p^s~.\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:fondr_def_tractiff}\\]",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            537,
            520,
            797
          ],
          "text": "In Fig. 2.2 we have plotted n(s, p) for various values of p. In order to compare the\ns-dependence of the plot directly for various p-values we plot\n\\begin{equation}\nG(s)=(1-p)^2\\,n(s,\\,p)=p^s~,\n\\end{equation} as a function of s. We notice that $(1-p)^2n(s,\\,p)$ is approximately constant for a\nwide range of s and then falls off rapidly for some characteristic value sξ which\nincreases as p approaches p c = 1. We can understand this behavior better by\nrewriting n(s, p) as\n\\begin{equation}\nn(s,\\,p)=(1-p)^2e^{s\\ln p}=(1-p)^2e^{-s/s_\\xi}~,\n\\end{equation} where we have introduced the cut-off cluster size\n\\begin{equation}\ns_\\xi=-\\frac{1}{\\ln p}~.\n\\end{equation}",
          "reading_order": 7
        }
      ]
    },
    {
      "page_number": 33,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            210,
            62
          ],
          "text": "2.2 Cluster Number Density",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            509,
            44,
            520,
            58
          ],
          "text": "23",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_033_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_033_figure_002.png",
          "bbox": [
            72,
            80,
            528,
            439
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            448,
            520,
            503
          ],
          "text": "Fig. 2.2 (Top) A plot of $n(s,\\,p)(1-p)^2$ as a function of $s$ for various values of $p$ for a one-\ndimensional percolation system shows that the cut-off increases as a function of $s$ . (Bottom) When\nthe $s$ axis is rescaled by $s_{\\xi}$ to $s/s_{\\xi}$ , all the curves fall onto a common scaling function, that is,\n$n(s,\\,p)=(1-p)^2F(s/s_{\\xi})$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            535,
            520,
            582
          ],
          "text": "What we are seeing in Fig. 2.2 is therefore the exponential cut-off curve, where the\ncut-off $s_\\xi(p)$ increases as $p\\to1$ . We call it a cut-off because the value of $n(s,\\, p)$\ndecays very rapidly (exponentially fast) when $s$ is larger than $s_\\xi$ .",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            582,
            520,
            743
          ],
          "text": "How does $s_\\xi$ depend on $p$ ?. We see from ( 2.21 ) that as $p$ approaches $p_c=1$ ,\nthe characteristic cluster size $s_\\xi$ will diverge. The form of the divergence can be\ndetermined in more detail through a Taylor expansion:\n$$ s_\\xi =-\\frac{1}{\\ln p} \\eqno(2.22)$$\nwhen $p$ is close to $1$ , we see that $1-p\\ll 1$ and we can write\n$$ \\ln p=\\ln(1-(1-p))\\simeq -(1-p)~, \\eqno(2.23)$$",
          "reading_order": 5
        }
      ]
    },
    {
      "page_number": 34,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            83,
            58
          ],
          "text": "24",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            358,
            44,
            520,
            62
          ],
          "text": "2 One-Dimensional Percolation",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            528,
            179
          ],
          "text": "where we have used that $\\ln(1-x)=-x+{\\cal O}(x^2)$ , which is simply the Taylor\nexpansion of the logarithm, where ${\\cal O}(x^2)$ is term that is on the order of $x^2$ . As a\nresult\n$$s_\\xi\\simeq \\frac{1}{1-p}=\\frac{1}{p_c-p}=|p-p_c|^{-1}~.$$",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            188,
            511,
            224
          ],
          "text": "This shows that the divergence of $s_\\xi$ as $p$ approaches $p_c$ is a power-law with\nexponent $-1$ . This power-law behavior is general in percolation theory:",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            88,
            258,
            502,
            354
          ],
          "text": "Scaling Behavior of the Characteristic Cluster Size The characteristic\ncluster size $s_\\xi$ diverges as\n$$ s_\\xi \\propto |p-p_c|^{-1/\\sigma}~, \\eqno(2.25)$$\nwhen $p\\rightarrow p_c$ . In one dimension, $\\sigma=1$ .",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            394,
            520,
            443
          ],
          "text": "The value of the exponent $\\sigma$ depends on the lattice dimensionality, but it does\nnot depend on the details of the lattice. It would, for example, be the same also for\nnext-nearest neighbor connectivity.",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            446,
            520,
            779
          ],
          "text": "The functional form we have found is also an example of a data collapse . We\nsee that if we plot $(1-p)^{-2}n(s,\\, p)$ as a function of $s/s_\\xi$ , all data-points for various\nvalues of $p$ should fall onto a single curve:\n$$ n(s,\\, p)=(1-p)^2 e^{-s/s_\\xi}\\;\\Rightarrow\\; (1-p)^{-2}n(s,\\, p)=e^{-s/s_\\xi}\\;\\,,\\eqno(2.26)$$\nas illustrated in Fig. 2.2 . We call this a data-collapse. We have one behavior for small\n$s$ and then a rapid cut-off when $s$ reaches $s_\\xi$ . We can rewrite $n(s,\\, p)$ so that all the\n$s_\\xi$ dependence is in the cut-off function by realizing that since $s_\\xi\\simeq (1-p)^{-1}$ we\nhave that $(1-p)^2=s_\\xi^{-2}$ . This gives\n$$ n(s,\\, p)=s_\\xi^{-2}e^{-s/s_\\xi}=s^{-2}\\left(\\frac{s}{s_\\xi}\\right)^2 e^{-s/s_\\xi}=s^{-2}F\\left(\\frac{s}{s_\\xi}\\right)\\;.\\eqno(2.27)$$\nwhere $F(u)=u^2e^{-u}$ . We will see later that this form for $n(s,\\, p)$ is general — it is\nvalid for percolation in any dimension, although with other values for the exponent\n$-2$ and other shapes of the cut-off function $F(u)$ . In percolation theory, we call this\nexponent $\\tau$ :\n$$n(s,\\, p)=s^{-\\tau} F(s/s_\\xi)\\;,\\eqno(2.28)$$",
          "reading_order": 6
        }
      ]
    },
    {
      "page_number": 35,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            210,
            62
          ],
          "text": "2.2 Cluster Number Density",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            509,
            44,
            520,
            58
          ],
          "text": "25",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            128
          ],
          "text": "where $\\tau=2$ in two dimensions. The exponent $\\tau$ is another example of a universal\nexponent that does not depend on details such as the connectivity rule, while it\ndepends on the dimensionality of the system.",
          "reading_order": 2
        },
        {
          "label": "sec",
          "bbox": [
            72,
            161,
            439,
            179
          ],
          "text": "Numerical Measurement of the Cluster Number Density",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            196,
            520,
            349
          ],
          "text": "Let us now test the measurement method and the theory through a numerical study\nof the cluster number density. According to the theory developed above we can\nestimate the cluster number density $n(s,\\,p)$ from\n$$\\overline{n(s,\\, p)}=\\frac{N_s(M)}{L^2\\, M}\\;,\\eqno(2.29)$$\nwhere $N_s(M)$ is the number of clusters of size $s$ measured in $M$ realizations of the\npercolation system. We generate a one-dimensional percolation system and index\nthe clusters using",
          "reading_order": 4
        },
        {
          "label": "code",
          "bbox": [
            79,
            358,
            340,
            456
          ],
          "text": "import numpy as np\nfrom scipy.ndimage import measurements\nL = 20\np = 0.90\nz = np.random.rand(L)\nm = z<p\nlw, num = measurements.label(m)",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            465,
            520,
            495
          ],
          "text": "Now, lw contains the indices for all the clusters. We can extract the size of the\nclusters by summing the number of elements for each label:",
          "reading_order": 6
        },
        {
          "label": "code",
          "bbox": [
            80,
            509,
            358,
            532
          ],
          "text": "labelList = np.arange(lw.max() + 1)\narea = measurements.sum(m, lw, labelList)",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            545,
            304,
            558
          ],
          "text": "The resulting list of areas for one sample is",
          "reading_order": 8
        },
        {
          "label": "code",
          "bbox": [
            80,
            572,
            493,
            636
          ],
          "text": ">> lw\narray([1, 1, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 3, 0, 4, 4,\n4, 4], dtype=int32)\n>> area\narray([0., 3., 9., 1., 4.])",
          "reading_order": 9
        },
        {
          "label": "para",
          "bbox": [
            72,
            645,
            520,
            707
          ],
          "text": "We need to collect all the areas of all the clusters for many realizations, and then\ncalculate the number of clusters of each size s based on this long list of areas. This\nis all brought together by continuously appending the area-array to the end of an\narray allarea that contains the areas of all the clusters.",
          "reading_order": 10
        },
        {
          "label": "code",
          "bbox": [
            79,
            724,
            340,
            801
          ],
          "text": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.ndimage import measurements\nnsamp = 1000\nL = 1000\np = 0.90",
          "reading_order": 11
        }
      ]
    },
    {
      "page_number": 36,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            84,
            62
          ],
          "text": "26",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            358,
            44,
            520,
            62
          ],
          "text": "2 One-Dimensional Percolation",
          "reading_order": 1
        },
        {
          "label": "code",
          "bbox": [
            79,
            80,
            448,
            296
          ],
          "text": "allarea = np.array([])\nfor i in range(nsamp):\nz = np.random.rand(L)\nm = z<p\nlw, num = measurements.label(m)\nlabelList = np.arange(lw.max() + 1)\narea = measurements.sum(m, lw, labelList)\nallarea = np.append(allarea,area)\nn,sbins = np.histogram(allarea,bins=int(max(allarea)))\ns = 0.5*(sbins[1:]+sbins[:-1])\nnsp = n/(L*nsamp)\nsxi = -1.0/np.log(p)\nnsptheory = (1-p)**2*np.exp(-s/sxi)\nplt.plot(s,nsp,’o’,s,nsptheory,’-’)\nplt.xlabel(’$s$’)\nplt.ylabel(’$n(s,p)$’)",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            304,
            520,
            340
          ],
          "text": "This script also calculates $N_{s}\\,$ using the histogram function with $L\\,$ bins to\nensure that there is at least one bin for each value of $s\\!\\!:$",
          "reading_order": 3
        },
        {
          "label": "code",
          "bbox": [
            80,
            349,
            448,
            376
          ],
          "text": "n,sbins = np.histogram(allarea,bins=int(max(allarea)))\ns = 0.5*(sbins[1:]+sbins[:-1])",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            385,
            520,
            417
          ],
          "text": "where we find $s$ as the midpoints of the bins returned by the histogram-function.\nWe estimate $\\overline{n(s,p)}$ from",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            80,
            430,
            197,
            441
          ],
          "text": "nsp = n/(L*nsamp)",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            448,
            520,
            501
          ],
          "text": "For comparison with theory, we calculate values from the theoretically predicted\nexpression $n(s,\\,p)$ , which is $n(s,\\,p)=(1-\\,p)^2\\exp(-s/s_{\\xi})$ , where $s_{\\xi}=-1/\\ln p$ .\nThis is calculated for the same values of $s$ as used for the histogram using:",
          "reading_order": 7
        },
        {
          "label": "code",
          "bbox": [
            80,
            510,
            322,
            537
          ],
          "text": "sxi = -1.0/np.log(p)\nnsptheory = (1-p)**2*np.exp(-s/sxi)",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            72,
            546,
            520,
            609
          ],
          "text": "When we use the histogram-function with many bins, we risk that many of the\nbins contain zero elements. To remove these elements from the plot, we can use the\nnonzero function from numpy to find the indices of the elements of n that are\nnon-zero:",
          "reading_order": 9
        },
        {
          "label": "para",
          "bbox": [
            80,
            624,
            197,
            636
          ],
          "text": "i = np.nonzero(n)",
          "reading_order": 10
        },
        {
          "label": "para",
          "bbox": [
            72,
            645,
            520,
            693
          ],
          "text": "And then we only plot the values of $\\overline{n(s,p)}$ at these indices. The values for the\ntheoretical $n(s,p)$ are calculated for all values of $s$ , and the two are plotted in the\nsame plot:",
          "reading_order": 11
        },
        {
          "label": "para",
          "bbox": [
            79,
            707,
            358,
            718
          ],
          "text": "plt.plot(s[i],nsp[i],’o’,s,nsptheory,’-’)",
          "reading_order": 12
        },
        {
          "label": "para",
          "bbox": [
            72,
            725,
            520,
            792
          ],
          "text": "The resulting plot is shown in Fig. 2.3 . We see that the measured results and the\ntheoretical values fit nicely, even though the theory is for an infinite system size, and\nthe simulations where performed at $L=1000$ . We also see that for larger values of\n$s$ there are fewer observed values. It may therefore be a good idea to make the bins",
          "reading_order": 13
        }
      ]
    },
    {
      "page_number": 37,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            210,
            62
          ],
          "text": "2.2 Cluster Number Density",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            502,
            44,
            520,
            62
          ],
          "text": "27",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            439,
            520,
            474
          ],
          "text": "used for the histogram larger for larger values of $s$ . We will return to this when we\nmeasure the cluster number density in two-dimensional systems in Chap. 4 .",
          "reading_order": 2
        },
        {
          "label": "sec",
          "bbox": [
            72,
            501,
            206,
            522
          ],
          "text": "Average Cluster size",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            537,
            520,
            636
          ],
          "text": "Since we have an exact expression for the cluster number density, $n(s,\\ p)$ we can use\nit to calculate the average cluster size. However, what do we mean by the average\ncluster size in this case? In percolation theory it is common to define the average\ncluster size as the average size of a cluster connected to a given (random) site in\nour system. That is, we will use the cluster number density, $n(s,\\ p)$ , as the basic\ndistribution for calculating the moments.",
          "reading_order": 4
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_037_figure_005.png)",
          "figure_path": "figures/percolation_studies_page_037_figure_005.png",
          "bbox": [
            89,
            80,
            475,
            358
          ],
          "reading_order": 5
        },
        {
          "label": "cap",
          "bbox": [
            72,
            374,
            520,
            412
          ],
          "text": "Fig. 2.3 Plot of the predicted $n(s,\\,p)$ , based on $M=1000$ samples of a $L=1000$ system with\n$p=0.9$ , and the theoretical $n(s,\\,p)$ curve on a linear scale (top) and a semilogarithmic scale\n(bottom). The semilogarithmic plot shows that $\\overline{n(s,\\,p)}$ follows an exponential curve",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            80,
            663,
            511,
            743
          ],
          "text": "$$\\begin{gathered}\n\\text { Average Cluster Size The average cluster size } S(p) \\text { is defined as } \\\\\nS(p)=\\langle s\\rangle=\\sum_{s} s\\left(\\frac{s n(s, p)}{\\sum_{s} s n(s, p)}\\right),\n\\end{gathered}\\qquad\\qquad(2.30)$$",
          "reading_order": 7
        }
      ]
    },
    {
      "page_number": 38,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            81,
            58
          ],
          "text": "28",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            358,
            44,
            512,
            62
          ],
          "text": "2 One-Dimensional Percolation",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            170
          ],
          "text": "The normalization sum in the denominator is equal to $p$ when $p<p_c$ . In this\ncase, we can therefore write this as\n\\[S(p)=\\sum_{s} s\\left(\\frac{sn(s, p)}{p}\\right)~.\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:nondefound}\\]",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            179,
            520,
            423
          ],
          "text": "We can calculate the average cluster size from:\n\\begin{align}\nS &=\\frac{1}{p}\\sum_s s^2n(s,\\, p)=\\frac{(1-p)^2}{p}\\sum_s s^2p^s\\\\\n&=\\frac{(1-p)^2}{p}\\sum_s p\\frac{\\mathrm{d}}{\\mathrm{d}p}p\\frac{\\mathrm{d}}{\\mathrm{d}p}p^s=\\frac{(1-p)^2}{p}p\\frac{\\mathrm{d}}{\\mathrm{d}p}p\\frac{\\mathrm{d}}{\\mathrm{d}p}\\sum_s p^s\\\\\n&=\\frac{(1-p)^2}{p}p\\frac{\\mathrm{d}}{\\mathrm{d}p}p\\frac{\\mathrm{d}}{\\mathrm{d}p}\\frac{1}{1-p}=(1-p)^2\\frac{\\mathrm{d}}{\\mathrm{d}p}\\frac{p}{(1-p)^2}\\\\\n&=(1-p)^2(\\frac{1}{(1-p)^2}+\\frac{2p}{(1-p)^3})=\\frac{1+p}{1-p}~,\n\\end{align}",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            429,
            520,
            564
          ],
          "text": "This shows that we can write\n\\[S=\\frac{1+p}{1-p}=\\frac{\\varGamma}{|p-p_c|^\\gamma}~,\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:thm:lorenz2019first}\\]\nwith $\\gamma=1$ and $\\varGamma(p)=1+p$ . That is, the average cluster size, $S$ , also diverges as\na power-law when $p$ approaches $p_c$ . The exponent $\\gamma=1$ of the power-law is again\nuniversal. That is, it depends on features such as dimensionality, but not on details\nsuch as the lattice structure.",
          "reading_order": 4
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            591,
            238,
            611
          ],
          "text": "2.3 Spanning Cluster",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            627,
            518,
            689
          ],
          "text": "The density of the spanning cluster, $P(p;L)$ , can be found using similar approaches.\nThe spanning cluster only exists for $p\\geq p_c$ . The discussion for $P(p;L)$ is therefore\nnot that interesting for the one-dimensional case. However, we can still introduce\nsome of the general notions.",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            88,
            689,
            403,
            761
          ],
          "text": "The behavior of $P(p;\\infty )$ for $L\\to \\infty $ in one dimension is\n$$P(p;\\infty )={\\left\\{\\begin{array}{l}0\\text{ when }p<1\\\\1\\text{ when }p=1\\end{array}\\right..}.$$",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            770,
            520,
            806
          ],
          "text": "What is the relation between $P(p;L)$ and the distribution of cluster sizes? The\ndistribution of the sizes of finite clusters is described by $sn(s,p)$ , which is the",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 39,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            179,
            62
          ],
          "text": "2.4 Correlation Lengt",
          "reading_order": 0
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            287
          ],
          "text": "probability that a given site belongs to a cluster of size $s$ . If we look at a given\nsite, that site is occupied with probability $p$ . If a site is occupied it is either part of\na finite cluster of size $s$ or it is part of the spanning cluster. Since these two events\ncannot occur at the same time, the probability for a site to be occupied must be the\nsum of the probability to belong to a finite cluster and the probability to belong to\nthe infinite cluster. The probability to belong to a finite cluster is the sum of the\nprobabilities to belong to a cluster of $s$ for all $s$ . We therefore have the equality:\n\\[ p=P(p;L)+\\sum_{s}sn(s,p;L)~,\\eqno(2.38)\\]\nwhich is valid for percolation in any dimension, since we have not assumed anything\nabout the dimensionality in this argument.",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            287,
            520,
            367
          ],
          "text": "We can use this relation to find the density of the spanning cluster from the cluster\nnumber density $n(s,\\ p)$ through\n$$P(p)=p-\\sum_{s}sn(s,\\ p)\\ .\\qquad\\qquad\\qquad\\qquad(2.39)$$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            384,
            513,
            414
          ],
          "text": "This illustrates that the cluster number density $n(s,\\,p)$ is a fundamental property\nwhich can be used to deduce many aspects of the percolation system.",
          "reading_order": 4
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            447,
            251,
            462
          ],
          "text": "2.4 Correlation Length",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            481,
            518,
            555
          ],
          "text": "From $p\\to p_c$ the simulations in Fig. 1.4 we see that the size of the clusters increases as . We expect a similar behavior for the one-dimensional system. We have already\nseen cluster that size the $s_{\\xi}$ mass characterizes mass (or area) the class (or areas) diverges of a cluster. How as $p\\to p_c$ can The we characteristic characterize\nthe extent of a cluster?",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            562,
            520,
            609
          ],
          "text": "To characterize the linear extent of a cluster, we find the probability for two\nsites at a distance $r$ to belong to the same cluster. This probability is called the\ncorrelation function , $g(r)$ :",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            88,
            644,
            502,
            689
          ],
          "text": "Correlation Function The correlation function $g(r)$ describes the conditional\nprobability that two sites $a$ and $b$ , which both are occupied and are separated\nby a distance $r$ , belong to the same cluster.",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            72,
            733,
            520,
            779
          ],
          "text": "For one-dimensional percolation, two sites $a$ and $b$ are part of the same cluster if\nand only if all the points in between $a$ and $b$ are occupied. If $r$ denotes the number\nof points between $a$ and $b$ (not counting the start and end positions) as illustrated in",
          "reading_order": 9
        }
      ]
    },
    {
      "page_number": 40,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            84,
            62
          ],
          "text": "30",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            358,
            44,
            520,
            62
          ],
          "text": "2 One-Dimensional Percolation",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_040_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_040_figure_002.png",
          "bbox": [
            71,
            80,
            528,
            161
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            177,
            520,
            201
          ],
          "text": "Fig. 2.4 An illustration of the distance $r$ between two sites $a$ and $b$ . The two sites $a$ and $b$ are\nconnected if and only if all the sites between $a$ and $b$ are occupied",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            232,
            520,
            376
          ],
          "text": "Fig. 2.4 , we find that the correlation function is\n\\[g(r)=p^{r}=e^{-r/\\xi}~,\\eqno(2.40)\\]\nwhere $\\xi=-\\frac{1}{\\ln p}$ is called the correlation length. The correlation length diverges\nas $p\\rightarrow p_c=1$ . We can again find the way in which it diverges from a Taylor\nexpansion in $(1-p)$ when $p\\rightarrow 1$\n\\[\\ln p=\\ln(1-(1-p))\\simeq-(1-p)~.\\eqno(2.41)\\]",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            394,
            520,
            504
          ],
          "text": "We find that the correlation length is\n\\[ \\xi=\\xi_0(p_c-p)^{-v}~,\\tag*{2.42}\\]\nwith $p\\to p_c=1$ $v=1$ . The correlation length therefore diverges as a power-law when . This behavior is general for percolation theory, although the particular value\nof the exponent $v$ depends on the dimensionality.",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            504,
            520,
            601
          ],
          "text": "We can use the correlation function to strengthen our interpretation of when a\nfinite system size becomes relevant. As long as $\\xi \\ll L$ , we will not notice the effect\nof a finite system, because no cluster is large enough to notice the finite system size.\nHowever, when $\\xi \\gg L$ , the behavior is dominated by the system size $L$ , and we are\nno longer able to determine how close we are to percolation. We will address these\narguments in more detail in Chap. 5 .",
          "reading_order": 6
        },
        {
          "label": "sec",
          "bbox": [
            72,
            634,
            135,
            646
          ],
          "text": "Exercises",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            663,
            520,
            716
          ],
          "text": "Exercise 2.1 (Next-Nearest Neighbor Connectivity in 1d) Assume that connec­\ntivity is to the next­nearest neighbors for an infinite one­dimensional percolation\nsystem.",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            72,
            733,
            304,
            746
          ],
          "text": "(a) Find $\\Pi (p,L)$ for a system of length $L$.",
          "reading_order": 9
        },
        {
          "label": "para",
          "bbox": [
            71,
            749,
            234,
            762
          ],
          "text": "(b) What is $p_c$ for this system",
          "reading_order": 10
        },
        {
          "label": "para",
          "bbox": [
            72,
            762,
            280,
            779
          ],
          "text": "(c) Find $n(s, p)$ for an infinite system.",
          "reading_order": 11
        }
      ]
    },
    {
      "page_number": 41,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            108,
            58
          ],
          "text": "Exercise",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            502,
            44,
            512,
            62
          ],
          "text": "3",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            528,
            152
          ],
          "text": "Exercise 2.2 (Higher Moments of s) The k'th moment of s is defined as\n\\[\n    \\langle s^k \\rangle = \\sum_s s^k (\\frac{sn(s,p)}{p})~.~\\eqno(2.43)\n  \\]",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            161,
            349,
            179
          ],
          "text": "(a) Find the second moment of $s$ as a function of $p$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            71,
            179,
            520,
            226
          ],
          "text": "(b) Calculate the first moment of $s$ numerically from $M=1000$ samples for $p=0.90, 0.95, 0.975$ and $0.99$ . Compare with the theoretical result.\n(c) Calculate the second moment of $s$ numerically from $M=1000$ samples for",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            226,
            520,
            242
          ],
          "text": "$p=0.90,0.95,0.975$ and 0.99 . Compare with the theoretical result.",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            636,
            520,
            701
          ],
          "text": "Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0\nInternational License ( http://creativecommons.org/licenses/by/4.0/ ), which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as long as you give appropriate\ncredit to the original author(s) and the source, provide a link to the Creative Commons license and\nindicate if changes were made.",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            701,
            520,
            770
          ],
          "text": "The images or other third party material in this chapter are included in the chapter’s Creative\nCommons license, unless indicated otherwise in a credit line to the material. If material is not\nincluded in the chapter’s Creative Commons license and your intended use is not permitted by\nstatutory regulation or exceeds the permitted use, you will need to obtain permission directly from\nthe copyright holder.",
          "reading_order": 7
        }
      ]
    },
    {
      "page_number": 42,
      "elements": [
        {
          "label": "title",
          "bbox": [
            72,
            98,
            376,
            116
          ],
          "text": "Infinite-Dimensional Percolation",
          "reading_order": 0
        },
        {
          "label": "para",
          "bbox": [
            528,
            107,
            546,
            134
          ],
          "text": "5",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            304,
            520,
            435
          ],
          "text": "In this chapter we address the percolation problem on an infinite-dimensional lattice\nwithout loops. In this case, it is possible to calculate several of the properties of\nthe percolation system analytically. This allows us to develop a general theory and\nto develop concepts to be used for finite-dimensional systems. We introduce the\ninfinite-dimensional Bethe lattice for a given coordination number. We find an exact\nsolution for $P$ and the average cluster size $S$ , and use a Taylor-expansion to find an\nexpression for $n(s,\\,p)$ . The methods and functional forms for $n(s,\\,p)$ we introduce\nhere, are used to interpret results in finite dimensions.",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            438,
            520,
            595
          ],
          "text": "We have now seen how the percolation problem can be solved exactly for a one-\ndimensional system. However, in this case the percolation threshold is $p_c=1$ ,\nand we were not able to address the behavior of the system for $p>p_c$ . There is,\nhowever, another system in which many features of the percolation problem can be\nsolved exactly. This is percolation on a regular tree structure on which there are no\nloops. The condition of no loops is essential. This is also why we call this system\na system of infinite dimensions, because we need an infinite number of dimensions\nin Euclidean space in order to embed a tree without loops. In this section, we will\nprovide an explicit solution to the percolation problem on a particular tree structure\ncalled the Bethe lattice [ 5 ] .",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            600,
            520,
            663
          ],
          "text": "The Bethe lattice, which is also called the Cayley tree, is a tree structure in which\neach node has $Z$ neighbors. This structure has no loops. If we start from the central\npoint and draw the lattice, the perimeter grows as fast as the bulk. Generally, we will\ncall $Z$ the coordination number. The Bethe lattice is illustrated in Fig. 3.1 .",
          "reading_order": 4
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            689,
            270,
            707
          ],
          "text": "3.1 Percolation Threshold",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            725,
            520,
            774
          ],
          "text": "If we start from the center in Fig. 3.1 and move along a branch, we find $(Z-1)$ new\nneighbors from each of the branches. To get a spanning cluster, we need to ensure\nthat at least one of the $Z-1$ sites are occupied on average. That is, the occupation",
          "reading_order": 6
        },
        {
          "label": "foot",
          "bbox": [
            72,
            806,
            396,
            845
          ],
          "text": "© The Author(s) 2024\nA. Malthe-Sørenssen, Percolation Theory Using Python, Lecture Notes\nin Physics 1029, https://doi.org/10.1007/978-3-031-59900-2_3",
          "reading_order": 7
        },
        {
          "label": "foot",
          "bbox": [
            506,
            806,
            520,
            816
          ],
          "text": "33",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 43,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            83,
            58
          ],
          "text": "34",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            349,
            44,
            512,
            62
          ],
          "text": "3 Infinite-Dimensional Percolation",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_043_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_043_figure_002.png",
          "bbox": [
            72,
            80,
            520,
            277
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            294,
            520,
            331
          ],
          "text": "Fig. 3.1 Four generations of the Bethe lattice with coordination number $Z=3$ . ( a ) Illustration of\na two-dimensional embedding of the lattice. ( b ) Illustration of how a central node is connected to\nthree branches",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            358,
            197,
            376
          ],
          "text": "probability, $p$, must be:",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            393,
            340,
            439
          ],
          "text": "$p(Z-1)\\geq 1$,\nin order for this process to continue indefinitely.",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            439,
            520,
            519
          ],
          "text": "We associate $p_c$ with the value for $p$ where the cluster is on the verge of dying\nout, that is\n\\[ p_c=\\frac{1}{Z-1}~.\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:defnocounter2}\\]",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            528,
            520,
            594
          ],
          "text": "For $Z=2$ we regain the one-dimensional system, with percolation threshold $p_c=1$ . However, when $Z>2$ , we obtain a finite percolation threshold, that is, $p_c<1$ ,\nwhich means that we can observe the behavior both above and below $p_c$ .\nIn the following, we will demonstrate how we can find the density of the spanning",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            594,
            520,
            627
          ],
          "text": "cluster, $P(p)$, and the average cluster size $S$, before we address the scaling behavior\nof the cluster number density $n(s,\\, p)$.",
          "reading_order": 8
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            660,
            238,
            675
          ],
          "text": "3.2 Spanning Cluster",
          "reading_order": 9
        },
        {
          "label": "para",
          "bbox": [
            72,
            689,
            520,
            739
          ],
          "text": "We will use a standard trick to find the density $P(p)$ of the spanning cluster when\n$p>\\ p_c$ . The technique is based on starting from a “ central ” site, and then address\nthe probability that a given branch is connected to infinity.",
          "reading_order": 10
        },
        {
          "label": "para",
          "bbox": [
            72,
            752,
            520,
            806
          ],
          "text": "We P to n(s, p) We start by noting that $P$ is the probability for a site to be\nconnected to the spanning cluster. If a site is present, which has a probability $p$ , it\nmust either belong to the infinite cluster with probability $P$ or to one of the finite",
          "reading_order": 11
        }
      ]
    },
    {
      "page_number": 44,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            179,
            62
          ],
          "text": "3.2 Spanning Cluster",
          "reading_order": 0
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            144
          ],
          "text": "clusters with probability $\\sum_{s} sn(s,p)$. This means that\n$$p=P+\\sum_{s} sn(s,p),\\qquad(3.3)$$",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            161,
            520,
            225
          ],
          "text": "The sum $\\sum_s sn(s,p)$ is the probability that the site is part of a finite cluster,\nwhich means that it is not connected to infinity. We introduce $Q(p)$ to denote the\nprobability that a branch does not lead to infinity. The concept of a central point and\na branch is illustrated in Fig. 3.1 .",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            241,
            520,
            370
          ],
          "text": "Deriving an Equation for Q ( p ) If the probability that a site is not connected\nto infinity in a particular direction is $Q$ , then the probability that the site is\nnot connected to infinity in any direction is $Q^Z$ . The probability that the site is\nconnected to infinity is therefore $1-Q^Z$ . In addition, we need to include the\nprobability $p$ that the site is occupied. The probability that a given site is connected\nto infinity, that is, that it is part of the spanning cluster, is therefore\n\\[P=p(1-Q^Z)~.\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:q2}\\]",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            385,
            520,
            537
          ],
          "text": "Now, we need to find an expression for $Q(p)$ . We will determine $Q$ through a\nconsistency equation. Let us assume that we are moving along a branch, and that\nwe have come to a point $k$ . Then, $Q$ gives the probability that this branch does\nnot lead to infinity. This can occur either if site $k$ is not occupied, which has a\nprobability ( $1-p$ ), or if site $k$ is occupied, which has probability $p$ , and all of the\n$Z-1$ branches that lead out of $k$ are not connected to infinity, which has probability\n$Q^{Z-1}$ . The probability $Q$ for the branch not to be connected to infinity is therefore\n\\[ Q=(1-p)+pQ^{Z-1}~. \\eqno(3.5)\\]",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            546,
            520,
            628
          ],
          "text": "We check this equation for the case $Z=2$ , which corresponds to a one-dimensional\nsystem. In this case we have $Q=1-p+p Q$ , which gives, $(1-p)Q=(1-p)$ ,\nwhere we see that when $p\\neq 1$ , $Q=1$ . That is, when $p<1$ all branches are not\nconnected to infinity, implying that there is no spanning cluster. We therefore regain\nthe results from one-dimensional percolation theory.",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            645,
            520,
            779
          ],
          "text": "Solving to Find Q ( p ) We could solve this equation for general $Z$ . However, for\nsimplicity we will restrict ourselves to $Z=3$ , which is the smallest $Z$ that gives a\nbehavior different from the one-dimensional system. We recall from ( 3.2 ) that for\n$Z=3$ , $p_c=1/2$ . We insert $Z=3$ in ( 3.5 ) , which gives\n\\begin{equation}\nQ=1-p+pQ^2~,\\\\\npQ^2-Q+1-p=0~.\n\\end{equation}",
          "reading_order": 7
        }
      ]
    },
    {
      "page_number": 45,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            83,
            58
          ],
          "text": "36",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            349,
            44,
            520,
            62
          ],
          "text": "3 Infinite-Dimensional Percolation",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            152
          ],
          "text": "The solution of this second order equation is\n$$Q=\\frac{+1 \\pm \\sqrt{1-4 p(1-p)}}{2 p}=\\frac{1 \\pm \\sqrt{(2 p-1)^{2}}}{2 p}=\\frac{1 \\pm|(2 p-1)|}{2 p} .\\qquad(3.8)$$",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            161,
            520,
            528
          ],
          "text": "First, we notice that for $(2p-1)=0$ , that is for $p=1/2$ (which is $p_c$ for $Z=3$ ),\nwe $p=p_c=1/2$ find that $Q=1/2p=1$ . Therefore, no branch propagates to infinity for . Second, for $(2p-1)<0$ , which corresponds to $p<1/2=p_c$ , we get\nthe solution\n\\[\nQ=\\frac{1\\pm(1-2p)}{2p}~,\\eqno(3.9)\n\\]\nwhich has two solutions: $Q=1$ or $Q=(1-p)/p$ . The second solution $(1-p)/p$\nis greater than $1$ when $p<1/2$ . We therefore conclude that for $p<1/2$ and for\n$p=1/2$ , no branch propagates to infinity. This means that there is no infinite cluster\n(no spanning cluster) for $p\\le 1/2=p_c$ . Third, for $(2p-1)>0$ , which corresponds\nto $p>1/2=p_c$ , we get the solution\n\\[\nQ=\\frac{1\\pm(2p-1)}{2p}~,\\eqno(3.10)\n\\]\nwhich has two solutions: $Q=1$ or $Q=(1-p)/p$ . The second solution is smaller\nthan $1$ when $p>1/2$ . This means that there is a finite probability for a branch\nto propagate to infinity and for there to be a spanning cluster. We have therefore\nfound that for $p\\le 1/2$ , there is no spanning cluster, but for $p>1/2$ there is a\nfinite probability for a spanning cluster. This finding confirms that $1/2$ indeed is the\npercolation threshold for this system.",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            537,
            520,
            627
          ],
          "text": "Finding $P(p)\\,$ We insert Q=(1 − p )/p back into the equation for P( p ) to find\nthe behavior of P( p ) for p>pc= 1/2:",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            636,
            520,
            755
          ],
          "text": "This result is illustrated in Fig. 3.2 . We notice that when $p\\to1$ , we have that\n$(1-p)/p\\to0$ . Therefore $P\\propto p$ in this limit. To address the behavior when\n$p\\to p_c=1/2$ , we use the identity $(1-a^3)=(1-a)(1+a+a^2)$ and that\n$1-(1-p)/p=2(p-1/2)$ to rewrite the expression in to become\n$$P=p(1-(\\frac{1-p}{p})^3)=p\\left(1-\\frac{1-p}{p}\\right)\\left(1+\\frac{1-p}{p}+\\left(\\frac{1-p}{p}\\right)^2\\right).\\eqno(3.12)$$",
          "reading_order": 5
        }
      ]
    },
    {
      "page_number": 46,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            179,
            62
          ],
          "text": "3.2 Spanning Cluster",
          "reading_order": 0
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_046_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_046_figure_002.png",
          "bbox": [
            72,
            80,
            520,
            439
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            454,
            520,
            505
          ],
          "text": "Fig. 3.2 (Top) A plot of P ( p ) as a function of p for the Bethe lattice with Z = 3 . The tangent\nat p = p c is illustrated by a straight line. (Bottom) A plot of the average cluster size, S ( p ) , as a\nfunction $p\\rightarrow p_c=1/2$ of p for the Bethe lattice with Z = 3 . The average cluster size diverges when both from below and above",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            537,
            520,
            609
          ],
          "text": "We can rewrite this as\n\\[P=2\\left(p-\\frac{1}{2}\\right)\\left(1+\\frac{1-p}{p}+\\left(\\frac{1-p}{p}\\right)^2\\right)~.\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:def_bound}\\]",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            618,
            520,
            761
          ],
          "text": "We Taylor expand the second term around $p=p_c=1/2$ :\n\\[\n    \\left(1+\\frac{1-p}{p}+\\left(\\frac{1-p}{p}\\right)^2\\right)\\simeq3+\\mathscr{O}(p-p_c)~,\\eqno(3.14)\n  \\]\nwhich when inserted back into ( 3.13 ) gives\n\\[\n    P\\simeq6(p-p_c)+\\mathscr{O}\\left((p-p_c)^2\\right)~.\\eqno(3.15)\n  \\]",
          "reading_order": 5
        }
      ]
    },
    {
      "page_number": 47,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            81,
            58
          ],
          "text": "38",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            349,
            44,
            520,
            62
          ],
          "text": "3 Infinite-Dimensional Percolation",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            528,
            241
          ],
          "text": "Since $p>p_c=1/2$ we are only interested in the leading term, we have found that for we can approximate $P(p)$ as:\n\\[ P(p) \\simeq B(p-p_c)^{\\beta}~,\\eqno(3.16)\\]\nwhere $B=6$ and the exponent $\\beta=1$ . The density of the spanning cluster, $P$ , is\ntherefore a power-law in $(p-p_c)$ with exponent $\\beta$ . In general, this exponent depends\non the dimensionality of the lattice, but it does not depend on lattice details, such as\nthe number of neighbors $Z$ . We will leave it as an exercise for the reader to show\nthat $\\beta$ is the same for $Z=4$ .",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            241,
            520,
            287
          ],
          "text": "The approach we have used here is often called a mean field solution or a self-\nconsistency solution: We assume that we know $Q$ , and then solve to find $Q$ . We will\nuse similar methods later.",
          "reading_order": 3
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            320,
            260,
            335
          ],
          "text": "3.3 Average Cluster Size",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            349,
            520,
            609
          ],
          "text": "We will use a similar method to find the average cluster size, $S(p)$ . We start by\ndefining $T(p)$ as the average number of sites connected to a given site on a specific\nbranch, such as in branch 1 in Fig. 3.1 . The average cluster size $S$ is then given as\n\\[ S=1+ZT~,\\eqno{(3.17)}\\]\nwhere the 1 represents the central point, $T$ is the average number of sites on each\nbranch and $Z$ is the number of branches. We will again attempt to find a self-\nconsistent solution for $T$ , starting from a center site. The average cluster size $T$\nis found from summing the probability that the next site $k$ is empty, $(1-p)$ ,\nmultiplied with the contribution to the average, in this case (0), plus the probability\nthat the next site is occupied, $p$ , multiplied with the contribution in this case, which\nis the contribution from the site (1) and the contribution of the remaining $Z-1$\nsubbranches. In total:\n\\[ T=(1-p)\\,0+p\\,(1+(Z-1)T)~,\\eqno{(3.18)}\\]",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            627,
            197,
            638
          ],
          "text": "We solve for $T$ , finding",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            233,
            654,
            358,
            689
          ],
          "text": "T = \\frac { p } { 1 - p ( Z - 1 ) } ~ .",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            698,
            520,
            788
          ],
          "text": "This expression diverges when $1-p(Z-1)=0$ , that is, for $p=1/(Z-1)$ , which\nwe recognize as $p_c=1/(Z-1)$ . We insert this in ( 3.17 ) as find that $S$ is\n$$\nS=1+Z T=\\frac{1+p}{1-(Z-1) p}=\\frac{1+p}{1-\\frac{p}{p_c}}=\\frac{p_c(1+p)}{p_c-p},\n$$",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 48,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            215,
            62
          ],
          "text": "3.4 Cluster Number Density",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            502,
            44,
            520,
            62
          ],
          "text": "39",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            161
          ],
          "text": "which is illustrated in Fig. 3.2 . This is a special case for $S(p)$ , which in general can\nbe written on the general form\n\\[ S=\\frac{\\Gamma}{(p_c-p)^\\gamma}~.\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:defnocounter}\\]",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            177,
            520,
            270
          ],
          "text": "For $p_c=1/(Z-1)$ the Bethe lattice with coordination number $Z$ , we have found that and that the exponent is $\\gamma=1$ . where our argument determines $p_c=1/(Z-1)$ ,\nand the exponent $\\gamma=1$ . The average cluster size $S$ therefore diverges as a power-\nlaw when $p$ approaches $p_c$ . The exponent $\\gamma$ characterizes the behavior. This is a\ngeneral results. The value of $\\gamma$ depends on the dimensionality, but not on the details\nof the lattice. Here, we notice that $\\gamma$ does indeed not depend on $Z$ .",
          "reading_order": 3
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            304,
            287,
            322
          ],
          "text": "3.4 Cluster Number Density",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            331,
            520,
            448
          ],
          "text": "In order to find the cluster number density for the Bethe lattice, we start by\ndeveloping a more general way to find the cluster number density. To find the cluster\nnumber density for a given $s$ , we need to find all possible configurations, $c(s)$ , of\nclusters of size $s$ , and sum up their probability:\n\\[n(s,p)=\\sum_{c(s)} p^s(1-p)^{t(c)}~.\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:lorenz2}\\]",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            465,
            520,
            638
          ],
          "text": "This was simple in one dimension, because there was only one possible configu-\nration for a given $s$ . Just like in one dimension we include the term $p^{s}$ , because\nwe know that we must have all the $s$ sites of the cluster present. In addition, we\nneed to include a term that takes into account that all the neighboring sites must be\nempty. In general, we introduce the notation $t(c)$ for the number of neighbors for\nconfiguration $c$ . In one dimension, $t$ is always 2, but in higher dimensions different\nclusters may have different numbers of neighbors, as illustrated for the case of a\ntwo-dimensional system in Fig. 3.3 . We therefore need to include the term $(1-p)^{t}$\nto account for the probability for the $t$ neighbors to be unoccupied. Based on this,\nwe realize that we may sum over all values of $t$ . However, we then need to include\nthe effect that there are several clusters that can have the same $t$ . We will then have",
          "reading_order": 6
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_048_figure_007.png)",
          "figure_path": "figures/percolation_studies_page_048_figure_007.png",
          "bbox": [
            72,
            672,
            520,
            779
          ],
          "reading_order": 7
        },
        {
          "label": "cap",
          "bbox": [
            72,
            779,
            511,
            797
          ],
          "text": "Fig. 3.3 Illustration of the 6 possible configurations for a two-dimensional cluster of size $s=3$",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 49,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            81,
            58
          ],
          "text": "40",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            349,
            44,
            511,
            58
          ],
          "text": "3 Infinite-Dimensional Percolation",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            179
          ],
          "text": "to introduce a degeneracy factor $g_{s,t}$ which gives the number of different clusters\nthat have size $s$ and a number of neighbors equal to $t$ . The cluster number density\ncan then be written as\n\\[n(s,p)=p^s\\sum_t g_{s,t}(1-p)^t~.\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:f2}\\]",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            188,
            520,
            286
          ],
          "text": "Degeneracy for Two-Dimensional Clusters We can illustrate these concept for\ntwo-dimensional percolation. Let us study the case when $s=3$ . In this case there\nare 6 possible clusters for size $s=3$ , as illustrated in Fig. 3.3 . There are two clusters\nwith $t=8$ , and four clusters with $t=7$ . There are no other clusters of size $s=3$ .\nWe can therefore conclude that for the two-dimensional lattice, we have $g_{3,8}=2$ ,\nand $g_{3,7}=4$ , and $g_{3,t}=0$ for all other values of $t$ .",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            304,
            520,
            510
          ],
          "text": "Degeneracy for the Bethe Lattice For the Bethe lattice, there is a particularly\nsimple relation between the number of sites, $s$ , and the number of neighbors, $t$ . We\ncan see this by looking at the first few generations of a Bethe lattice grown from a\ncentral seed. For $s=1$ , the number of neighbors is $t_1=Z$ . To add one more site,\nwe have to remove one neighbor from what we had previously, and then we add\n$Z-1$ new neighbors, that is, for $s=2$ we have $t_2=t_1+(Z-2)$ . Consequently\nwe get an iterative relation for the number of neighbors $t_k$ when we have $k$ sites:\n$$t_k=t_{k-1}+(Z-2)\\;,\\eqno(3.24)$$\nand therefore:\n$$t_s=s(Z-2)+2\\;.\\eqno(3.25)$$",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            528,
            520,
            600
          ],
          "text": "Cluster Number Density The cluster number density, given by the sum over all t,\nis therefore reduced to only a single term for the Bethe lattice",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            609,
            514,
            689
          ],
          "text": "For simplicity, we will write $g_s=g_{s,t_s}$ . In general, we do not know $g_s$ , but we will\nshow that we still can learn quite a lot about the behavior of $n(s,\\,p)$ . The cluster\ndensity can therefore be written as\n$$ n(s,\\,p)=g_sp^s(1-p)^{2+(Z-2)s}~. \\eqno(3.27)$$",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            707,
            403,
            753
          ],
          "text": "We rewrite this as a common factor to the power $s$ :\n$$n(s,\\,p)=g_{s}[p(1-p)^{Z-2}]^{s}(1-p)^{2}\\;,$$",
          "reading_order": 7
        }
      ]
    },
    {
      "page_number": 50,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            210,
            62
          ],
          "text": "3.4 Cluster Number Density",
          "reading_order": 0
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_050_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_050_figure_002.png",
          "bbox": [
            72,
            80,
            520,
            251
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            266,
            520,
            349
          ],
          "text": "Fig. $n(s,\\,p)=g_{s}[p(1-p)^{Z-2}]^{z}(1-p)^{2}$ A plot $f(p)=p(1-p)^{Z-2}$ , which is a term in the cluster number density for the Bethe lattice. We notice that $f(p)$ has a maximum at $p=p_c$ ,\nand that the second derivative, $f''(p)$ , is zero in this point. A Taylor expansion of $f(p)$ around\n$p=p_c$ will therefore have a second order term in $(p-p_c)$ as the lowest-order term — to lowest\norder it is a parabola at $p=p_c$ . It is this second order term which determines the exponent $\\sigma$ ,\nwhich consequently is independent of $Z$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            376,
            520,
            430
          ],
          "text": "which in the special case for $Z=3$, which we studied above, becomes\n$$n(s,p)=g_{s}[p(1-p)]^{s}(1-p)^{2}\\;.\\eqno(3.29)$$",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            439,
            520,
            801
          ],
          "text": "Taylor Expansion Around p = p c Let us now address n( s, p ) for p close to p c\nfor a general value of Z . In this range, we will do a Taylor expansion of the term\n$f(p) = p(1-p)^{Z-2}$ , which is raised to the power s in the equation for n( s, p ) in\n( 3.28 ) . The shape of f( p ) as a function of p is shown in Fig. 3.4 . The maximum\nof f( p ) occurs for p = p c = 1/( Z − 1) . This is also easily seen from the first\nderivative of f( p ) .\nf′ ( p ) = (1 − p ) Z − 2 − p ( Z − 2)(1 − p ) Z − 3 (3.30)\n= (1 − p ) Z − 3 (1 − p − p ( Z − 2)) (3.31)\n= (1 − p ) Z − 3 (1 − ( Z − 1) p ) (3.32)\nwhich shows that f ′ ( p c ) = 0 . (We leave it to the reader to show that f ′′ ( p c ) < 0.)\nThe Taylor expansion of f( p ) around p = p c is then:\nf( p ) = f( p c ) + f ′ ( p c )( p − p c ) + \\frac{1}{2} f ′′ ( p c )( p − p c ) 2 + \\mathscr{O}((p-p_c)^3)~,~~~~~~~(3.33)\n$$\nwhere we already have found the first order term, f ′ ( p c ) = 0 . We can therefore\nwrite",
          "reading_order": 5
        }
      ]
    },
    {
      "page_number": 51,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            80,
            58
          ],
          "text": "4:",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            349,
            44,
            512,
            62
          ],
          "text": "3 Infinite-Dimensional Percolation",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            215
          ],
          "text": "Cluster Number Density We will now insert this Taylor expansion back into the\nexpression for the cluster number density:\n\\[n(s, \\, p)=g_{s}[f(p)]^{s}(1-p)^{2}=g_{s}e^{s\\ln f(p)}(1-p)^{2}~,\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:lorenz}\\]\nwhere we now insert $f(p)\\simeq A(1-B(p-p_c)^{2})$ to get\n\\[n(s, \\, p)\\simeq g_{s}A^{s}e^{s\\ln(1-B(p-p_c)^{2})}(1-p)^{2}~.\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:lorenz}\\]",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            228,
            520,
            295
          ],
          "text": "When $p$ is close to $p_c$ , $(p-p_c)^2$ is small number, and we can use the first order of\nthe Taylor expansion of $\\ln(1-x)\\simeq -x+\\mathcal{O}(x^2)$ , to get",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            313,
            520,
            359
          ],
          "text": "Consequently, for $p=p_{c}$ we get\n\\[n(s,\\, p_{c})=g_{s}A^{s}(1-p_{c})^{2}~.\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:fondr}\\]",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            376,
            520,
            465
          ],
          "text": "Cluster Number Density Expressed in Terms of $n(s,\\,p_c)$ When $p$ is close to $p_c$ ,\nwe can assume that $(1-p)^2 \\simeq (1-p_c)^2$ , and we can therefore rewrite the cluster\nnumber density in terms of $n(s,\\,p_c)$ , giving\n$$ n(s,\\,p)=n(s,\\,p_c)e^{-sB(p-p_c)^2}~. \\eqno(3.39) $$",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            474,
            457,
            591
          ],
          "text": "We rewrite the exponential in terms of a characteristic cluster size $s_\\xi$ as\n$$n(s,\\,p)=n(s,\\,p_c)e^{-s/s_\\xi}\\;,$$\nwhere the characteristic cluster size $s_\\xi$ is\n$$s_\\xi=B^{-1}(p-p_c)^{-2}\\;.$$",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            609,
            520,
            754
          ],
          "text": "This implies that the characteristic cluster size $s_\\xi$ diverges as a power-law with\nexponent $1/\\sigma=2$ as $p$ approaches $p_c$ . The general scaling form for the\ncharacteristic cluster size $s_\\xi$ is\n$$ s_\\xi\\propto|p-p_c|^{-1/\\sigma}~, \\eqno(3.42)$$\nwhere the exponent $\\sigma$ is universal, which means that is does not depend on lattice\ndetails such a $Z$ , but it does depend on lattice dimensionality. It will therefore have\na different value for two-dimensional percolation.",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            770,
            520,
            806
          ],
          "text": "Scaling Ansatz for $n(s,\\, p_c)$ We can use our knowledge of the behavior of $P$ and $S$\nwhen $p$ approaches $p_c$ to constrain the scaling behavior of $n(s,\\, p_c)$ . We know that",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 52,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            210,
            62
          ],
          "text": "3.4 Cluster Number Density",
          "reading_order": 0
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            322
          ],
          "text": "we can find $S$ and $P$ from the cluster number density. The average cluster size $S$ as\n$p$ approaches $p_c$ is\n\\[ S=\\frac{\\Gamma}{p_c-p}~,\\eqno(3.43)\\]\nwhich should diverge when $p$ approaches $p_c$ . We rewrite $S$ in terms of $n(s,\\, p)$ :\n\\[ S=\\sum s^2 n(s,\\, p)~,\\eqno(3.44)\\]\nwhich should diverge as $p$ approaches $p_c$ . We rewrite the sum as an integral in the\nlimit of $p=p_c$\n\\[ S=\\int_0^\\infty s^2 n(s,\\, p_c)ds~.\\eqno(3.45)\\]",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            339,
            520,
            439
          ],
          "text": "This integral must diverge. We can therefore conclude that $n(s,\\,p_c)$ is not an\nexponential, otherwise the integral then would converge. We therefore assume that\nthe cluster number density has a power-law shape, that is, we introduce the scaling\nansatz:\n$$ n(s,\\,p_c) \\simeq C s^{-\\tau} \\;. \\eqno(3.46)$$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            448,
            520,
            637
          ],
          "text": "This expression is only valid in the limit when $s\\gg1$ . We introduce this scaling\nansatz into the expression for $P$ :\n$$\\sum_{s}sn(s,p)=p-P~,\\eqno(3.47)$$\nand approximate the sum with an integral in the limit when $p=p_c$ :\n$$\\int_0^\\infty sn(s,\\, p_c)\\mathrm{d} s=\\int_0^\\infty sCs^{-\\tau}\\mathrm{d} s=p-P~,\\eqno(3.48)$$\nwhich should converge. We therefore have two conditions",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            654,
            152,
            666
          ],
          "text": "1. The integral",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            87,
            680,
            520,
            747
          ],
          "text": "$$\\begin{gathered}\n\\int_{0}^{\\infty} s^{2} n\\left(s, p_{c}\\right) d s=\\int_{0}^{\\infty} s^{2} C s^{-\\tau} \\mathrm{d} s \\\\\n\\text { should diverge, which implies that } \\tau-2 \\leq 1\n\\end{gathered}\\qquad\\qquad\\qquad(3.49)$$",
          "reading_order": 6
        }
      ]
    },
    {
      "page_number": 53,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            83,
            58
          ],
          "text": "44",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            349,
            44,
            512,
            62
          ],
          "text": "3 Infinite-Dimensional Percolation",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            152,
            98
          ],
          "text": "1. The integral",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            87,
            107,
            520,
            179
          ],
          "text": "$$\\begin{gathered}\n\\int_{0}^{\\infty} s n\\left(s, p_{c}\\right) \\mathrm{d} s=\\int_{0}^{\\infty} s C s^{-\\tau} \\mathrm{d} s \\\\\n\\text { should converge, which implies that } \\tau-1>1 .\n\\end{gathered}\\qquad\\qquad\\qquad\\qquad(3.50)$$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            88,
            188,
            520,
            241
          ],
          "text": "This implies that the exponent $\\tau $ has the following bounds:\n2< τ≤3 .",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            258,
            520,
            322
          ],
          "text": "We Behavior of S ( p ) When p Is Close to p c We can sum up our arguments\nso far in the relation",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            338,
            520,
            421
          ],
          "text": "Let us use this expression to calculate $S$ , for which we know the exact scaling\nbehavior, and then again use this to find the value for $\\tau$\n$$ S=C\\sum_{s} s^{2-\\tau}e^{-s/s_{\\xi}}\\rightarrow C\\int_1^{\\infty}s^{2-\\tau}e^{-s/s_{\\xi}}ds~.\\eqno(3.53)$$",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            437,
            520,
            609
          ],
          "text": "We now make a rough estimate. This is useful, since it is in the spirit of this book,\nand it also provides the correct behavior. We assume that\n\\[S=C \\int_1^{\\infty} s^{2-\\tau} e^{-s/s_{\\xi}} ds \\sim C \\int_1^{s_{\\xi}} s^{2-\\tau} ds \\sim s_{\\xi}^{3-\\tau}~,\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:causal}\\]\nwhere we have used the sign $\\sim$ to denote that the expressions have the same scaling\nbehavior. We can do it slightly more elaborately:\n\\[S \\simeq C \\int_1^{\\infty} s^{2-\\tau} e^{-s/s_{\\xi}} ds~.\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:causal}\\]",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            625,
            520,
            690
          ],
          "text": "We change variables by introducing, $u=s/s_\\xi$ , which gives\n$$S\\simeq s_\\xi^{3-\\tau}\\int_{1/s_\\xi}^\\infty u^{2-\\tau}e^{-u}du~.\\eqno(3.56)$$",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            72,
            707,
            520,
            771
          ],
          "text": "This integral is simply a number, since $1/s_\\xi\\to0$ , when $p\\to p_c$ . The asymptotic\nscaling behavior in the limit $p\\to p_c$ is therefore\n$$S\\sim s^{3-\\tau}_\\xi\\sim(p-p_c)^{-2(3-\\tau)}\\sim(p-p_c)^{-1}~,\\eqno(3.57)$$",
          "reading_order": 9
        }
      ]
    },
    {
      "page_number": 54,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            210,
            62
          ],
          "text": "3.4 Cluster Number Density",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            502,
            44,
            511,
            58
          ],
          "text": "4",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            199,
            93
          ],
          "text": "where we have used that",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            107,
            349,
            197
          ],
          "text": "$$\n\\begin{array} { c } { { s _ { \\xi } \\sim ( p - p _ { c } ) ^ { - 2 } ~ , } } \\\\ { { } } \\\\ { { \\mathrm { a n d ~ t h a t } } } \\\\ { { } } \\\\ { { S \\sim ( p - p _ { c } ) ^ { - 1 } ~ . } } \\end{array}\n$$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            206,
            322,
            277
          ],
          "text": "Our direct solution therefore gives that\n\\[ \\tau=\\frac{5}{2}~.\\]",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            286,
            512,
            316
          ],
          "text": "This relation indeed satisfies the exponent relations we found above, since 2 -\n$5/2\\leq3$ . A plot of the scaling form is shown in Fig. 3.5 .",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            331,
            520,
            492
          ],
          "text": "Preliminary Scaling Theory for Cluster Number Density We have now devel-\noped a preliminary scaling theory for the cluster number density. In the coming\nchapters, we will demonstrate that similar scaling relations also are valid for\npercolation in other dimension. We have found that in the vicinity of $p_c$ , we do\nnot expect deviations until we reach large $s$ , that is, until we reach a characteristic\ncluster size $s_\\xi$ that increases as $p\\to p_c$ . The general scaling form for the cluster\nnumber density is\n$$n(s,\\,p)= n(s,\\,p_c)F(\\frac{s}{s_\\xi})\\;,\\eqno(3.61)$$",
          "reading_order": 6
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_054_figure_007.png)",
          "figure_path": "figures/percolation_studies_page_054_figure_007.png",
          "bbox": [
            72,
            519,
            512,
            761
          ],
          "reading_order": 7
        },
        {
          "label": "cap",
          "bbox": [
            72,
            770,
            511,
            800
          ],
          "text": "Fig. A plot of $n(s,p)=s^{-\\tau}\\exp(-s(p-p_c)^2)$ as a function of $s$ for various values of\nillustrates how the characteristic cluster size $s_{\\xi}$ appears as a cut-off ff in the cluster number density",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 55,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            83,
            58
          ],
          "text": "46",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            349,
            44,
            512,
            62
          ],
          "text": "3 Infinite-Dimensional Percolation",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            107,
            93
          ],
          "text": "where",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            107,
            520,
            197
          ],
          "text": "$$\\text{and}\\qquad\\qquad\\qquad\\qquad\\qquad \\begin{aligned}\n& n\\left(s, p_{c}\\right)=C s^{-\\tau}, \\\\\n& s_{\\xi}=s_{0}\\left|p-p_{c}\\right|^{-1 / \\sigma} .\n\\end{aligned}\\qquad\\qquad\\qquad\\qquad(3.62)$$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            206,
            520,
            386
          ],
          "text": "In addition, we have the following scaling relations:\n\\begin{equation}  P(p) \\sim (p-p_c)^\\beta~, & \\label{eq:P12}  \\\\ \\xi \\sim |p-p_c|^{-\\nu}~, & \\label{eq:P30}  \\\\ \\text{and} \\qquad S \\sim |p-p_c|^{-\\gamma}~, & \\label{eq:P45}  \\\\ \\end{equation}",
          "reading_order": 4
        },
        {
          "label": "sec",
          "bbox": [
            72,
            419,
            135,
            431
          ],
          "text": "Exercises",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            448,
            520,
            483
          ],
          "text": "Exercise 3.1 ( P ( p ) for Z = 4) Find P ( p ) for Z = 4 and determine β for this\nvalue of Z.",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            636,
            520,
            701
          ],
          "text": "Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0\nInternational License ( http://creativecommons.org/licenses/by/4.0/ ), which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as long as you give appropriate\ncredit to the original author(s) and the source, provide a link to the Creative Commons license and\nindicate if changes were made.",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            701,
            518,
            770
          ],
          "text": "The images or other third party material in this chapter are included in the chapter’s Creative\nCommons license, unless indicated otherwise in a credit line to the material. If material is not\nincluded in the chapter’s Creative Commons license and your intended use is not permitted by\nstatutory regulation or exceeds the permitted use, you will need to obtain permission directly from\nthe copyright holder.",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 56,
      "elements": [
        {
          "label": "header",
          "bbox": [
            520,
            98,
            546,
            134
          ],
          "text": "4",
          "reading_order": 0
        },
        {
          "label": "title",
          "bbox": [
            72,
            98,
            367,
            116
          ],
          "text": "Finite-Dimensional Percolation",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            304,
            520,
            467
          ],
          "text": "In this chapter we apply the scaling theories developed in the one-dimensional\nsystem and the infinite-dimensional system to systems of finite dimensions. The\nlowest dimension with an interesting behavior is two dimensions. Here, we intro-\nduce effective ways to measure the cluster number density $n(s,\\;p)$ in two dimension.\nWe develop the scaling theory for $n(s,\\;p)$ and demonstrate how to use data-collapse\nplots as an efficient method to measure the critical exponents. We also demonstrate\nhow we can use the scaling theory for $n(s,\\;p)$ to derive expressions for the density of\nthe spanning cluster, $P$ , and the average cluster size, $S$ . Finally, we demonstrate how\nthe scaling theory provides scaling relations, that is, relations between exponents,\nand bounds for the values of the critical exponents.",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            467,
            520,
            627
          ],
          "text": "For the one-dimensional and the infinite-dimensional systems we have been able\nto find exact results for the percolation probability, $\\Pi(p)$ , for $P(p)$ , the probability\nfor a site to belong to an infinite cluster, and we have characterized the behavior\nusing the distribution of cluster sizes, $n(s,\\, p)$ and its cut-off, $s_{\\xi}$ . In both one and\ninfinite dimensions we have been able to calculate these functions exactly. However,\nin two and three dimensions — which are the most relevant for our world — we are\nunfortunately not able to find exact solutions. We saw above that the number of\nconfigurations in a $L^d$ system in $d$ -dimensions increases very rapidly with $L$ — so\nrapidly that a complete enumeration is impossible. But can we still use what we\nlearned from the one and infinite-dimensional systems?",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            627,
            520,
            743
          ],
          "text": "In the one-dimensional case it was simple to find $\\Pi(p,L)$ because there is\nonly one possible path from one side to another. We cannot generalize this to\ntwo dimensions, since in two dimensions there are many paths from one side to\nanother — and we need to include all to estimate the probability for percolation.\nSimilarly, it was simple to find $n(s,\\, p)$ in one dimension, because all clusters only\nhave two neighboring sites and the surface, $t$ , is always of size 2. This is also not\ngeneralizable to higher dimensions.",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            743,
            520,
            774
          ],
          "text": "In the infinite-dimensional system, that is in the Bethe lattice, we were able to\nfind $P(p)$ because we could separate the cluster into different paths that never could",
          "reading_order": 5
        },
        {
          "label": "foot",
          "bbox": [
            72,
            806,
            396,
            845
          ],
          "text": "© The Author(s) 2024\nA. Malthe-Sørenssen, Percolation Theory Using Python, Lecture Notes\nin Physics 1029, https://doi.org/10.1007/978-3-031-59900-2_4",
          "reading_order": 6
        },
        {
          "label": "foot",
          "bbox": [
            506,
            806,
            520,
            816
          ],
          "text": "47",
          "reading_order": 7
        }
      ]
    },
    {
      "page_number": 57,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            81,
            58
          ],
          "text": "48",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            355,
            44,
            520,
            62
          ],
          "text": "4 Finite-Dimensional Percolation",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            225
          ],
          "text": "intersect except in a single point, because there are no loops in the Bethe lattice. This\nis not the case in two and three dimensions, where loops always will be possible.\nWhen there are loops present, we cannot use the arguments we used for the Bethe\nlattice, because a branch cut off at one point may be connected again further out.\nFor the Bethe lattice, we could also estimate the multiplicity $g(s,t)$ of the clusters,\nthe number of possible clusters of size $s$ and surface $t$ , since $t$ was a function of\n$s$ . In a two- or three-dimensional system this is not similarly simple, because the\nmultiplicity $g(s,t)$ , that is the number of different cluster configurations with size $s$\nand surface $t$ , is not simple even in two dimensions, as illustrated in Fig. 4.1 .",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            225,
            520,
            340
          ],
          "text": "This means that the solution methods used for the one dimensional and the\ninfinite dimensional systems cannot be extended to address two-dimensional or\nthree-dimensional systems. However, several of the techniques and observations we\nhave made for the one-dimensional and the Bethe lattice systems, can be used as the\nbasis for a generalized theory that can be applied in any dimension. Here, we will\ntherefore pursue the more general features of the percolation system, starting with\nthe cluster number density, $n(s,\\;p)$ .",
          "reading_order": 3
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            367,
            287,
            386
          ],
          "text": "4.1 Cluster Number Density",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            403,
            520,
            451
          ],
          "text": "We have found that the cluster number density plays a fundamental role in our\nunderstanding of the percolation problem, and we will use it here as our basis for\nthe scaling theory for percolation.",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            454,
            520,
            663
          ],
          "text": "When we discussed the Bethe lattice, we found that we could write the cluster\nnumber density as a sum over all possible configurations of cluster size, $s$ :\n\\[n(s,p)=\\sum_j p^s(1-p)^{t_j}~,\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:frammariner2013}\\]\nwhere $j$ runs over all different configurations, and $t_j$ denotes the number of\nneighbors for this particular configuration. We can simplify this by rewriting the\nsum to be over all possible number of neighbors, $t$ , and include the degeneracy $g_{s,t}$ ,\nthe number of configurations with $t$ neighbors:\n\\[n(s,p)=\\sum_t g_{s,t}p^s(1-p)^t~.\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:framiner2013}\\]",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            672,
            520,
            739
          ],
          "text": "The values of $g_{s,t}$ can be found for smaller values of $s$ . However, while this may\ngive us interesting information about the smaller cluster, and therefore for smaller\nvalues of $p$ , it does not help us to develop a theory for the behavior for $p$ close to\n$p_c$ .",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            742,
            520,
            806
          ],
          "text": "In order to address the cluster number density, we will need to study the\ncharacteristics of $n(s,\\,p)$ , for example by generating numerical estimates for its\nscaling behavior, and then propose a general scaling form which will be tested in\nvarious settings.",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 58,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            210,
            62
          ],
          "text": "4.1 Cluster Number Density",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            506,
            44,
            520,
            62
          ],
          "text": "49",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_058_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_058_figure_002.png",
          "bbox": [
            63,
            89,
            528,
            689
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            696,
            502,
            718
          ],
          "text": "Fig. 4.1 Illustration of the possible configurations for two-dimensional clusters of size s\n1, 2, 3, 4",
          "reading_order": 3
        }
      ]
    },
    {
      "page_number": 59,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            84,
            62
          ],
          "text": "50",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            355,
            44,
            512,
            62
          ],
          "text": "4 Finite-Dimensional Percolation",
          "reading_order": 1
        },
        {
          "label": "sec",
          "bbox": [
            72,
            80,
            278,
            98
          ],
          "text": "Numerical Estimation of $n(s, p)$",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            116,
            520,
            269
          ],
          "text": "We discussed how to measure $n(s,\\; p)$ from a set of numerical simulations in Chap. 2 .\nWe can use the same method in two and higher dimensions. We estimate $n(s,\\; p; L)$\nusing\n$$\\overline{n(s,\\; p; L)}=\\frac{N_s}{M\\cdot L^d}\\;,\\eqno(4.3)$$\nwhere $N_s$ is the total number of clusters of size $s$ measured for $M$ simulations in a\nsystem of size $L^d$ and for a given value of $p$ . We perform these simulations just as\nwe did in one dimension, using the following program:",
          "reading_order": 3
        },
        {
          "label": "code",
          "bbox": [
            79,
            284,
            448,
            645
          ],
          "text": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.ndimage import measurements\nM = 2000\nL = 200\np = 0.58\nallarea = np.array([])\nfor i in range(M):\nz = np.random.rand(L,L)\nm = z<p\nlw, num = measurements.label(m)\nlabelList = np.arange(lw.max() + 1)\narea = measurements.sum(m, lw, labelList)\nallarea = np.append(allarea,area)\nn,sbins = np.histogram(allarea,bins=int(max(allarea)))\ns = 0.5*(sbins[1:]+sbins[:-1])\nnsp = n/(L*nsamp)\ni = np.nonzero(n)\nplt.figure(figsize=(12,4))\nplt.subplot(1,2,1)\nplt.plot(s[i],nsp[i],’o’)\nplt.xlabel(’$s$’)\nplt.ylabel(’$n(s,p)$’)\nplt.subplot(1,2,2)\nplt.loglog(s[i],nsp[i],’o’)\nplt.xlabel(’$s$’)\nplt.ylabel(’$n(s,p)$’)",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            653,
            520,
            766
          ],
          "text": "The resulting plot of $\\overline{n(s,\\,p;L)}$ for $L=200$ is shown in Fig. 4.2 . Unfortunately,\nthis plot is not very useful. The problem is that there are too many values of $s$ for\nwhich we have little or no data at all. For small values of $s$ we have many clusters\nfor each value of $s$ and the statistics is good. But for large values of $s$ , such as for\nclusters of size $s=10^4$ and above, we have less than one data point for each value\nof $s$ . Our measured distribution $\\overline{n(s,\\,p;L)}$ is therefore a poor representation of the\nreal $n(s,\\,p;L)$ in this range.",
          "reading_order": 5
        }
      ]
    },
    {
      "page_number": 60,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            210,
            62
          ],
          "text": "4.1 Cluster Number Density",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            502,
            44,
            511,
            58
          ],
          "text": "5",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_060_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_060_figure_002.png",
          "bbox": [
            72,
            80,
            520,
            224
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            241,
            520,
            268
          ],
          "text": "Fig. Plot of $n(s,\\,p;L)$ estimated from $M=1000$ samples for $p=0.58$ and $L=200$ . (Left)\nDirect plot. (Right) Log-log plot with linear and logaritmic binning",
          "reading_order": 3
        },
        {
          "label": "sec",
          "bbox": [
            72,
            295,
            379,
            313
          ],
          "text": "Measuring Probability Densities of Rare Events",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            331,
            518,
            425
          ],
          "text": "The problem with the measured results in Fig. 4.2 occur because we have chosen a\nvery small bin size for the histogram. For small values of $s$ we want to have a small\nbin size, since the statistics here is good, but for large values of $s$ we want to have\nlarger bin sizes. This is often solved by using logarithmic binning: We make the bin\nedges $a^i$ , where $a$ is the basis for the bins and $i$ is bin number. If we chose $a=2$ as\nthe basis for the bins, the bin edges will be $2^0$ , $2^1$ , $2^2$ , $2^3$ , . . ., that is $1$ , $2$ , $4$ , $8$ , . . .",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            425,
            520,
            591
          ],
          "text": "We then count how many events occur in each such bin. If we number the bins\nusing the index $i$ , then the edges of the bins are $s_{i}=a^{i}$ , and the width of bin $i$ is\n$\\Delta s_{i}=s_{i+1}-s_{i}$ . We then count how many events, $N_{i}$ , occur in the range from $s_{i}$\nto $s_{i}+\\Delta s_{i}$ . The average number of clusters, $\\bar{N}_{i}$ in each bin in the interval $\\Delta s_{i}$ is\n$\\bar{N}_{i}=N_{i}/\\Delta s_{i}$ for a single realization and $\\bar{N}_{i}=N_{i}/(\\Delta s_{i}M)$ for $M$ realizations. The\nestimate for the cluster number density in the middle point of the bin, that is for\n$\\bar{s}_{i}=(s_{i+1}+s_{i})/2$ , is\n$$\\overline{n(\\bar{s}_{i},\\,p;L)}=\\frac{\\bar{N}_{i}}{L^{d}}=\\frac{N_{i}}{M\\Delta s_{i}\\, L^{d}}\\ .\\eqno(4.4)$$",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            600,
            520,
            636
          ],
          "text": "A common mistake is to forget to divide by the bin size $\\Delta s_i$ when the bin sizes are\nnot all the same! We implement method by generating an array of all the bin edges.",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            636,
            520,
            716
          ],
          "text": "First, we find an upper limit to the bins, that is, we find an $i_m$ so that\n\\[a^{i_m}>\\max(s)~\\Rightarrow~\\log_a a^{i_m}>\\log_a \\max(s)~,\\tag*{4.5}\\]\n\\[i_m>\\log_a \\max(s)~.\\tag*{4.6}\\]",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            72,
            734,
            449,
            747
          ],
          "text": "We can for example round the right hand side up to the nearest integer",
          "reading_order": 9
        },
        {
          "label": "code",
          "bbox": [
            80,
            761,
            421,
            788
          ],
          "text": "a = 1.2\nlogamax = np.ceil(np.log(max(allarea))/np.log(a));",
          "reading_order": 10
        }
      ]
    },
    {
      "page_number": 61,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            83,
            62
          ],
          "text": "52",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            355,
            44,
            520,
            62
          ],
          "text": "4 Finite-Dimensional Percolation",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            116
          ],
          "text": "where allarea corresponds to all the s-values. We can then generate an array of\nindices from 1 to this maximum value",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            80,
            125,
            304,
            137
          ],
          "text": "logbins = a**np.arange(0,logamax)",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            143,
            439,
            161
          ],
          "text": "And we can further generate the histogram with this set of bin edges",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            80,
            170,
            387,
            188
          ],
          "text": "nl,nlbins = np.histogram(allarea,bins=logbins",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            197,
            322,
            215
          ],
          "text": "And calculate the bin sizes and the bin centers",
          "reading_order": 6
        },
        {
          "label": "code",
          "bbox": [
            80,
            224,
            323,
            250
          ],
          "text": "ds = np.diff(logbins)\nsl = 0.5*(logbins[1:]+logbins[:,-1])",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            259,
            369,
            277
          ],
          "text": "Finally, we calculate the estimated value for ${\\overline {n(s,p;L)}}$:",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            80,
            286,
            215,
            298
          ],
          "text": "nsl = nl/(M*L**2*ds)",
          "reading_order": 9
        },
        {
          "label": "para",
          "bbox": [
            72,
            311,
            431,
            324
          ],
          "text": "The complete code for this analysis is found in the following script",
          "reading_order": 10
        },
        {
          "label": "code",
          "bbox": [
            79,
            338,
            387,
            442
          ],
          "text": "a = 1.2\nlogamax = np.ceil(np.log(max(s))/np.log(a))\nlogbins = a**np.arange(0,logamax)\nnl,nlbins = np.histogram(allarea,bins=logbins\nds = np.diff(logbins)\nsl = 0.5*(logbins[1:]+logbins[:-1])\nnsl = nl/(M*L**2*ds)\nplt.loglog(sl,nsl,’.b’)",
          "reading_order": 11
        },
        {
          "label": "para",
          "bbox": [
            72,
            448,
            520,
            564
          ],
          "text": "The resulting plot for $a=1.2$ is shown in Fig. 4.2 . Notice that the logarithmically\nbinned plot is much easier to interpret than the linearly binned plot. You should,\nhowever, always reflect on whether your binning method may influence the resulting\nplot in some way, since there may be cases where your choice of binning method\nmay affect the results you get. Although this is not expected to play any role in\nyour measurements in this book. We will in the following adapt logarithmic binning\nstrategies whenever we measure a dataset which is sparse.",
          "reading_order": 12
        },
        {
          "label": "sec",
          "bbox": [
            72,
            597,
            326,
            612
          ],
          "text": "Measurements of $n(s,p)$ When $p\\to p_{c}$",
          "reading_order": 13
        },
        {
          "label": "para",
          "bbox": [
            72,
            627,
            520,
            676
          ],
          "text": "What happens to $n(s,\\,p;L)$ when $p$ is close to $p_c$ ? We perform a sequence of\nsimulations for various values of $p_c$ and plot the resulting values for $\\overline{n(s,\\,p;L)}$ .\nThe resulting plot is shown in Fig. 4.3 .",
          "reading_order": 14
        },
        {
          "label": "para",
          "bbox": [
            72,
            680,
            520,
            806
          ],
          "text": "Since the plot is double-logarithmic, a straight line corresponds to a power-law\nbehavior, $n(s,\\,p)\\propto s^{-\\tau}$ . We see that as $p$ approaches $p_c$ the cluster number density\n$n(s,\\,p)$ approaches a power-law. We see that the $n(s,\\,p)$ curve follows the power-\nlaw behavior over some range of $s$ -values, but drops rapidly for larger $s$ -values. This\nis an effect of the characteristic cluster size, which also can be visually observed in\nFigs. 1.4 and 1.5 , where we see that the characteristic cluster size increases as $p$\napproaches $p_c$ . How can we characterize the characteristic cluster size based on this\nmeasurement of $n(s,\\,p)$ ? We could measure $s_\\xi$ directly from the plot, by drawing",
          "reading_order": 15
        }
      ]
    },
    {
      "page_number": 62,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            210,
            62
          ],
          "text": "4.1 Cluster Number Density",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            511,
            44,
            520,
            58
          ],
          "text": "3",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_062_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_062_figure_002.png",
          "bbox": [
            63,
            80,
            528,
            439
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            448,
            520,
            492
          ],
          "text": "Fig. 4.3 (a) Plot of $n(s,\\,p;L)$ as a function of $s$ for various values of $p$ for a 512 $\\times$ 512 lattice.\n(b) Plot of $s_{\\xi}(p)$ measured from the plot of $n(s,\\,p)$ corresponding to the points shown in circles in\n(a)",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            519,
            520,
            727
          ],
          "text": "a straight line parallel to but below $n(s,\\,p_c)$ , as illustrated in Fig. 4.3 . When the\nmeasured, $\\overline{n(s,\\,p)}$ intersects this drawn line, $n(s,\\,p)$ has fallen by a constant factor\nbelow $n(s,\\,p_c)$ . We define this as $s_\\xi$ , and we measure it by reading the values from\nthe $s$ -axis. The resulting set of $s_\\xi$ values are plotted as a function of $p$ in Fig. 4.3 .\nWe see that $s_\\xi$ increases and possibly diverges as $p$ approaches $p_c$ . This is an effect\nwe also found in the one-dimensional and the infinite-dimensional case, where we\nfound that\n$$ s_\\xi \\propto |p-p_c|^{-1/\\sigma} \\eqno{(4.7)}$$\nwhere $\\sigma$ was 1 is one dimension. We will now use this to develop a theory for\nboth $n(s,\\,p;L)$ and $s_\\xi$ based on our experience from one and infinite dimensional\npercolation.",
          "reading_order": 4
        }
      ]
    },
    {
      "page_number": 63,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            84,
            62
          ],
          "text": "54",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            355,
            44,
            512,
            62
          ],
          "text": "4 Finite-Dimensional Percolation",
          "reading_order": 1
        },
        {
          "label": "sec",
          "bbox": [
            72,
            80,
            233,
            98
          ],
          "text": "Scaling Theory for $n(s,p)$",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            116,
            520,
            197
          ],
          "text": "When $p\\rightarrow p_c$ we develop a theory, we realize that we are only interested in the limit , that is $|p-p_c|\\ll1$ , and $s\\gg1$ . In this limit, we expect $s_{\\xi}$ to mark the cross-\nover between two different behaviors. There is a common behavior for $n(s,\\,p)$ for\nall $p$ -values for small $s$ , up to a cut-off, $s_{\\xi}$ , as we also observe in Fig. 4.3 : The curves\nfor different $p$ -values are approximately equal for small $s$ .",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            197,
            528,
            340
          ],
          "text": "Based on what we observed in one-dimension and infinite-dimensions, we expect\nand propose the following scaling form for $n(s,\\;p)$ :\n$$ n(s,\\;p)=n(s,\\;p_c)F(\\frac{s}{s_\\xi})\\;, \\eqno (4.8) $$\n$$ n(s,\\;p_c)=Cs^{-\\tau}\\;, \\eqno (4.9) $$\n$$ s_\\xi=s_0|p-p_c|^{-1/\\sigma}\\;. \\eqno (4.10)$$",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            349,
            520,
            421
          ],
          "text": "Based on the methods presented in this book, we have estimated the exponents for\nvarious systems and listed them in Table 4.1 . You can find an up-to-date list of all the\nexponents in the wikipedia article on percolation thresholds at https://en.wikipedia.\norg/wiki/Percolation_critical_exponents .",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            80,
            421,
            520,
            466
          ],
          "text": "We will often simplify the scaling form by writing it on the form:\n\\[n(s,p)=s^{-\\tau}F(s/s_{\\xi})=s^{-\\tau}F((p-p_c)^{1/\\sigma}s)~.\\]",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            483,
            359,
            501
          ],
          "text": "What can we expect from the scaling function $F(x)$ ?",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            501,
            520,
            547
          ],
          "text": "This is essentially the prediction of a data-collapse. If we plot $s^\\tau n(s,\\, p)$ as a\nfunction of $s|p-p_c|^{1/\\sigma}$ we would expect to get the scaling function $F(x)$ , which\nshould be a universal curve, as illustrated in Fig. 4.4 .",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            72,
            547,
            520,
            645
          ],
          "text": "An alternative scaling form is\n\\[n(s,\\,p)=s^{-\\tau}\\hat F((p-p_c)s^\\sigma)~,\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:lorenz2}\\]\nwhere we have introduced the function $\\hat F(u)=F(u^\\sigma)$ . These forms are equivalent,\nbut in some cases this form produces simpler calculations.",
          "reading_order": 9
        },
        {
          "label": "para",
          "bbox": [
            72,
            645,
            520,
            673
          ],
          "text": "This scaling form should in particular be valid for both the 1d and the Bethe\nlattice cases—let us check this in detail.",
          "reading_order": 10
        },
        {
          "label": "tab",
          "bbox": [
            72,
            716,
            520,
            806
          ],
          "text": "<table><tr><td>d</td><td>β</td><td>τ</td><td>σ</td><td>γ</td><td>υ</td><td>D</td><td>μ</td><td>D min</td><td>D max</td><td>DB</td></tr><tr><td>1</td><td></td><td>2</td><td>1</td><td>1</td><td>1</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>2</td><td>0.14</td><td>2.05</td><td>0.4</td><td>2.4</td><td>1.33</td><td>1.89</td><td>1.3</td><td>1.1</td><td>1.4</td><td>1.6</td></tr><tr><td>3</td><td>0.4</td><td>2.2</td><td>0.45</td><td>1.8</td><td>0.9</td><td>2.5</td><td>2.0</td><td>1.3</td><td>1.6</td><td>1.7</td></tr><tr><td>Bethe</td><td>1</td><td>5/2</td><td>1/2</td><td>1</td><td>1/2</td><td>4</td><td>3</td><td>2</td><td>2</td><td>2</td></tr></table>",
          "reading_order": 11
        },
        {
          "label": "cap",
          "bbox": [
            72,
            698,
            520,
            716
          ],
          "text": "Table 4.1 Values for scaling exponents for percolation in $1,2,3,4$ and infinite dimensions [8,37]",
          "reading_order": 12
        }
      ]
    },
    {
      "page_number": 64,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            210,
            62
          ],
          "text": "4.1 Cluster Number Density",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            506,
            44,
            512,
            62
          ],
          "text": "5",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_064_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_064_figure_002.png",
          "bbox": [
            72,
            80,
            520,
            259
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            268,
            520,
            297
          ],
          "text": "Fig. 4.4 A plot of $n(s,\\,p) s^{\\tau}$ as a function of $|p-p_c|^{1/\\sigma} s$ shows that the cluster number density\nsatisfies the scaling ansatz of ( 4.11 )",
          "reading_order": 3
        },
        {
          "label": "sec",
          "bbox": [
            72,
            328,
            287,
            343
          ],
          "text": "Scaling Ansatz for 1d Percolation",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            358,
            520,
            430
          ],
          "text": "In the case of one-dimensional percolation, we know that we can write the cluster\ndensity exactly as\n\\[n(s,\\,p)=(1-p)^2e^{-s/s_{\\xi}}~.\\addtocounter{equation}{1}\\tag{\\theequation}\\label{equ:fondrvc}\\]",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            439,
            520,
            531
          ],
          "text": "We showed that we could rewrite this as\n\\[n(s,\\,p)=s^{-2}F(\\frac{s}{s_\\xi})~,\\]\nwhere $F(u)=u^2e^{-u}$ . This is indeed on the general scaling form with $\\tau=2$ .",
          "reading_order": 6
        },
        {
          "label": "sec",
          "bbox": [
            72,
            564,
            279,
            582
          ],
          "text": "Scaling Ansatz for Bethe Lattice",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            598,
            520,
            725
          ],
          "text": "For the Bethe lattice we found that the cluster density was approximately on the\nform\n\\[n(s,\\,p) \\propto s^{-\\tau}e^{-s/s_{\\xi}}~,\\]\nwhich is already on the wanted form, so that\n\\[n(s,\\,p)=s^{-\\tau}F(s/s_{\\xi})~.\\tag*{$4.16$}\\]",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 65,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            83,
            58
          ],
          "text": "56",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            355,
            44,
            520,
            62
          ],
          "text": "4 Finite-Dimensional Percolation",
          "reading_order": 1
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            80,
            367,
            98
          ],
          "text": "4.2 Consequences of the Scaling Ansatz",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            116,
            520,
            197
          ],
          "text": "While the scaling ansatz has a simple form, it has powerful consequences. Here,\nwe address the theoretical consequences of the scaling ansatz, and demonstrate how\nwe can use the scaling ansatz in theoretical arguments. The methods we introduce\nhere are important methods in scaling theories, and we will use them in theoretical\narguments throughout this text.",
          "reading_order": 3
        },
        {
          "label": "sec",
          "bbox": [
            72,
            228,
            206,
            243
          ],
          "text": "Average Cluster Size",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            259,
            520,
            305
          ],
          "text": "Let us demonstrate how we can use the scaling ansatz to calculate the scaling of the\naverage cluster size, $S$ , and how this can be used to provide limits for the exponent\n$\\tau$ .",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            322,
            520,
            465
          ],
          "text": "The of Average Cluster size S The average cluster size, $S$ , is defined as\nfollows: We point to a random point in the percolation system. What is the average\nsize of the cluster connected to that point? The probability that a random point is\npart of the cluster of size $s$ is $sn(s,\\,p)$ and the size of that cluster is $s$ . We find the\naverage cluster by summing over all (finite) clusters, that is from $s=1$ to infinity:\n$$S(p)=\\sum_{s=1}^{\\infty}ssn(s,\\,p)=\\sum_{s=1}^{\\infty}s^2n(s,\\,p)\\;.\\eqno(4.17)$$",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            474,
            520,
            600
          ],
          "text": "We assume that we study systems where $p$ is close to $p_c$ so that the cluster number\ndensity $n(s,\\, p)$ is wide and that its drop-off (crossover) $s_{\\xi}$ is rapid. The sum over\n$s$ will then be a sum with many non-negligible terms and we can approximate this\nsum by an integral over $s$ instead:\n$$S(p)=\\sum_{s=1}^{\\infty} s^2 n(s,\\, p)\\simeq \\int_{1}^{\\infty} s^2 n(s,\\, p)\\,\\mathrm{d} s~.\\eqno(4.18)$$",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            618,
            439,
            681
          ],
          "text": "We can now insert the scaling ansatz $n(s,\\,p)=s^{-\\tau}\\,F(s/s_{\\xi})$ , getting:\n$$S(p)=\\int_1^{\\infty} s^{2-\\tau}\\,F(s/s_{\\xi})\\,\\mathrm{d} s~,$$",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            484,
            654,
            520,
            672
          ],
          "text": "(4.19)",
          "reading_order": 9
        },
        {
          "label": "para",
          "bbox": [
            72,
            697,
            520,
            761
          ],
          "text": "We know that the function $F(s/s_\\xi)$ goes very rapidly to zero when $s$ is larger than $s_\\xi$ ,\nand that it is approximately a constant when $s$ is smaller than $s_\\xi$ . We will therefore\napproximate $F(u)$ by a step function which is a constant up to $u=1$ and then 0\nfor $u>1$ . Consequently, we only integrate up to $s_\\xi$ , over a region where $F(s/s_\\xi)$ is",
          "reading_order": 10
        }
      ]
    },
    {
      "page_number": 66,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            269,
            62
          ],
          "text": "4.2 Consequences of the Scaling Ansatz",
          "reading_order": 0
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            152
          ],
          "text": "approximately a constant:\n\\[S(p)=\\int_{1}^{\\infty}s^{2-\\tau}F(s/s_{\\xi})\\,\\mathrm{d} s \\simeq \\int_{1}^{s_{\\xi}}Cs^{2-\\tau}\\,\\mathrm{d} s~.\\]",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            161,
            520,
            286
          ],
          "text": "We solve this integral, finding that\n\\[S(p)=C's_{\\xi}^{3-\\tau}~,\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:defnocurf20}\\]\nwhere $C'$ is a constant. We insert $s_{\\xi}=|p-p_c|^{-1/\\sigma}$ , giving:\n\\[S(p)\\propto\\left(|p-p_c|^{-1/\\sigma}\\right)^{3-\\tau}\\propto|p-p_c|^{\\frac{3-\\tau}{\\sigma}}~.\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:defnocurf20}\\]",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            304,
            520,
            385
          ],
          "text": "We recall that $\\gamma$ we is the scaling exponent of $S(p)$ : $S(p) \\propto |p-p_c|^{-\\gamma}$ . We have\ntherefore found what we call a scaling relation between exponents:\n$$\\gamma=\\frac{3-\\tau}{\\sigma}~. \\eqno(4.23)$$",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            412,
            520,
            510
          ],
          "text": "We for τ We have demonstrated that the average cluster size diverges\nwhen p → p c , which implies that the exponent $\\gamma$ must be positive. In turn, this\nimplies that\n$$\\gamma>0~\\Rightarrow~\\frac{3-\\tau}{\\sigma}>0~\\Rightarrow~3>\\tau~.\\eqno(4.24)$$",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            519,
            511,
            546
          ],
          "text": "We have therefore found a first bound for $\\tau\\colon\\tau<3$ . As an exercise, you can check\nthat this relation holds for the one-dimensional system and the Bethe lattice.",
          "reading_order": 6
        },
        {
          "label": "sec",
          "bbox": [
            72,
            582,
            255,
            600
          ],
          "text": "Density of Spanning Cluster",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            616,
            520,
            663
          ],
          "text": "We may use a similar argument to find the behavior of $P(p)$ from the cluster number\ndensity, which will give us further scaling relations between exponents and another\nbound on the exponent $\\tau$.",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            72,
            680,
            520,
            743
          ],
          "text": "Relation Between $P(p)$ and n(s, p) We recall the general relation\n\\[\\sum_{s}sn(s,p)+P(p)=p~.\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:defn-bounding}\\]",
          "reading_order": 9
        },
        {
          "label": "para",
          "bbox": [
            72,
            752,
            520,
            788
          ],
          "text": "This equation expresses that a site picked at random is occupied with probability p\n(right hand side), and that this site must either be in a finite cluster, with a probability",
          "reading_order": 10
        }
      ]
    },
    {
      "page_number": 67,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            81,
            58
          ],
          "text": "58",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            357,
            44,
            520,
            58
          ],
          "text": "4 Finite-Dimensional Percolation",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            191
          ],
          "text": "corresponding to the sum $\\sum_{s}sn(s,p)$ , or in the infinite cluster with probability\n$P(p)$ . We can therefore find $P(p)$ from\n$$P(p)=p-\\sum_{s}sn(s,p)~.$$\nby calculating the sum on the right hand side.",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            206,
            520,
            313
          ],
          "text": "Finding the Sum Using the Scaling Ansatz We can find the sum over $sn(s,\\,p)$\nwhen $p$ is close to $p_c$ by transforming the sum to an integral and inserting the\nscaling ansatz $n(s,\\,p)=s^{-\\tau}F(s/s_{\\xi})$ :\n$$\\sum_{s=1}^{\\infty}sn(s,\\,p)\\simeq \\sum_{s=1}^{\\infty}ss^{-\\tau}F(s/s_{\\xi})\\;.\\eqno(4.27)$$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            331,
            520,
            403
          ],
          "text": "Again, we approximate the sum with an integral over $s$ :\n\\[\n    \\sum_{s=1}^\\infty s^{1-\\tau} F(s/s_\\xi) \\simeq \\int_1^\\infty s^{1-\\tau}F(s/s_\\xi)ds~.\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:f2}\n  \\]",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            420,
            520,
            519
          ],
          "text": "Here, $F(s/s_\\xi)$ is approximately a constant when $s<s_\\xi$ and goes very rapidly to\nzero when $s>s_\\xi$ , so we integrate up to $s_\\xi$ assuming that $F(s/s_\\xi)$ is a constant $C$\nup to $s_\\xi$ , giving\n$$\\int_1^{\\infty} s^{1-\\tau} F(s/s_\\xi)ds \\simeq \\int_1^{s_\\xi} C s^{1-\\tau} ds=c_1+c_2 s_\\xi^{2-\\tau}~.\\eqno(4.29)$$",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            528,
            520,
            600
          ],
          "text": "We insert this back into the expression for $P(p)$ in ( 4.26 ) getting:\n\\[ P(p)=p-\\sum_{s}sn(s,p)\\simeq p-c_1-c_2s^{2-\\tau}~.\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:lorenz}\\]",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            609,
            520,
            689
          ],
          "text": "Consequences for τ First, we realize that P ( p ) cannot diverge when $p\\rightarrow p_c$ .\nSince s ξ diverges, this means that the exponent $2-\\tau$ must be smaller than or equal\nto zero, otherwise P ( p ) will diverge. This gives us a new bound for τ :",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            706,
            511,
            735
          ],
          "text": "This means that $\\tau$ is bounded by 2 and 3: $2 \\leq \\tau < 3$ . This is an impressive result\nfrom the scaling ansatz.",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 68,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            206,
            62
          ],
          "text": "4.3 Percolation Thresholds",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            502,
            44,
            520,
            58
          ],
          "text": "59",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            161
          ],
          "text": "We the Exponents β and τ We can rewrite the expression in for P( p )\nand insert sξ = s0|p − p c | − 1/σ, getting:",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            170,
            520,
            268
          ],
          "text": "We realize that when $p\\rightarrow p_c$ the linear term $(p-p_c)$ will be smaller than the term\n$|p-p_c|^{(\\tau-2)/\\sigma}$ . And we remember that $P(p)\\propto (p-p_c)^{\\beta}$ . This gives us a new\nscaling relation for $\\beta$ :\n$$\\beta=\\frac{\\tau-2}{\\sigma}~. \\eqno(4.33)$$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            277,
            520,
            313
          ],
          "text": "We have therefore again demonstrated the power of the scaling ansatz by both\ncalculating bounds for $\\tau$ and by finding relations between the scaling exponents.",
          "reading_order": 4
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            340,
            278,
            358
          ],
          "text": "4.3 Percolation Thresholds",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            376,
            520,
            537
          ],
          "text": "While the exponents are universal and independent of the details of the lattice but\ndependent on the dimensionality, the percolation threshold, $p_c$ , depends on details\nof the system such as the lattice type and the type of percolation. We typically\ndiscern between site percolation , where neighboring sites on a lattice are connected\nif present, and bond percolation , where the presence of bonds between the sites\ndetermines the connectivity. Table 4.2 provides basic values for the percolation\nthresholds. These results have been measured with code in this book and therefore\nhave limited precision. You can find an updated set of percolation threshold for\nvarious models on the Wikipedia page for percolation at https://en.wikipedia.org/\nwiki/Percolation_threshold .",
          "reading_order": 6
        },
        {
          "label": "cap",
          "bbox": [
            72,
            564,
            207,
            591
          ],
          "text": "Table 4.2 Percolation\nthresholds for various models",
          "reading_order": 7
        },
        {
          "label": "tab",
          "bbox": [
            385,
            564,
            520,
            680
          ],
          "text": "<table><tr><td>Lattice type</td><td>Site</td><td>Bond</td></tr><tr><td>d = 1</td><td>1</td><td>1</td></tr><tr><td colspan=\"3\">d = 2</td></tr><tr><td>Square</td><td>0.5927</td><td>1/2</td></tr><tr><td>Triangular</td><td>1/2</td><td>0.34</td></tr><tr><td colspan=\"3\">d = 3</td></tr><tr><td>Cubic</td><td>0.3</td><td>0.25</td></tr></table>",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 69,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            84,
            62
          ],
          "text": "60",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            355,
            44,
            520,
            62
          ],
          "text": "4 Finite-Dimensional Percolation",
          "reading_order": 1
        },
        {
          "label": "sec",
          "bbox": [
            72,
            80,
            135,
            98
          ],
          "text": "Exercises",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            116,
            520,
            179
          ],
          "text": "Exercise 4.1 (Alternative Way to Analyze Percolation Clusters) In this exercise\nwe will use python to generate and visualize percolation clusters. We generate a L ×\nL matrix of random numbers, and will examine clusters for a occupation probability\np .",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            179,
            520,
            215
          ],
          "text": "We generate the percolation matrix consisting of occupied (1) and unoccupied\n(0) sites, using",
          "reading_order": 4
        },
        {
          "label": "code",
          "bbox": [
            79,
            224,
            360,
            331
          ],
          "text": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.ndimage import measurements\nL = 100\nr = np.random.rand(L,L)\np = 0.6\nz = r<p # This generates the binary array\nlw, num = measurements.label(z)",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            340,
            520,
            367
          ],
          "text": "We have then produced the array lw that contains labels for each of the connected\nclusters.",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            385,
            520,
            421
          ],
          "text": "(a) Familiarize yourself with labeling by looking at lw, and by studying the second\nexample in the python help system on the image analysis toolbox.",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            94,
            421,
            520,
            450
          ],
          "text": "We can examine the array directly by mapping the labels onto a color-map,\nusing imshow.",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            98,
            465,
            197,
            475
          ],
          "text": "plt.imshow(lw)",
          "reading_order": 9
        },
        {
          "label": "para",
          "bbox": [
            97,
            483,
            520,
            519
          ],
          "text": "We can extract information about the labeled image using measurements,\nfor example, we can extract an array of the areas of the clusters using",
          "reading_order": 10
        },
        {
          "label": "code",
          "bbox": [
            98,
            528,
            376,
            555
          ],
          "text": "labelList = np.arange(lw.max() + 1)\narea = measurements.sum(z, lw, labelList",
          "reading_order": 11
        },
        {
          "label": "para",
          "bbox": [
            93,
            564,
            520,
            663
          ],
          "text": "You can also extract information about the clusters using the skimage.\nmeasure module. This provides a powerful set of tools that can be used to\ncharacterize the clusters in the system. For example, you can determine if a\nsystem is percolating by looking at the extent of a cluster. If the extent in any\ndirection is equal to $L$ , then the cluster is spanning the system. We can use this\nto find the area of the spanning cluster or to mark if there is a spanning cluster:",
          "reading_order": 12
        },
        {
          "label": "code",
          "bbox": [
            98,
            672,
            368,
            806
          ],
          "text": "import skimage\nprops = skimage.measure.regionprops(lw)\nspanning = False\nfor prop in props:\nif (prop.bbox[2]-prop.bbox[0]==L or\nprop.bbox[3]-prop.bbox[1]==L):\n# This cluster is percolating\narea = prop.area\nspanning = True\nbreak",
          "reading_order": 13
        }
      ]
    },
    {
      "page_number": 70,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            108,
            58
          ],
          "text": "Exercise",
          "reading_order": 0
        },
        {
          "label": "para",
          "bbox": [
            71,
            80,
            520,
            109
          ],
          "text": "(b) Using these features, write a program to calculate $P(p,L)$ for various $p$ for the\ntwo-dimensional system.",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            115,
            520,
            179
          ],
          "text": "(c) How robust is your algorithm to changes in boundary conditions? Could you do\na rectangular grid where $L_x\\gg L_y$ ? Could you do a more complicated set of\nboundaries? Can you think of a simple method to ensure that you can calculate\n$P$ for any boundary geometry?",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            196,
            322,
            209
          ],
          "text": "Exercise 4.2 (Finding $\\Pi(p,L)$ and $P(p,L)$ )",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            224,
            520,
            271
          ],
          "text": "(a) Write a program to find $P(p,L)$ and $\\Pi(p,L)$ for $L=2$ , 4, 8, 16, 32, 64, 128.\nComment on the number of samples you need to make to get a good estimate\nfor $P$ and $\\Pi$ .",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            71,
            277,
            520,
            304
          ],
          "text": "(b) Test the program for small $L$ by comparing with the exact results from above.\nComment on the results?",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            322,
            520,
            386
          ],
          "text": "Exercise 4.3 (Determining β ) We know that when p\n>\np c, the probability\n$P(p,L)$ for a given site to belong to the percolation cluster, has the form",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            403,
            520,
            439
          ],
          "text": "Use the data from above to find an expression for $\\beta$ . For this you may need that\n$p_c=0.59275$ .",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            72,
            454,
            520,
            483
          ],
          "text": "Exercise 4.4 (Determining the Exponent of Power-Law Distributions) In this\nexercise you will build tools to analyse power-law type probability densities.",
          "reading_order": 9
        },
        {
          "label": "para",
          "bbox": [
            80,
            483,
            367,
            501
          ],
          "text": "Generate the following set of data-points in python:",
          "reading_order": 10
        },
        {
          "label": "code",
          "bbox": [
            80,
            510,
            323,
            537
          ],
          "text": "import numpy as np\nz = np.random.rand(int(1e6))**(-3+1)",
          "reading_order": 11
        },
        {
          "label": "para",
          "bbox": [
            72,
            546,
            484,
            564
          ],
          "text": "Your task is to determine the distribution function $f_{Z}(z)$ for this distribution.",
          "reading_order": 12
        },
        {
          "label": "para",
          "bbox": [
            72,
            582,
            340,
            593
          ],
          "text": "Hint The distribution is on the form $f(u)\\propto u^{\\alpha}$ .",
          "reading_order": 13
        },
        {
          "label": "para",
          "bbox": [
            72,
            609,
            520,
            689
          ],
          "text": "(a) Find the cumulative distribution, that is, $P(Z>z)$. You can then find the actual\ndistribution from\n\\[f_{Z}(z)=\\frac{dP(Z>z)}{dz}~.\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:defn-bound}\\]",
          "reading_order": 14
        },
        {
          "label": "para",
          "bbox": [
            71,
            698,
            520,
            746
          ],
          "text": "(b) Generate a method to do logarithmic binning in python. That is, you estimate\nthe density by doing a histogram with bin-sizes that increase exponentially in\nsize.",
          "reading_order": 15
        },
        {
          "label": "para",
          "bbox": [
            72,
            768,
            341,
            781
          ],
          "text": "Hint Remember to divide by the correct bin-size.",
          "reading_order": 16
        }
      ]
    },
    {
      "page_number": 71,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            83,
            62
          ],
          "text": "62",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            355,
            44,
            520,
            62
          ],
          "text": "4 Finite-Dimensional Percolation",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            116
          ],
          "text": "Exercise 4.5 (Cluster Number Density n ( s, p )) We will generate the cluster\nnumber density n ( s, p ) from the two-dimensional data-set.",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            125,
            520,
            161
          ],
          "text": "Hint 1 The cluster sizes are extracted using area = measurements.sum(z,\nlw, labelList) as described in a previous exercise.",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            179,
            358,
            193
          ],
          "text": "Hint 2 Remember to remove the percolating cluster.",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            206,
            251,
            225
          ],
          "text": "Hint 3 Use logarithmic binning.",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            241,
            520,
            277
          ],
          "text": "(a) Estimate $n(s,p)$ for a sequence of $p$ values approaching $p_c=0.59275$ from\nabove and below.",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            71,
            277,
            511,
            290
          ],
          "text": "(b) Estimate $n(s,\\,p_c;L)$ for $L=2^{k}$ for $k=4,\\ldots,9$ . Use this plot to estimate $\\tau$ .",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            290,
            475,
            306
          ],
          "text": "(c) Can you estimate the scaling of $s_{\\xi} \\sim\\left|p-p_{c}\\right|^{-1 / \\sigma}$ using this data-set?",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            72,
            322,
            448,
            340
          ],
          "text": "Hint 1 Use $n(s,p)/n(s,p_{c})=F(s/s_{\\xi })=0.5$ as the definition of $s_{\\xi }$.",
          "reading_order": 9
        },
        {
          "label": "sec",
          "bbox": [
            72,
            357,
            271,
            370
          ],
          "text": "Exercise 4.6 (Average Cluster Size)",
          "reading_order": 10
        },
        {
          "label": "para",
          "bbox": [
            72,
            385,
            520,
            421
          ],
          "text": "(a) Find the average (finite) cluster size $S(p)$ for $p$ close to $p_c$, for $p$ above and\nbelow $p_c$.",
          "reading_order": 11
        },
        {
          "label": "para",
          "bbox": [
            71,
            421,
            376,
            451
          ],
          "text": "(b) Determine the scaling exponent $S(p)\\sim|p-p_c|^{-\\gamma}$ .\n(c) In what ways can you generate $S^{(k)}(p)$ ? What do you",
          "reading_order": 12
        },
        {
          "label": "para",
          "bbox": [
            72,
            636,
            520,
            701
          ],
          "text": "Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0\nInternational License ( http://creativecommons.org/licenses/by/4.0/ ), which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as long as you give appropriate\ncredit to the original author(s) and the source, provide a link to the Creative Commons license and\nindicate if changes were made.",
          "reading_order": 14
        },
        {
          "label": "para",
          "bbox": [
            72,
            701,
            518,
            770
          ],
          "text": "The images or other third party material in this chapter are included in the chapter’s Creative\nCommons license, unless indicated otherwise in a credit line to the material. If material is not\nincluded in the chapter’s Creative Commons license and your intended use is not permitted by\nstatutory regulation or exceeds the permitted use, you will need to obtain permission directly from\nthe copyright holder.",
          "reading_order": 15
        }
      ]
    },
    {
      "page_number": 72,
      "elements": [
        {
          "label": "title",
          "bbox": [
            72,
            98,
            269,
            125
          ],
          "text": "Geometry of Clusters",
          "reading_order": 0
        },
        {
          "label": "para",
          "bbox": [
            528,
            98,
            546,
            134
          ],
          "text": "5",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            304,
            520,
            501
          ],
          "text": "We have seen how we can characterize clusters by their mass, $s$ . As $p$ approaches $p_c$ ,\nthe typical cluster size $s$ increases as well as the characteristic cluster diameter. In\nthis chapter we will discuss the geometry of clusters, and by geometry we will mean\nhow the number of sites in a cluster is related to the linear size of the cluster. We\nwill introduce several measures to characterize the spatial extent, the characteristic\nradius $R_{s}$ , of clusters of size $s$ . We will measure $R_{s}$ to motivate that it is proportional\nto $s^1/D$ , where $D$ is a new exponent characterizing the dimension of clusters.\nWe will demonstrate that the percolation system is characterized by two lengths,\nthe system size $L$ and a characteristic cluster size $\\xi$ , and that the system shows\nfractal, self-similar scaling when the characteristic length diverges. We develop\nscaling theories for $P(s, L)$ for $p>p_c$ and lay the foundations for a geometrical\nunderstanding and description of the spanning cluster.",
          "reading_order": 2
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            528,
            307,
            548
          ],
          "text": "5.1 Geometry of Finite Clusters",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            564,
            520,
            680
          ],
          "text": "We have so far studied the clusters in our model porous material, the percolation\nsystem, through the distribution of cluster sizes, $n(s,\\,p)$ , and properties that can be\nfound from $n(s,\\,p)$ , such as the average cluster size, $S$ and the characteristic cluster\nsize, $s_{\\xi}$ . However, clusters with the same mass, $s$ , can have very different shapes.\nFigure 5.1 illustrates three clusters all with $s=20$ sites. Notice that the linear and\nthe compact clusters are unlikely, but possible realizations. How can we characterize\nthe spatial extent of these clusters?",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            680,
            520,
            775
          ],
          "text": "There are many ways to define the extent of a cluster. We could, for example,\ndefine the maximum distance between any two points in a cluster $i$ ( $R_{\\max, i}$ ) to be\nthe extent of the cluster, or we could use the average distance between two points in\nthe cluster. However, it is common to use the standard deviation of the position of\nthe sites in a cluster, which we recognize as the radius of gyration of a cluster. The\nradius of gyration $R_i$ for a cluster $i$ of size $s_i$ with sites at $\\mathbf{r}_j$ for $j=1,\\ldots, s_i$ , is",
          "reading_order": 5
        },
        {
          "label": "foot",
          "bbox": [
            72,
            806,
            396,
            845
          ],
          "text": "© The Author(s) 2024\nA. Malthe-Sørenssen, Percolation Theory Using Python, Lecture Notes\nin Physics 1029, https://doi.org/10.1007/978-3-031-59900-2_5",
          "reading_order": 6
        },
        {
          "label": "foot",
          "bbox": [
            506,
            806,
            520,
            816
          ],
          "text": "63",
          "reading_order": 7
        }
      ]
    },
    {
      "page_number": 73,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            84,
            62
          ],
          "text": "64",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            394,
            44,
            513,
            62
          ],
          "text": "5 Geometry of Cluster",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_073_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_073_figure_002.png",
          "bbox": [
            72,
            80,
            520,
            215
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            223,
            520,
            250
          ],
          "text": "Fig. 5.1 Illustrations of three clusters all with $s=24$ . The red circle illustrates the radius of\ngyration for the clusters",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            277,
            126,
            289
          ],
          "text": "defined as",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            304,
            520,
            396
          ],
          "text": "_",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            396,
            520,
            483
          ],
          "text": "As we see from Fig. 5.1 , clusters of the same size $s$ can have different radii. How\ncan we then find a characteristic size for a given cluster size $s$ ? We find that by\naveraging $R_i^2$ over all clusters of the same size $s$ :\n\\[ R_s^2=\\langle R_i^2\\rangle_i~.\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eqn:frequiring}\\]",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            498,
            511,
            528
          ],
          "text": "Let us see how this can be done analytically in one dimension and numerically if\ntwo dimensions.",
          "reading_order": 7
        },
        {
          "label": "sec",
          "bbox": [
            72,
            555,
            308,
            575
          ],
          "text": "Analytical Results in One Dimension",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            72,
            591,
            520,
            716
          ],
          "text": "We can use the one-dimensional percolation system to gain insight into how we\nexpect $R_s$ to depend on $s$ . In one dimension, a cluster of size $s$ can only be realized\nin one way, as a line of length $s$ . If the cluster runs from 1 to $s$ , the center of mass is\nat $s/2$ , and the sum over all sites runs from 1 to $s$ :\n\\[ R_s^2=\\frac{1}{s}\\sum_{i=1}^s(i-s/2)^2~,\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eqn:lorenz}\\]",
          "reading_order": 9
        }
      ]
    },
    {
      "page_number": 74,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            225,
            62
          ],
          "text": "5.1 Geometry of Finite Clusters",
          "reading_order": 0
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            286
          ],
          "text": "where we assume that $s$ is so large that we only need to address the leading term in\n$s$ , and that we do not have to treat even and odd $s$ separately. This can be expanded\nto\n\\[R_{s}^2=\\frac{1}{s}[\\sum_{i=1}^{s} i^2-is+\\frac{s^2}{4}]=\\frac{1}{s}\\left[\\frac{s(s+1)(2s+1)}{6}-s\\frac{s(s+1)}{2}+s\\frac{s^2}{4}\\right]\\propto s^2~,\\]\n\n(5.4)\n\nwhere we have used that $\\sum_{i=1}^{s} s^2=s(s+1)(2s+1)/6$ and $\\sum_{i=1}^{s} s=s(s+1)/2$\nand where we only have kept the leading term in $s$ . This shows that $R_{s}^2\\propto s^2$ , which\nmeans that $s\\propto R_{s}$ in one dimension. This is indeed what we expected. The extent\nof the cluster is proportional to $s$ because the cluster is $s$ sites long.",
          "reading_order": 2
        },
        {
          "label": "sec",
          "bbox": [
            72,
            313,
            316,
            331
          ],
          "text": "Numerical Results in Two Dimensions",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            349,
            520,
            460
          ],
          "text": "For the one-dimensional system we found that $s\\propto R_{s}$ . How does this generalize to\nhigher dimensions? We start by measuring the behavior for a given value of $p$ for a\nfinite system of size $L$ . Our strategy is: (i) to generate clusters on a $L\\times L$ lattice;\n(ii) for each cluster, $i$ , of size $s_i$ , we will find the center of mass and the radius of\ngyration, $R^2_i$ ; and (iii) for each value of $s$ we will find the average radius, $R^2_s$ , by\na linear average. For larger values of $s$ we will collect the data in bins, using the\nlogarithmic binning approach we developed to measure $n(s,~p)$ .",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            474,
            520,
            601
          ],
          "text": "Developing a Function to Measure $R_s$ First, we introduce a function to calculate\nthe radius of gyration of all the clusters in a lattice. This is done in two steps, first\nwe find the center of mass of all clusters, and then we find the radius of gyration.\nThe center of mass for a cluster $i$ with sites at $\\mathbf{r}_{i,j}$ for $j=1,\\ldots,s_i$ , is\n$$\\mathbf{r}_{cm,i}=\\frac{1}{s_i}\\sum_{j=1}^{s_i}\\mathbf{r}_{i,j}~,\\eqno(5.5)$$",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            618,
            520,
            645
          ],
          "text": "We generate a lattice, ensure that each cluster are marked with the index of the\ncluster, and find the center of mass cm using a built-in command:",
          "reading_order": 6
        },
        {
          "label": "code",
          "bbox": [
            79,
            663,
            421,
            743
          ],
          "text": "L = 400\np = 0.58\nz = np.random.rand(L,L)\nm = z<p\nlw, num = measurements.label(m)\ncm = measurements.center_of_mass(m, lw, labelList)",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            752,
            520,
            797
          ],
          "text": "Second, we calculate the radius gyration by running through all the sites ix,iy in\nthe lattice. For each site, we find the index i of the cluster that it belongs to from i\n= lw[ix, iy] . If the site belongs to a cluster, that is if i>0 , we add the sum of",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 75,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            83,
            58
          ],
          "text": "66",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            401,
            44,
            513,
            62
          ],
          "text": "5 Geometry of Cluster",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            109
          ],
          "text": "the square of the distance from the site to the center of mass to the radius of gyration\nfor cluster $i$ :",
          "reading_order": 2
        },
        {
          "label": "code",
          "bbox": [
            80,
            125,
            304,
            152
          ],
          "text": "dr = np.array([ix,iy])-cm[i]\nrad2[i] = rad2[2] + np.dot(dr,dr)",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            161,
            520,
            250
          ],
          "text": "After running through all the site, we divide by the mass (size) $s_i$ of each cluster to\nfind the radius of gyration according to the formula\n\\[R^2_i=\\frac{1}{s_i}\\sum_{j=1}^{s_i}\\left(\\mathbf{r}_{i,j}-\\mathbf{r}_{cm,i}\\right)^2~,\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:framing}\\]",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            268,
            322,
            282
          ],
          "text": "This is implemented in the following function:",
          "reading_order": 5
        },
        {
          "label": "code",
          "bbox": [
            80,
            295,
            340,
            333
          ],
          "text": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.ndimage import measurements",
          "reading_order": 6
        },
        {
          "label": "code",
          "bbox": [
            80,
            349,
            448,
            537
          ],
          "text": "def radiusofgyration(m, lw, L):\nlabelList = np.arange(lw.max() + 1)\narea = measurements.sum(m, lw, labelList)\ncm = measurements.center_of_mass(m, lw, labelList)\nrad2 = np.zeros(int(lw.max()+1))\nfor ix in range(L):\nfor iy in range(L):\nilw = lw[ix, iy];\nif (ilw>0):\ndr = np.array([ix, iy])-cm[ilw]\ndr2 = np.dot(dr, dr)\nrad2[ilw] = rad2[ilw] + dr2\nrad = np.sqrt(rad2/area)\nreturn area, cm, rad2",
          "reading_order": 7
        },
        {
          "label": "code",
          "bbox": [
            79,
            546,
            378,
            708
          ],
          "text": "M = 20\n# Nr of samples\nL = 400\n# System size\np = 0.58 # p-value\nallr2 = np.array([])\nallarea = np.array([])\nfor i in range(M):\nz = np.random.rand(L,L)\nm = z<p\nlw, num = measurements.label(m)\narea,rcm,rad2 = radiusofgyration(m,1w,L)\nallr2 = np.append(allr2,rad2)\nallarea = np.append(allarea,area)",
          "reading_order": 8
        },
        {
          "label": "code",
          "bbox": [
            79,
            725,
            287,
            735
          ],
          "text": "plt.loglog(allarea,allr2,‘k.’)",
          "reading_order": 9
        },
        {
          "label": "para",
          "bbox": [
            72,
            743,
            520,
            779
          ],
          "text": "We use this function to calculate the average radius of gyration for each cluster size\ns for M different lattice realizations, and plot the results using the following script:",
          "reading_order": 10
        }
      ]
    },
    {
      "page_number": 76,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            225,
            62
          ],
          "text": "5.1 Geometry of Finite Clusters",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            506,
            44,
            512,
            62
          ],
          "text": "6",
          "reading_order": 1
        },
        {
          "label": "code",
          "bbox": [
            79,
            80,
            378,
            286
          ],
          "text": "M = 20\n# Nr of samples\nL = 400\n# System size\np = 0.58 # p-value\nallr2 = np.array([])\nallarea = np.array([])\nfor i in range(M):\nz = np.random.rand(L,L)\nm = z<p\nlw, num = measurements.label(m)\narea,rcm,rad2 = radiusofgyration(m,lw,L)\nallr2 = np.append(allr2,rad2)\nallarea = np.append(allarea,area)\nplt.loglog(allarea,allr2,'k.')\nplt.xlabel(\"$s$\")\nplt.ylabel(\"$R_s^2$\")",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            304,
            520,
            404
          ],
          "text": "Scaling Behavior of the Radius of Gyration The resulting plots for several values\nof $p$ are shown in Fig. 5.2 . We see that there is an approximately linear relation\nbetween $R_s^2$ and $s$ in this double-logarithmic plot, which indicates that there is a\npower-law relationship between the two:\n\\[ R_s^2 \\propto s^x~.\\eqno(5.7)\\]",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            421,
            520,
            485
          ],
          "text": "How can we interpret this relation? Equation ( 5.7 ) relates the radius $R_s$ and the area\n(or mass) of the cluster. We are more used to the inverse relation:\n\\begin{equation}\n    s \\propto R^D_s~,\n    \\end{equation}",
          "reading_order": 4
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_076_figure_005.png)",
          "figure_path": "figures/percolation_studies_page_076_figure_005.png",
          "bbox": [
            72,
            510,
            511,
            752
          ],
          "reading_order": 5
        },
        {
          "label": "cap",
          "bbox": [
            72,
            761,
            520,
            806
          ],
          "text": "Fig. 5.2 Plot of $R_s^2$ as function of $s$ for simulations on two-dimensional systems with $L=400$ .\nThe largest cluster for each value of $p$ is illustrated by a circle. The dotted line shows the curve\n$R_s^2\\propto s^{2/D}$ for $D=1.89$",
          "reading_order": 6
        }
      ]
    },
    {
      "page_number": 77,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            81,
            58
          ],
          "text": "68",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            401,
            44,
            520,
            62
          ],
          "text": "5 Geometry of Clusters",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            306
          ],
          "text": "where $D=2/x$ is the exponent relating the radius to the mass of a cluster. This\ncorresponds to our intuition from geometry. We know that for a cube of size $L$ , the\nmass (or volume) of the cube is $M=L^3$ . For a square of length $L$ , the mass (or area)\nis $M=L^2$ , and similarly for a circle $M=\\pi R^2$ , where $R$ is the radius of the circle.\nFor a line of length $L$ , the mass is $M=L^1$ . We see a general trend, $M\\propto R^d$ , where\n$R$ is a characteristic length for the object, and $d$ describes the dimensionality of the\nobject. If we extend this intuition to the relation in ( 5.8 ) , which is an observation\nbased on Fig. 5.2 , we see that we may interpret $D$ as the dimension of the cluster.\nHowever, the value of $D$ is not an integer. We have indicated the value of $D=1.89$\nwith a dotted line in Fig. 5.2 . This non-integer value of $D$ may seem strange, but it\nis fully possible, mathematically, to have non-integer dimensions. This is a feature\nfrequently found in fractal structures, and percolation clusters as $p$ approaches $p_c$\nare indeed good examples of self-similar fractals. We will return to this aspect of\nthe geometry of the percolation system in Sect. 5.3 .",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            322,
            520,
            456
          ],
          "text": "Characteristic Cluster Radius The largest cluster and its corresponding radius\nof gyration is indicated by a circle for each $p$ value in Fig. 5.2 . We see that as $p$\napproaches $p_c$ , both the mass and the radius of the largest cluster increases. Indeed,\nthis corresponds to the observation we have previously made for the characteristic\ncluster size, $s_\\xi$ . We may define a corresponding characteristic cluster radius , $R_{s_\\xi}$\nthrough\n$$ s_\\xi \\propto R^D_{s_\\xi}  \\quad \\Longleftrightarrow \\quad R_{s_\\xi} \\propto s^{1/D}_\\xi \\; . \\eqno(5.9)$$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            472,
            520,
            519
          ],
          "text": "This length is a characteristic length for the system for a given value of $p$ ,\ncorresponding to the largest cluster size or the typical cluster size in the system. In\nSect. 5.2 we see how we can relate this length directly to the cluster size distribution.",
          "reading_order": 4
        },
        {
          "label": "sec",
          "bbox": [
            72,
            546,
            308,
            566
          ],
          "text": "Scaling Behavior in Two Dimensions",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            582,
            518,
            806
          ],
          "text": "We have already found that the characteristic cluster size $s_\\xi$ diverges as a power law\nas $p$ approaches $p_c$ :\n$$ s_\\xi \\simeq s_0\\,(p-p_c)^{-1/\\sigma} \\;\\;, \\eqno(5.10)$$\nwhen $p<p_c$ . The behavior is similar when $p>p_c$ , but the prefactor $s_0$ may\nbe different. How does $R_{s_\\xi}$ behave when $p$ approaches $p_c$ ? We can find this by\ncombining the scaling relations for $s_\\xi$ and $R_{s_\\xi}$ from ( 5.9 ) :\n$$ R_{s_\\xi} \\propto s_\\xi^{1/D} \\propto \\Big((p-p_c)^{-1/\\sigma}\\Big)^{1/D} \\propto (p-p_c)^{-1/\\sigma D} \\;\\;, \\eqno(5.11)$$\nwhere we introduce the symbol $v=1/(\\sigma\\,D)$ . For two-dimensional percolation, the\nexponent $v$ is a universal number, just like $\\sigma$ and $D$ . By universal, we mean that it",
          "reading_order": 6
        }
      ]
    },
    {
      "page_number": 78,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            217,
            58
          ],
          "text": "5.2 Characteristic Cluster Size",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            502,
            44,
            520,
            58
          ],
          "text": "69",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            127
          ],
          "text": "does not depend on details such as the lattice type or the connectivity of the lattice,\nalthough it does depend on the dimensionality of the system. We know the exact\nvalue of $v$ in two dimensions, $\\nu=4/3$ .",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            127,
            520,
            179
          ],
          "text": "The argument we have provided here is an example of a scaling argument. In\nthese arguments we are only interested in the exponent in the scaling relation, which\ngives us the functional form, and not in the values of the prefactors.",
          "reading_order": 3
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            206,
            297,
            224
          ],
          "text": "5.2 Characteristic Cluster Size",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            241,
            520,
            340
          ],
          "text": "We have now defined the characteristic size of a cluster of size $s$ through $R_{s}$ . In\naddition, we introduced a characteristic cluster length $R_{s_{\\xi}}$ , which characterizes the\nwhole system and not only clusters of a particular size $s$ . However, there are several\nways we can introduce a length scale to describe the typical cluster size in a system.\nHere, we will introduce two such measures, the average radius of gyration $R$ and\nthe characteristic length $\\xi$ .",
          "reading_order": 5
        },
        {
          "label": "sec",
          "bbox": [
            72,
            367,
            251,
            386
          ],
          "text": "Average Radius of Gyration",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            403,
            520,
            519
          ],
          "text": "We have now defined the characteristic length $R_{s_\\xi}$ through the definition of the\ncharacteristic cluster size, $s_\\xi$ , and the scaling relation $s \\propto R^D_s$ . However, it may be\nmore natural to define the characteristic length of the system as the average radius\nand not the cut-off radius. We introduced the radius of gyration for clusters of size\n$s$ by averaging the radius of gyration $R_i$ over all clusters $i$ of size $s$ :\n$$\nR^2_s=\\langle R^2_i\\rangle_i~, ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            536,
            511,
            566
          ],
          "text": "This gives us the radius of gyration $R_s$ , which we found to scale with cluster mass\nas $s\\propto R_s^D$ .",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            72,
            582,
            520,
            665
          ],
          "text": "Introducing an Average Cluster Radius For the cluster sizes, we introduced an\naverage cluster size $S$ , which is\n\\[ S=\\frac{1}{Z_S}\\sum_s s\\:sn(s,p)~,~ Z_S=\\sum_s sn(s,p)~.\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:l2-step}\\]",
          "reading_order": 9
        },
        {
          "label": "para",
          "bbox": [
            72,
            680,
            520,
            761
          ],
          "text": "We can also similarly introduce an average radius of gyration , $R$ , by averaging $R_s$\nover all cluster sizes:\n\\[ R=\\frac{1}{Z_R}\\sum_s R^2_s s^k sn(s,p)~,~~ Z_R=\\sum_s s^ksn(s,p)~.\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:lorenz}\\]",
          "reading_order": 10
        }
      ]
    },
    {
      "page_number": 79,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            81,
            58
          ],
          "text": "70",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            401,
            44,
            520,
            62
          ],
          "text": "5 Geometry of Clusters",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_079_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_079_figure_002.png",
          "bbox": [
            72,
            80,
            520,
            322
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            338,
            513,
            362
          ],
          "text": "Fig. 5.3 A plot of the average radius of gyration $R$ as a function of $p$ and $L$ . We observe that $i$\nincreases as $p\\rightarrow p_c$ , but is limited in magnitude by the finite system size $L$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            394,
            520,
            636
          ],
          "text": "Here, we have purposely introduced an unknown exponent $k$ . We are to some\nextent free to choose this exponent, although the average needs to be finite, and\nthe exponent will determine how small and large clusters are weighed in the sum.\nA natural choice may be to choose $k=1$ so that we get terms $R_s^2 s^2 n(s,\\,p)$ in the\nsum. However, the results we present here will not change in any significant way,\nexpect for different prefactors to the scaling relations, if you choose a larger value\nof $k$ . Using $k=1$ , we define the average radius of gyration to be\n$$R=\\frac{1}{Z_R}\\sum_s R_s^2 s^2 n(s,\\,p)\\;,\\; Z_R=\\sum_s s^2 n(s,\\,p)\\;,\\eqno(5.15)$$\nwhere $S$ , $Z_R=S$ we notice shows that a plot the normalization of the average sum $R$ as $Z_R$ is a function the average of cluster $p$ for size various sizes $L$ . We see that $R$ diverges as $p$ approaches $p_c$ . How can we develop a theory",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            654,
            520,
            716
          ],
          "text": "A Scaling Form for R We know that the cluster number density $n(s,\\,p)$ has the\napproximate scaling form\n$$ n(s,\\,p)= s^{-\\tau}\\, F\\left(s/s_{\\xi}\\right)~,~s_{\\xi}\\propto|\\, p-p_c|^{-1/\\sigma}~.\\eqno(5.16)$$",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            734,
            520,
            764
          ],
          "text": "We can use this to calculate the average radius of gyration, $R$ , when p is close to\np c . We find the scaling behavior of the average radius of gyration by replacing the",
          "reading_order": 6
        }
      ]
    },
    {
      "page_number": 80,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            218,
            62
          ],
          "text": "5.2 Characteristic Cluster Size",
          "reading_order": 0
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            528,
            450
          ],
          "text": "sums over $s$ with integrals over $s$ :\n\\begin{align}\nR^2&=\\frac{\\sum_s R_s^2 s^2 n(s,p)}{\\sum_s s^2 n(s,p)}=\\frac{\\int_1^\\infty R_s^2 s^{2-\\tau} F(s/s_\\xi)\\mathop{}\\!\\mathrm{d} s}{\\int_1^\\infty s^{2-\\tau}F(s/s_\\xi)\\mathop{}\\!\\mathrm{d} s}\\\\\n&\\propto \\frac{\\int_1^\\infty s^{2/D} s^{2-\\tau} F(s/s_\\xi)\\mathop{}\\!\\mathrm{d} s}{\\int_1^\\infty s^{2-\\tau} F(s/s_\\xi)\\mathop{}\\!\\mathrm{d} s}~,\n\\end{align}\nwhere we have inserted $R_s^2\\propto s^{2/D}$ . While this expression only is valid when $s<s_\\xi$ , we can apply it here since $F(s/s_\\xi)$ goes rapidly to zero when $s>s_\\xi$ , and\ntherefore only the $s<s_\\xi$ values will contribute significantly to the integral. We\nchange variables to $u=s/s_\\xi$ , getting:\n\\begin{align*}\n    R^2&\\propto \\frac{s_\\xi^{2/D+3-\\tau}\\int_{1/s_\\xi}^\\infty u^{2/D+2-\\tau} F(u)\\mathop{}\\!\\mathrm{d} u}{s_\\xi^{3-\\tau}\\int_{1/s_\\xi}^\\infty u^{2-\\tau} F(u)\\mathop{}\\!\\mathrm{d} u}\\\\\n    &\\propto s_\\xi^{2/D}\\frac{\\int_0^\\infty u^{2/D+2-\\tau} F(u)\\mathop{}\\!\\mathrm{d} u}{\\int_0^\\infty u^{2-\\tau} F(u)\\mathop{}\\!\\mathrm{d} u}\\propto s_\\xi^{2/D}~,\n\\end{align*}",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            465,
            520,
            636
          ],
          "text": "The Characteristic Lengths Are Proportional This shows that $R^2\\propto s_{\\xi}^{2/D}$ . We\nfound above that $R_{s_{\\xi}}\\propto s_{\\xi}^{2/D}$ . Therefore, $R\\propto R_{s_{\\xi}}!$ These two characteristic\nlengths therefore have the same behavior. They are only different by a constant\nof proportionality, $R=c~R_{s_{\\xi}}$ . We can therefore use either length to characterize the\nsystem — they are effectively the same up to a prefactor. This is not only true for\nthese two lengths, but all lengths have the same asymptotic scaling behavior close\nto $p_c$ . For example, Fig. 5.4 illustrates the radius of gyration of the largest cluster\nwith a circle and the average radius of gyration, $R$ , by the length of the side of the\nsquare. As $p$ increases, both the maximum cluster size and the average cluster size\nincreases in concert.",
          "reading_order": 3
        },
        {
          "label": "sec",
          "bbox": [
            72,
            663,
            197,
            683
          ],
          "text": "Correlation Length",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            698,
            520,
            797
          ],
          "text": "We can also define the typical size of a cluster from the correlation function. We\nrecall that the correlation function $g(r,\\,p)$ is the probability that an occupied site $i$\nat $\\mathbf{r}_i$ is connected to a site $j$ at $\\mathbf{r}_j$ , where $\\mathbf{r}=\\mathbf{r}_j-\\mathbf{r}_i$ and $r=|\\mathbf{r}|$ . The correlation\nfunction is only a function of the relative position of the two sites, $\\mathbf{r}$ , which we\nusually only write as $r$ , because we assume that the correlation function is isotropic.\nWe define the correlation length, $\\xi$ , as the average squared distance between two",
          "reading_order": 5
        }
      ]
    },
    {
      "page_number": 81,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            80,
            58
          ],
          "text": "7:",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            394,
            44,
            520,
            62
          ],
          "text": "5 Geometry of Clusters",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_081_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_081_figure_002.png",
          "bbox": [
            71,
            80,
            520,
            232
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            241,
            520,
            295
          ],
          "text": "Fig. $p=0.59$ 5.4 Illustration of the largest cluster in $512\\times512$ systems for $p=0.55$ , $p=0.57$ , and . The circles illustrate the radius of gyration of the largest cluster, and the boxes show the size\nof the average radius of gyration, $R=\\langle R_{s}\\rangle$ . We observe that both lengths increase approximately\nproportionally as $p$ approaches $p_c$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            322,
            153,
            340
          ],
          "text": "connected sites",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            349,
            520,
            483
          ],
          "text": "$$\\xi^{2}=\\frac{\\sum_{\\mathbf{r}} r^{2} g(r ; p)}{\\sum_{\\mathbf{r}} g(r ; p)} .\\qquad(5.21)$$\nwhere the sum is over all relative positions $\\mathbf{r}$, that is, over all space. The denominator\nis a normalization sum, which corresponds to the average cluster size, $S$. This length\nis called the correlation length. However, to gain insight into this length, we will first\naddress the correlation function, its scaling behavior and its relation to the average\ncluster size $S$.",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            501,
            520,
            630
          ],
          "text": "In System In Chap. 2 we found that for a one-dimensional system,\nthe correlation function $g(r;\\,p)$ is\n$$g(r)=p^{r}=e^{-r/\\xi}~, \\eqno(5.22)$$\nwhere $\\xi=-\\frac{1}{\\ln p}=\\simeq 1/(1-p_c)$ is called the correlation length . The correlation\nlength diverges as $p\\rightarrow p_c=1$ as $\\xi\\simeq (1-p_c)^{-v}$ , where $v=1$ .",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            630,
            520,
            761
          ],
          "text": "general scaling form for the one-dimensional system\n\\[g(r;\\,p)=r^0f(r/\\xi)~,\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:gamma_bound}\\]\nwhere $f(u)$ is a function that decays rapidly when $u$ is larger than 1. We will assume\nthat this behavior can be generalized to higher dimension. That is, we expect the\ncorrelation function to decay rapidly beyond a length, $\\xi$ , that corresponds to the\ntypical extent of clusters in the system.",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            778,
            520,
            806
          ],
          "text": "Measuring the Correlation Function For a two- or three-dimensional system,\nwe cannot find the exact form of the correlation function, like we could in one",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 82,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            218,
            62
          ],
          "text": "5.2 Characteristic Cluster Size",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            509,
            44,
            520,
            58
          ],
          "text": "73",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            259
          ],
          "text": "dimension. However, we can still measure it from our simulations, although such\nmeasurements typically are computationally intensive. How can we measure it?\nWe can loop through all sites $i$ and $j$ and find their distance $r_{ij}$ . We estimate the\nprobability for two sites at a distance $r_{ij}$ to be connected by counting how many\nof the sites that are a distance $r_{ij}$ apart that are connected and compare it to how\nmany sites in total that are a distance $r_{ij}$ apart. This is done through the following\nprogram, which returns the correlation function g(r) estimated for a lattice lw\nwhich contains the cluster indexes for each site, similar to what is returned by\nthe lw, num = measurements.label(m) command. We write a subroutine\nperccorrfunc to find the correlation function for a given lattice lw , and then we\nuse this function to find the correlation function for several values of p and L :",
          "reading_order": 2
        },
        {
          "label": "code",
          "bbox": [
            80,
            268,
            457,
            618
          ],
          "text": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.ndimage import measurements\nfrom numba import jit\n@jit\ndef perccorrfunc(m,lw,L):\nr = np.arange(2*L) # Positions\npr = np.zeros(2*L)\n# Correlation function\nnpr = np.zeros(2*L)\n# Nr of elements\nfor ix1 in range(L):\nfor iy1 in range(L):\nlw1 = lw[ix1,iy1]\nif (lw1>0):\nfor ix2 in range(L):\nfor iy2 in range(L):\nlw2 = lw[ix2,iy2]\nif (lw2>0):\ndx = (ix2-ix1)\ndy = (iy2-iy1)\nrr = np.hypot(dx,dy)\n# Find corresponding box\nnr = int(np.ceil(rr)+1)\npr[nr] = pr[nr] + (lw1==lw2\nnpr[nr] = npr[nr] + 1\npr = pr/npr\nreturn r,pr",
          "reading_order": 3
        },
        {
          "label": "code",
          "bbox": [
            79,
            633,
            304,
            791
          ],
          "text": "# Calculate correlation function\nM = 20 # Nr of samples\nL = 800 # System size\npp = [0.57,0.58,0.59] # p-value\nlenpp = len(pp)\npr = np.zeros((2*L,lenpp),float)\nrr = np.zeros((2*L,lenpp),float)\nfor i in range(M):\nprint(\"i = \",i)\nz = np.random.rand(L,L)\nfor ip in range(lenpp):\np = pp[ip]",
          "reading_order": 4
        }
      ]
    },
    {
      "page_number": 83,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            84,
            62
          ],
          "text": "74",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            394,
            44,
            520,
            62
          ],
          "text": "5 Geometry of Clusters",
          "reading_order": 1
        },
        {
          "label": "code",
          "bbox": [
            79,
            80,
            349,
            179
          ],
          "text": "m = z<p\nlw, num = measurements.label(m)\nr,g = perccorrfunc(m,lw,L)\npr[:,ip] = pr[:,ip] + g\nrr[:,ip] = rr[:,ip] + r\npr = pr/M\nr = r/M",
          "reading_order": 2
        },
        {
          "label": "code",
          "bbox": [
            79,
            188,
            493,
            243
          ],
          "text": "# Plot data ­ linearly binned\nfor ip in range(lenpp):\nplt.loglog(rr[:,ip],pr[:,ip],’.’,label=\"p=\"+gtr(pp[ip]))\nplt.legend()",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            250,
            520,
            461
          ],
          "text": "Figure 5.5 shows the resulting plots of the correlation function $g(r;\\,p)$ for various\nvalues of $p$ for an $L=400$ system. First, we notice that the scaling is rather poor.\nWe will understand this as we develop a theory for $g(r;\\,p)$ below. The plot shows\nthat there also in two dimensions appear to be a cross-over length $\\xi$ , which we call\nthe correlation length, beyond which the correlation function falls rapidly to zero.\nFor $r<\\xi$ the correlation function appears to approximately be a power-law. Based\non our experience with percolation systems, we suggests the following functional\nform\n$$g(r;\\,p)=r^{-x}f(r/\\xi)~,\\eqno(5.24)$$\nwhere the cross-over function $f(u)$ falls rapidly to zero when $u>1$ and\nis approximately constant when $u<1$ . We expect that as $p$ approaches $p_c$ ,",
          "reading_order": 4
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_083_figure_005.png)",
          "figure_path": "figures/percolation_studies_page_083_figure_005.png",
          "bbox": [
            98,
            492,
            493,
            745
          ],
          "reading_order": 5
        },
        {
          "label": "cap",
          "bbox": [
            72,
            761,
            520,
            806
          ],
          "text": "Fig. 5.5 A plot of $g(r;\\,p)$ as a function of $r$ for various values of $p$ . When $p$ approaches $p_c$ the\nfunction approaches a power-law behavior $g(r) \\propto r^{-\\eta}$ , which is illustrated by a dashed line with\n$\\eta=0.208$ . Notice the rapid cross-over for large $r$ , which occurs at a characteristic length $\\xi$",
          "reading_order": 6
        }
      ]
    },
    {
      "page_number": 84,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            217,
            58
          ],
          "text": "5.2 Characteristic Cluster Size",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            502,
            44,
            512,
            58
          ],
          "text": "7",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            514,
            125
          ],
          "text": "the correlation length $\\xi$ grows to infinity, and the correlation function $g(r;p_c)$\napproaches a power-law $r^{-x}$ for all values of $r$ up to a length limited by the system\nsize $L$ .",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            143,
            520,
            225
          ],
          "text": "Based the Correlation Function to S( p ) Based on these observations, we are\nmotivated to develop a theory for the behavior of the correlation function. Our plan\nis first to relate the correlation function $g(r;\\,p)$ to the average cluster size $S(p)$ and\nthen use what we know about the behavior of $S(p)$ to determine the behavior of\n$g(r;\\,p)$ .",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            225,
            520,
            340
          ],
          "text": "How can we relate $g(r;\\,p)$ to $S(p)$ ? We notice that $S(p)$ is the average number\nof sites in a cluster, that is, the average number of sites connected to a given\noccupied site. We can therefore find $S(p)$ by summing the probability for a site\nto be connected for all possible relative positions ${\\bf r}$ :\n$$ S(p)=\\sum_{{\\bf r}} g(r;\\,p)~. \\eqno(5.25)$$",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            349,
            520,
            546
          ],
          "text": "We approximate the sum by an integral:\n\\[S(p) = \\sum_{\\mathbf r} g(r;\\, p) \\simeq \\int g(r) \\, \\mathrm d r^d~,\\]\nwhere the integral is over a volume in space corresponding to all relative positions\n$\\mathbf r$ . We change integration variables to the radial distance $r$ and the solid angle $\\Omega$\n\\[S(p) \\simeq \\int g(r) \\mathrm d r^d = \\int \\int g(r) r^{d-1} \\, \\mathrm d r \\, \\, \\mathrm d \\Omega~,\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:f20bound}\\]\nwhere the integral is from $r=0$ to $r\\to\\infty$ and over all solid angles $\\Omega$ .",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            555,
            520,
            672
          ],
          "text": "Average Cluster Size at $p_c$ We know that when p → p c, then the average cluster\nsize, S , diverges. At p = p c , the scaling form for the correlation function in ( 5.24 )\nis g ( r ; p ) ∝ r − x . The condition that the integral in ( 5.27 ) must diverge therefore\nprovides bounds for the exponent x :\nS ( p c ) ≃ ∫∫r − x r d − 1 d r d Ω = c ∫ 1 ◦ r − x + d − 1 d r . (5.28)",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            680,
            520,
            765
          ],
          "text": "This integral diverges when $-x+d>0$ , that is, for $x<d$ . It is common to\nintroduce an exponent $\\eta$ so that $x=(d-2+\\eta)$ . The condition for $S(p_c)$ to diverge\nis then $2-\\eta>0$ . The correlation function at $p_c$ is then:\n$$g(r;\\, p_c)\\propto r^{-(d-2)-\\eta}~. \\eqno(5.29)$$",
          "reading_order": 7
        }
      ]
    },
    {
      "page_number": 85,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            83,
            58
          ],
          "text": "76",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            394,
            44,
            520,
            62
          ],
          "text": "5 Geometry of Clusters",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            511,
            111
          ],
          "text": "This is consistent with what we found for the one-dimensional system where $x=$\nand $\\eta=1$ .",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            125,
            520,
            215
          ],
          "text": "Finding $S(p)$ for p below $p_c$ We use the scaling form of $g(r;\\,p)$ in to\ncalculate the integral in ( 5.27 ) for $p<p_c$ :\n$$S(p)\\simeq\\int\\int r^{-(d-2)-\\eta}f(\\frac{r}{\\xi})r^{d-1}\\,\\mathrm{d}r\\,\\mathrm{d}\\Omega=c\\int_{1}^{\\infty}r^{1-\\eta}f(\\frac{r}{\\xi})\\,\\mathrm{d}r~.\\eqno(5.30)$$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            224,
            520,
            340
          ],
          "text": "We change variables by introducing $u=r/\\xi$ and realize that $f(u)$ is approximately\na constant for $u<1$ and zero for $u>1$ . We therefore use 1 as the upper limit for\nthe integral since $f(u)$ rapidly goes to zero beyond $u=1$ .\n\n$$\nS(p) \\simeq c \\int_{1 / \\xi}^{\\infty} \\xi^{2-\\eta} u^{1-\\eta} f(u) \\mathrm{d} u=c \\xi^{2-\\eta} \\int_{1 / \\xi}^{1} u^{1-\\eta} \\mathrm{d} u=c \\xi^{2-\\eta}\\left(1-\\xi^{-(2-\\eta)}\\right) .\n$$\n\n(5.31)",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            357,
            520,
            422
          ],
          "text": "Because $2-\\eta>0$ , we see that $\\xi^{-(2-\\eta)}$ approaches zero as $p$ approaches $p_c$ and $\\xi$\ngrows. The right-hand term is therefore approximately 1, and we get:\n$$S(p)\\propto \\xi^{2-\\eta}~. \\eqno(5.32)$$",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            439,
            520,
            548
          ],
          "text": "We also know that $S(p)\\propto|p-p_c|^{-\\gamma}$ so that\n$$ S(p)\\propto \\xi^{2-\\eta}\\propto|p-p_c|^{-\\gamma}\\quad \\Rightarrow\\quad \\xi\\propto|p-p_c|^{-\\gamma/(2-\\eta)}=|p-p_c|^{-v}~,\\eqno(5.33)$$\nwhere we have introduced a new critical exponent, $\\nu$ , and related it to other\nexponents through $\\nu=\\gamma/(2-\\eta)$ . For percolation in two dimensions, $\\nu=4/3$ ,\nwhereas in three dimensions it is $\\nu=0.9$ .",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            564,
            520,
            699
          ],
          "text": "Finding the Correlation Length from n ( s, p ) The correlation length ξ can be\nfound from the correlation function by\n\\[\n    \\xi^2=\\frac{\\sum_{\\mathbf r}r^2g(r)}{\\sum_{\\mathbf r}g(r)}~,\\eqno(5.34)\n  \\]\nwhere $\\sum_{\\mathbf r}g(r)=S(p)$ . You can check this by inserting $g(r)=r^{-(d-2)-\\eta}f(r/\\xi)$\nand calculating the integral.",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            80,
            699,
            360,
            770
          ],
          "text": "We recall that the average radius of gyration is\n$$R^2=\\frac{\\sum_s R_s^2 s^2 n(s,p)}{\\sum_s s^2 n(s,p)} \\; ,$$",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 86,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            218,
            62
          ],
          "text": "5.2 Characteristic Cluster Size",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            502,
            44,
            520,
            62
          ],
          "text": "77",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            188
          ],
          "text": "averaged over all clusters of size $i$ . Here, $\\sum_{s} s^2 n(s,p)=S(p)$ . Notice the\nsimilarity between these two definitions. This indicates that the correlation length\ncan be defined in terms on $n(s,p)$ . The common definition is\n$$\\xi^2=\\frac{\\sum_{s} 2 R_s^2 s^2 n(s,p)}{\\sum_{s} s^2 n(s,p)}=2R^2~.\\eqno(5.36)$$",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            197,
            520,
            278
          ],
          "text": "The important aspect is that the two lengths $\\xi$ and $R$ are proportional to each other.\nAnd we already round that $R\\propto R_{s_\\xi}$ . This means that they all have the same scaling\nbehavior as $p$ approaches $p_c$ . This means that\n$$\\xi\\propto|p-p_c|^{-\\gamma/(2-\\eta)}\\propto|p-p_c|^{-v}\\propto R_{s_\\xi}\\propto|p-p_c|^{-1/\\sigma D}~.\\eqno(5.37)$$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            295,
            367,
            313
          ],
          "text": "This gives us the scaling relation for $\\eta $ : $\\eta =2-\\gamma \\sigma D$ .",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            88,
            340,
            502,
            376
          ],
          "text": "Correlation Length All the lengths R, Rs ξ and ξ has the same scaling\nbehavior.",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            88,
            376,
            502,
            474
          ],
          "text": "The correlation length $\\xi$ scales as\n$$\\xi \\propto |p-p_c|^{-v} \\quad \\text{when} \\quad p \\to p_c~, \\eqno(5.38)$$\nwith the exponent $v=1/(\\sigma D)=\\gamma/(2-\\eta)$ . For a two-dimensional system,\n$v_{2d}=4/3$ , and for a three-dimensional system, $v_{3d}=0.9$ .",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            510,
            520,
            674
          ],
          "text": "The Characteristic Length $\\xi$ and System Size $L$ What happens to $\\xi$ in a finite\nsystem as $p$ approaches $p_c$ ? Figure shows a plot of $R(p) \\propto \\xi(p)$ for $L=100$ ,\n200, and 400 in two dimensions. Notice that the $R$ does not diverge as $p$ approaches\n$p_c$ . Instead, it reaches a plateau, the height of which increases with system size\n$L$ . This is not surprising, since we cannot observe clusters that are larger than the\nsystem size $L$ . Figure illustrates $\\xi \\propto |p-p_c|^v$ as we would expect it in an\ninfinite system. However, for a finite system, the curve for $\\xi(p)$ is cut off at a length\nproportional to $L$ . This means that for $p$ in some region around $p_c$ , as illustrated in\nFig. 5.6 , we have that $\\xi>L$ . In this range we cannot determine if the system is at\n$p_c$ or not, because the system is not large enough for us to make this distinction.",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            689,
            520,
            806
          ],
          "text": "If we study a system of size $L\\ll\\xi$ , we will typically observe a cluster that spans\nthe system, since the typical cluster size, $\\xi$ , is larger than the system size. We are\ntherefore not able to determine if we observe a spanning cluster because we are at $p_c$\nor only because we are sufficiently close to $p_c$ . We will start to observe a spanning\ncluster when $\\xi\\simeq L$ , which corresponds to\n$$\\xi_-(p_c-p)^{-v}=\\xi\\simeq L~,\\eqno(5.39)$$",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 87,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            84,
            62
          ],
          "text": "78",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            394,
            44,
            520,
            62
          ],
          "text": "5 Geometry of Clusters",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_087_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_087_figure_002.png",
          "bbox": [
            152,
            80,
            439,
            268
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            277,
            513,
            305
          ],
          "text": "Fig. 5.6 Illustration of the behavior of $\\xi$ when $p$ approaches $p_c$ . In a finite system of size $L$ , the\nsystem will be percolating for all $p$ in the range indicated by the arrows",
          "reading_order": 3
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_087_figure_004.png)",
          "figure_path": "figures/percolation_studies_page_087_figure_004.png",
          "bbox": [
            72,
            321,
            520,
            465
          ],
          "reading_order": 4
        },
        {
          "label": "cap",
          "bbox": [
            72,
            474,
            520,
            519
          ],
          "text": "Fig. 5.7 Illustration of the largest cluster in $512\\times512$ systems with $p>p_c$ , for $p=0.593$ ,\n$p=0.596$ , and $p=0.610$ . The circles illustrate the radius of gyration of the largest cluster. We\nobserve that the radius of gyration increases as $p$ approaches $p_c$",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            546,
            163,
            564
          ],
          "text": "and therefore tha",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            573,
            520,
            680
          ],
          "text": "$$\\begin{align}\n&(p_c-p)\\simeq(L/\\xi_-)^{-(1/v)},\\\\\n&\\text{when } p<p_c,\\text{ and a similar expression for } p>p_c.\\text{ This means that when we}\\\\\n&\\text{observe spanning we can only be sure that } p\\text{ is within a certain range of } p_c:\\\\\n&|p-p_c|=c L^{-1/v}~.\n\\end{align}$$",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            689,
            520,
            772
          ],
          "text": "The correlation length $\\xi$ is therefore the natural length to characterize the system.\nAt distances smaller than $\\xi$ , the system behaves as if it is at $p=p_c$ . However, at\ndistances much larger than $\\xi$ , the system is essentially homogeneous. As we can\nobserve in Fig. 5.7 the system becomes more and more homogeneous when $p$ goes\naway from $p_c$ . We will now address this feature in more detail when $p>p_c$ .",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 88,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            260,
            62
          ],
          "text": "5.3 Geometry of the Spanning Cluster",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            502,
            44,
            520,
            62
          ],
          "text": "79",
          "reading_order": 1
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            80,
            358,
            98
          ],
          "text": "5.3 Geometry of the Spanning Cluster",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            116,
            520,
            295
          ],
          "text": "How can we develop a scaling theory for the spanning cluster, that is, a theory\nfor how the mass of the spanning cluster depends on system size $L$ and the\ncharacteristic cluster size, $\\xi$ ? We know that as $p$ is increased from below towards\n$p_c$ , the characteristic cluster size $\\xi$ diverges. The mass of a characteristic cluster of\nsize $\\xi$ is expected to follow the scaling relation $s_{\\xi}\\propto \\xi^D$ . For a given value of $p$ , we\ncan therefore choose the system size $L$ to be equal to $\\xi$ , $L=\\xi(p)$ . In this case, a\ncluster of size $\\xi$ would correspond to a cluster of size $L$ , and it would be a spanning\ncluster in this system. For this system of size $L=\\xi$ , we therefore expect the mass\nof the spanning cluster to be $M(p, L)\\propto \\xi^D\\propto L^D$ . This suggests that the mass\nof the spanning cluster in a system close to or at $p_c$ depends on the system size $L$\naccording to $M(p_c, L)\\propto L^D$ .",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            304,
            520,
            386
          ],
          "text": "The Density of the Spanning Cluster The density, $P(p,L)$ , of the spanning\ncluster at $p=p_c$ therefore has the following behavior:",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            402,
            520,
            431
          ],
          "text": "Because we know that $P(p_c,L)$ does not diverge when $L\\rightarrow\\infty$ , we deduce that\n$D<d$ . The value of $D$ in two-dimensional percolation is $D=91/48\\simeq 1.90$ .",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            431,
            520,
            528
          ],
          "text": "This implies that the density of the spanning cluster depends on the system\nsize, $L$ . Indeed, since $D<d$ , we see that the density decreases with system size.\nThis may initially seem surprising, since we may be used to thinking of density\nas a material property. However, we recognize this behavior from bodies that are\nembedded in dimensions higher than themselves, such as for a thin sheet or a thin\nrod embedded in three dimensions.",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            546,
            520,
            725
          ],
          "text": "Embedded, Regular Bodies For example, consider a thin, flat sheet of thickness\n$h$ , and dimensions $\\mathcal{L} \\times \\mathcal{L}$ , placed in a three-dimensional space. If we cut out a\nvolume of size $L \\times L \\times L$ , so that $L \\ll \\mathcal{L}$ , the mass of the sheet inside that volume\nis\n$$M= h L^2~, ~~~~~~~~~~~~~~~(5.43)$$\nwhich implies that the density of the sheet is\n$$\\rho = \\frac{h L^2}{L^3} = h L^{-1}~.~~~~~~~~~~~~~~~~~~~~~~~(5.44)$$",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            734,
            520,
            783
          ],
          "text": "It is only in the case when we use a two-dimensional volume $L\\times L$ with a third\ndimension of constant thickness $H$ larger than $h$ , that we recover a constant density\n$\\rho$ independent of system size.",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 89,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            81,
            58
          ],
          "text": "80",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            394,
            44,
            520,
            62
          ],
          "text": "5 Geometry of Clusters",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_089_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_089_figure_002.png",
          "bbox": [
            72,
            80,
            520,
            179
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            188,
            520,
            215
          ],
          "text": "Fig. 5.8 Illustration of three generations of the Sierpinski gasket starting from an equilateral\ntriangle",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            241,
            520,
            305
          ],
          "text": "Non-Integer, Fractal Dimensions We found that $D$ was indeed smaller than $d$ so\nthat the density decreases with system size. However, $D$ is also not an integer. How\ncan we build intuition for non-integer dimensions of objects? First, let us be precise\nabout what we mean with dimension .",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            88,
            340,
            502,
            394
          ],
          "text": "Dimension For an object with mass $M$ and linear size $L$ , we define the\ndimension of the object as $D$ , if $M(L)=c L^{D}$ , that is, if the mass is\nproportional to $L$ to the power of $D$ .",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            430,
            520,
            621
          ],
          "text": "Self-Similar Deterministic Fractals To gain intuition about non-integer values for\nthe dimension $D$ , we will introduce a structure known as a deterministic fractal.\nA famous example is the Sierpinski gasket [ 32 ] , which is defined iteratively. We\nstart with a unit equilateral triangle as illustrated in Fig. 5.8 . We divide the triangle\ninto 4 identical triangles, and remove the center triangle. For each of the remaining\ntriangles, we continue this process. The resulting set of points after infinitely many\niterations is called the Sierpinski gasket. This set contains a hierarchy of holes. We\nalso notice that the structure is identical under (a specific) dilatational rescaling. If\nwe take one of the tree triangles generated in the first step and rescale it to fit on top\nof the initial triangle, we see that it reproduces the original identically. This structure\nis therefore a self-similar fractal in the limit of an infinite number of generations of\niterations.",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            627,
            520,
            752
          ],
          "text": "To find the dimensionality of such a structure we need to understand how the\nmass $M$ depends on the length scale $L$ of the structure. A common trick is to look\nat how the mass is rescaled between generations of iterations of the structure. Each\ntime we generate a new iteration of the structure we increase the length scale by\na factor of 2 and the mass by a factor of 3. This means that $L'=2L$ and $M'=M(2L)=3M(L)$ . If we assume that $M(L)=c{L^D}$ , we get that\n$$ M(2L)=c(2L)^D=3M(L)=3c{L^D}\\quad\\Rightarrow\\quad 2^D=3~,\\eqno{(5.45)}$$",
          "reading_order": 7
        }
      ]
    },
    {
      "page_number": 90,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            224,
            62
          ],
          "text": "5.4 Spanning Cluster Above p c",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            502,
            44,
            512,
            58
          ],
          "text": "8",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            143
          ],
          "text": "where we take the logarithm on both sides, getting\n\\[D \\ln 2=\\ln 3 \\quad \\Rightarrow \\quad D=\\frac{\\ln 3}{\\ln 2}\\simeq 1.58~.\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:thm_bound}\\]",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            63,
            152,
            520,
            216
          ],
          "text": "Thus, the dimension of this object is also not an integer, but lies between 1 and 2.\nThis indicates that the Sierpinski gasket is an object that is somewhere between a\nplane and a line. It fills space less efficiently that a plane, but more efficiently than\na line.",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            216,
            520,
            299
          ],
          "text": "We have presented a robust method for finding the dimension of iteratively\ndefined objects. However, the method also gives us the correct dimension for e.g. a\ncube: For a cube of size $L$ , if we double the size of the cube, that is $L'=2L$ , the\nmass is increased by a factor of 8, $M'=M(2L)=8M(L)$ , which gives a dimension\nof $d=\\ln{8}/\\ln{2}=3$ .",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            313,
            520,
            501
          ],
          "text": "Box Counting Typically, the mass dimensions of objects from experiments or\nsimulations are measured by box counting . The sample is divided into regular boxes\nwhere the size of each side of the box is $\\delta$ . The number of boxes, $N(\\delta)$ , that contain\nthe cluster are counted as a function of $\\delta$ . For a uniform mass we expect\n$$N(\\delta)=(\\frac{L}{\\delta})^d~, \\eqno(5.47)$$\nand for a fractal structure we expect\n$$N(\\delta)=(\\frac{L}{\\delta})^D~, \\eqno(5.48)$$",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            510,
            520,
            546
          ],
          "text": "We leave it as an exercise for the reader to address what happens when $\\delta \\rightarrow 1$, and\nwhen $\\delta \\rightarrow L$.",
          "reading_order": 6
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            573,
            304,
            592
          ],
          "text": "5.4 Spanning Cluster Above p c",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            609,
            520,
            721
          ],
          "text": "Let us now return to the discussion of the mass $M(p,\\,L)$ of the spanning cluster for\n$p> p_c$ $p> p_c$ in a finite system of size $L$ . The behavior of the percolation system for is illustrated in Fig. 5.7 . We notice that the correlation length $\\xi$ diverges when\n$p$ approaches $p_c$ . At lengths larger than $\\xi$ , the system is effectively homogeneous\nbecause there are no holes significantly larger than $\\xi$ . For such systems, there are\ntwo effectively types of behavior, depending on whether $L$ is larger than or smaller\nthan the correlation length $\\xi$ .",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            72,
            734,
            518,
            801
          ],
          "text": "Systems Effectively at p c When $L\\ll\\xi$ and $p>p_c$ , we are in the situation where\nwe cannot discern a system at $p$ from a system at $p_c$ because the size of the holes\n(empty regions described by $\\xi$ when $p>p_c$ ) in the spanning cluster is much larger\nthan the system size. We say that the system is effectively at $p_c$ . When we look at",
          "reading_order": 9
        }
      ]
    },
    {
      "page_number": 91,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            80,
            58
          ],
          "text": "8",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            394,
            44,
            520,
            62
          ],
          "text": "5 Geometry of Clusters",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_091_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_091_figure_002.png",
          "bbox": [
            71,
            80,
            520,
            296
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            304,
            520,
            349
          ],
          "text": "Fig. 5.9 Illustration of the spanning cluster in a $512\\times512$ system at $p=0.595>p_c$ . In this\ncase, the correlation length is $\\xi=102$ . The system is divided into regions of size $\\xi$ . Each such\nregion has a mass $M(p,\\xi)\\propto\\xi^D$ , and there are $(L/\\xi)^d\\simeq25$ such regions in the system",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            376,
            520,
            492
          ],
          "text": "this system through a window of size $L$ , that is, in a finite system size, we do not\nknow if the spanning cluster in that system is an infinite cluster or just a cluster\nthat is larger than the system size $L$ . However, because the mass of finite clusters\nall scale as $s\\propto R_{s}^{D}$ up to a length $\\xi$ that is much larger than $L$ , the mass of the\nspanning cluster of size $L$ will also follow this scaling relation:\n$$M(p, L) \\propto L^{D} \\text{ when }L \\ll \\xi \\text{ . }\\eqno{(5.49)}$$",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            510,
            520,
            700
          ],
          "text": "In Away from p c In the other case, when $L\\gg\\xi$ and $p>p_c$ , the typical\nsize of a hole in the percolation cluster is $\\xi$ , as illustrated in Fig. 5.9 . This means that\non lengths much larger than $\\xi$ , the percolation cluster is effectively homogeneous.\nThat is, it has holes up to a size $\\xi$ , but not much larger than that. It looks like a Swiss\ncheese with a finite size of the holes. We can therefore divide the $L\\times L$ system into\n$(L/\\xi)^d$ regions of size $\\xi$ . In each such region of size $\\ell=\\xi$ , the system is effectively\nat the percolation threshold $p_c$ . The mass of the spanning cluster in this region is\ntherefore given by ( 5.49 ) , so that, $m~\\propto~\\ell^D$ , where $\\ell=\\xi$ , and therefore $m~\\propto~\\xi^D$ .\nConsequently, the total mass of the spanning cluster is the mass of one such region\nmultiplied with the number of regions:\n$$M(p,L)\\propto (\\xi^D)(L/\\xi)^d\\propto \\xi^{D-d}L^d~.\\eqno(5.50)$$",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            716,
            518,
            752
          ],
          "text": "Scaling Behavior of the Mass Above $p_c$ We have therefore derived the behavior\nof the mass, $M(p,L)$ , of the spanning cluster for $p>p_c$ for system sizes $L$ that are",
          "reading_order": 6
        }
      ]
    },
    {
      "page_number": 92,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            108,
            58
          ],
          "text": "Exercise",
          "reading_order": 0
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            152
          ],
          "text": "$$\\begin{aligned}\n& \\text { much smaller or much larger than } \\xi: \\\\\n& M(p, L) \\propto\\left\\{L^{D} \\quad \\text { when } L \\ll \\xi\\right. \\\\\n& \\xi^{D-d} L^{d} \\text { when } L \\gg \\xi\n\\end{aligned} .\\qquad\\qquad\\qquad(5.51)$$",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            161,
            520,
            322
          ],
          "text": "This behavior can be rewritten in what we call the standard scaling form, with a\nscaling behavior and a cut-off function:\n\\begin{equation}  M(p,L)= L^DY(\\frac{L}{\\xi})~,\\label{eq:cond12}\n\\end{equation} where the cut-off function is:",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            331,
            520,
            367
          ],
          "text": "We will use this function form many times when we discuss the behavior of finite\nsystem sizes in the next chapter.",
          "reading_order": 4
        },
        {
          "label": "sec",
          "bbox": [
            72,
            400,
            135,
            412
          ],
          "text": "Exercises",
          "reading_order": 5
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            430,
            358,
            448
          ],
          "text": "Exercise 5.1 (Mass Scaling of Percolating Cluster)",
          "reading_order": 6
        },
        {
          "label": "list",
          "bbox": [
            72,
            465,
            520,
            492
          ],
          "text": "(a) Find the mass $M(L)$ of the percolating cluster at $p=p_c$ as a function of $L$ , for\n$L=2^k, k=4,\\dots,11$ .",
          "reading_order": 7
        },
        {
          "label": "list",
          "bbox": [
            71,
            492,
            288,
            511
          ],
          "text": "(b) Plot $\\log (M)$ as a function of $\\log (L)$.",
          "reading_order": 8
        },
        {
          "label": "list",
          "bbox": [
            72,
            511,
            236,
            528
          ],
          "text": "(c) Determine the exponent $D$",
          "reading_order": 9
        },
        {
          "label": "para",
          "bbox": [
            72,
            544,
            439,
            646
          ],
          "text": "Exercise 5.2 (Expressions for R s 2 ) Show that\n\\[R_{s}^{2}=\\frac{1}{s}\\langle\\sum_{i}(\\mathbf{r}_{i}-\\mathbf{r}_{cm})^{2}=\\frac{1}{2}\\frac{1}{s^{2}}\\sum_{ij}(\\mathbf{r}_{i}-\\mathbf{r}_{j})^{2}~,\\]\nwhere the sum over $ij$ are over all pairs of sites in a cluster of size $s$ .",
          "reading_order": 10
        },
        {
          "label": "para",
          "bbox": [
            72,
            663,
            439,
            680
          ],
          "text": "Hint Show that both expressions are equal to $\\sum_{i}\\mathbf{r}_{i}\\cdot\\mathbf{r}_{i}-\\mathbf{r}_{c}m\\cdot\\mathbf{r}_{cm}$",
          "reading_order": 11
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            697,
            270,
            708
          ],
          "text": "Exercise 5.3 (Correlation Function",
          "reading_order": 12
        },
        {
          "label": "list",
          "bbox": [
            72,
            725,
            484,
            743
          ],
          "text": "(a) Write a program to find the correlation function, $g(r, p, L)$ for $L=256$.",
          "reading_order": 13
        },
        {
          "label": "list",
          "bbox": [
            71,
            743,
            385,
            761
          ],
          "text": "(b) Plot $g(r, p, L)$ for $p=0.55$ to $p=0.65$ for $L=256$.",
          "reading_order": 14
        },
        {
          "label": "list",
          "bbox": [
            72,
            761,
            502,
            775
          ],
          "text": "(c) Find the correlation length $\\xi(p,L)$ for $L=256$ for the $p$-values used above",
          "reading_order": 15
        },
        {
          "label": "list",
          "bbox": [
            71,
            778,
            350,
            791
          ],
          "text": "(d) Plot $\\xi$ as a function of $p-p_c$ , and determine $v$ .",
          "reading_order": 16
        }
      ]
    },
    {
      "page_number": 93,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            83,
            58
          ],
          "text": "84",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            394,
            44,
            513,
            62
          ],
          "text": "5 Geometry of Cluster",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            518,
            162
          ],
          "text": "Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0\nInternational License ( http://creativecommons.org/licenses/by/4.0/ ), which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as long as you give appropriate\ncredit to the original author(s) and the source, provide a link to the Creative Commons license and\nindicate if changes were made.\nThe images or other third party material in this chapter are included in the chapter's Creative",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            162,
            518,
            216
          ],
          "text": "Commons license, unless indicated otherwise in a credit line to the material. If material is not\nincluded in the chapter's Creative Commons license and your intended use is not permitted by\nstatutory regulation or exceeds the permitted use, you will need to obtain permission directly from\nthe copyright holder.",
          "reading_order": 3
        }
      ]
    },
    {
      "page_number": 94,
      "elements": [
        {
          "label": "sec",
          "bbox": [
            72,
            98,
            242,
            125
          ],
          "text": "Finite Size Scaling",
          "reading_order": 0
        },
        {
          "label": "para",
          "bbox": [
            528,
            98,
            555,
            134
          ],
          "text": "6",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            304,
            520,
            467
          ],
          "text": "In this chapter we will introduce the theory of finite size scaling and demonstrate\nhow we can apply the theory to improve our measurements of the properties\nof percolation clusters. Usually, we attempt to measure properties of percolation\nsystem in the largest possible system we can simulate. Here, we demonstrate that if\nthe system behaves according to simple scaling relations, it is instead much better\nto systematically vary the system size and the interpolate to infinite system sizes.\nThis approach is generally called finite size scaling and we provide a thorough\nintroduction to the theory and its applications to understand the scaling of the\ndensity of the spanning cluster, $P(p,L)$ , the average cluster size, $S(p,L)$ , and the\npercolation probability $\\Pi(p,L)$ .",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            467,
            520,
            593
          ],
          "text": "How can we utilize a disadvantage, such as a finite system size, to an advantage?\nUsually, we have found a finite system size to be a hassle in simulations. We would\nlike to find the general behavior, but we are limited by the largest finite system\nsize we can afford to simulate. It may be tempting to put all our resources into one\nattempt — to make one simulation in a really large system. However, this is usually\nnot a good strategy. Because we will then know that our results are limited by the\nsystem size, but we do not know to what degree the finite system size affects our\nresult.",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            600,
            520,
            726
          ],
          "text": "Instead, we will follow a different strategy: the strategy of finite size scaling.\nWe will systematically increase the system size, measure the quantities we are\ninterested in, and then try to extrapolate to an infinite system size. This has several\nadvantages: It allows us to understand and estimate the errors in our predictions,\nand it allows us to use simulations of smaller systems. Indeed, it turns out that it is\nmore important to do simulations in smaller systems, than only to try to simulate\nthat largest system possible. However, for this to be effective, we need to have a\ntheoretical understanding of finite size scaling [ 7 ] .",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            726,
            520,
            774
          ],
          "text": "The methods we develop here are powerful and can be generalized to many\nother experimental and computational situations. In many experiments it is also\ntempting to try to perform the perfect experiment by reducing noise or measurement",
          "reading_order": 5
        },
        {
          "label": "foot",
          "bbox": [
            72,
            806,
            396,
            845
          ],
          "text": "© The Author(s) 2024\nA. Malthe-Sørenssen, Percolation Theory Using Python, Lecture Notes\nin Physics 1029, https://doi.org/10.1007/978-3-031-59900-2_6",
          "reading_order": 6
        },
        {
          "label": "foot",
          "bbox": [
            506,
            806,
            520,
            816
          ],
          "text": "85",
          "reading_order": 7
        }
      ]
    },
    {
      "page_number": 95,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            83,
            58
          ],
          "text": "86",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            417,
            44,
            520,
            62
          ],
          "text": "6 Finite Size Scaling",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            207
          ],
          "text": "errors. For example, we may perform an experiment where we need to make the\nexperimental system as horizontal as possible, because deviations from a horizontal\nsystem would introduce errors. Instead of trying to make the system as horizontal as\npossible, we may instead systematically vary the orientation, and then extrapolate\nto the case when the system is perfectly horizontal. This allows us to control the\nuncertainty. Of course, we cannot vary all possible uncertainties in an experiment or\na simulation, but this alternative mindset provides us with a new tool in our toolbox,\nand a new way to deal with uncertainties.",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            212,
            520,
            306
          ],
          "text": "In practical situations, we will always be limited by finite system sizes. If you\nmeasure the size of earthquakes in the Earth's crust, your results are limited by the\nthickness of the crust or by the extent of a homogeneous region. If you simulate\na molecular system, you are definitely limited by the number of atoms you can\ninclude in your simulation. Thus, better insight into how we can systematically vary\nthe system size and use this to gain insight are general tools of great utility.",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            306,
            520,
            439
          ],
          "text": "Here, you will learn how to systematically vary system size $L$ in order to\nfind good estimates for exponents and percolation thresholds. Indeed, my hope is\nthat you will see that finite size scaling is a powerful tool that can be used both\ntheoretically and computationally. To introduce this tool, we need to address specific\nexamples that can help build our intuition and shape our mindset. We will therefor\nstart from a few examples, such as the finite size scaling for the density of the\nspanning cluster, $P(p,\\, L)$ , and then apply the method to a new case, the percolation\nprobability $\\Pi(p,\\, L)$ .",
          "reading_order": 4
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            465,
            376,
            483
          ],
          "text": "6.1 General Aspects of Finite Size Scaling",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            501,
            520,
            564
          ],
          "text": "We have found that a percolation system is described by three length-scales: the size\nof a site, the system size $L$ , and the correlation length $\\xi$ . Finite size scaling addresses\nthe change in behavior of a system as we change the system size $L$ . Typically, we\ndivide the behavior into two categories:",
          "reading_order": 6
        },
        {
          "label": "list",
          "bbox": [
            71,
            582,
            520,
            612
          ],
          "text": "• When the system size $L$ is much smaller than the correlation length $\\xi$ , $L \\ll \\xi$ ,\nthe system appears to be on the percolation threshold.",
          "reading_order": 7
        },
        {
          "label": "list",
          "bbox": [
            71,
            612,
            520,
            645
          ],
          "text": "• When L is much larger than ξ, L ≫ ξ, the geometry is essentially homogeneous\nat lengths longer than ξ.",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            72,
            663,
            520,
            774
          ],
          "text": "We will then address the behavior close to $p_c$ . In the case of percolation, we\nusually assume that the behavior is a power-law in $p-p_c$ . For example, the mass\n$M(p;L)$ of the spanning cluster:\n$$ M(p)\\propto (p-p_c)^{-x}~, \\eqno(6.1)$$\nwhere the exponent $x$ determines the behavior close to $p_c$ .",
          "reading_order": 9
        },
        {
          "label": "para",
          "bbox": [
            72,
            777,
            520,
            806
          ],
          "text": "The general approach to finite size scaling is to make a scaling ansatz, that is,\nan assumption about how the system behaves, which typically consists of a scaling",
          "reading_order": 10
        }
      ]
    },
    {
      "page_number": 96,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            233,
            62
          ],
          "text": "6.2 Finite Size Scaling of P(p, L)",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            509,
            44,
            520,
            58
          ],
          "text": "37",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            208
          ],
          "text": "term and a cut-off function, as you have seen several times in this book:\n\\[M(p,L)=L^{\\frac{x}{v}}f\\left(\\frac{L}{\\xi}\\right)~, \\eqno(6.2)\\]\nwhere $f(u)$ is an unknown function. (Sometimes we instead make the assumption\n$M(p,L)=\\xi^{x/v}\\tilde f(L/\\xi)$ . We leave it to the reader to demonstrate that these\nassumptions are equivalent.)",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            208,
            520,
            288
          ],
          "text": "We will then apply our insight into the particulars of the system to infer the\nbehavior scaling function in the $f(u)$ limits , and when use $\\xi \\gg L$ this functional , and form $\\xi \\ll L$ as to a tool determine to study the form behavior of the\nof the system. We will explain this reasoning through three examples: The case of\n$P(p,L)$ , the case of $S(p,L)$ and the case of $\\Pi(p,L)$ .",
          "reading_order": 3
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            321,
            322,
            340
          ],
          "text": "6.2 Finite Size Scaling of P(p,L)",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            349,
            520,
            421
          ],
          "text": "Measuring $P(p,L)$ for finite $L$ Let us now apply this methodology to study\nthe behavior of the density of the spanning cluster, $P(p,L)$ , for finite system sizes.\nFirst, we generate a plot of $P(p,L)$ for various values of $L$ using the following\nprogram:",
          "reading_order": 5
        },
        {
          "label": "code",
          "bbox": [
            79,
            439,
            457,
            798
          ],
          "text": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.ndimage import measurements\nLL = [25,50,100,200]\np = np.linspace(0.4,0.75,50)\nnL = len(LL)\nnx = len(p)\nNi = np.zeros(nx)\nP = np.zeros((nx,nL),float)\nfor iL in range(nL):\nL = LL[iL]\nN = int(2000*25/L)\nfor i in range(N):\nz = np.random.rand(L,L)\nfor ip in range(nx):\nm = z<p[ip]\nlw, num = measurements.label(m)\nperc_x = np.intersect1d(lw[0,:],lw[-1,:])\nperc = perc_x[np.where(perc_x>0)]\nif (len(perc)>0):\nNi[ip] = Ni[ip] + 1\narea = measurements.sum(m, lw, perc[0])\nP[ip,iL] = P[ip,iL] + area\nP[:,iL] = P[:,iL]/({L*L}*N)\nfor iL in range(nL):\nL = LL[iL]\nplt.plot(p,P[:,iL],label=\"L = \"+str(L))",
          "reading_order": 6
        }
      ]
    },
    {
      "page_number": 97,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            81,
            58
          ],
          "text": "88",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            417,
            44,
            520,
            62
          ],
          "text": "6 Finite Size Scaling",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_097_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_097_figure_002.png",
          "bbox": [
            72,
            80,
            520,
            259
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            275,
            387,
            286
          ],
          "text": "Fig. 6.1 (a) Plot of $P(p,L)$ . (b) Plot of $P(p_c;L)$ as a function of $L$",
          "reading_order": 3
        },
        {
          "label": "code",
          "bbox": [
            107,
            313,
            251,
            358
          ],
          "text": "plt.ylabel('$P(p,L)$'\nplt.xlabel('$pS')\nplt.legend()",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            376,
            520,
            474
          ],
          "text": "The resulting plot of $P(p,L)$ is shown in Fig. 6.1 . We see that as $L$ increases,\n$P(p,L)$ approaches the shape expected in the limit when $L\\to\\infty$ . We can see\nhow it approaches this limit by finding the value of $P(p_c,L)$ as a function of $L$ . We\nexpect this value to go to zero as $L$ increases. Figure 6.1 b shows how $P(p_c,L)$\napproaches zero. Let us see if we can develop a theoretical prediction for this\nbehavior and check if our measured results confirm the prediction.",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            483,
            520,
            555
          ],
          "text": "Finite Size Effects in P ( p, L) We know that P ( p ) ∝ ( p − p c ) β and ξ ∝ |p −\np c | − v , so that\nP ( p ) ∝ ( p − p c ) β ∝ ξ − β/ν .",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            564,
            520,
            680
          ],
          "text": "This is valid in the limit when $L\\to\\infty$ , that is, when $L\\gg\\xi$ . In the limit when\n$L\\ll\\xi$ , which eventually will occur as $p$ approaches $p_c$ and $\\xi$ diverges, we see\nfrom Fig. 6.1 that $P(p_c,L)$ depends on $L$ . In this case, we have previously found\nthat\n$$ P(p,L)\\simeq P(p_c,L)=\\frac{M(p_c,L)}{L^2}\\propto \\frac{L^D}{L^d}\\propto L^{D-d}\\propto L^{-\\beta/\\nu}~.\\eqno(6.4)$$",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            689,
            394,
            756
          ],
          "text": "Combined, we therefore have the behavior\n\\[P(p,L) \\propto \\left\\{\\begin{array}{ll}\n    \\xi^{-\\beta/\\nu}&\\text{when } L \\gg \\xi\\\\\n    L^{-\\beta/\\nu}&\\text{when } L \\ll \\xi\n  \\end{array}\\right..\\]",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 98,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            233,
            62
          ],
          "text": "6.2 Finite Size Scaling of P(p, L)",
          "reading_order": 0
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            161
          ],
          "text": "Finite Size Scaling Ansatz The fundamental idea of finite size scaling is then to\nassume a particular form of a function that encompasses this behavior both when\n$\\xi \\ll L$ and $\\xi \\gg L$ , by rewriting the expression for $P(p,L)$ as\n$$ P(p,L)=L^{-\\beta/v} f(L/\\xi)~. \\eqno(6.6)$$",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            179,
            520,
            241
          ],
          "text": "Where we have assumed that the only relevant length scales are $L$ and $\\xi$ , and that\nthe function therefore only can depend on a ratio between these two length scales.\nHow must the function $f(u)$ behave for this general form to reduce to Eqs. ( 6.3 ) and\n( 6.4 )?",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            241,
            520,
            340
          ],
          "text": "First, we see that when $\\xi \\gg L$ the function $f(L/\\xi)$ should be a constant, that\nis, $f(u)$ is a constant when $u \\ll 1$ . Second, we see that when $\\xi \\ll L$ , we need\nthe function $f(L/\\xi)$ to cancel all the $L$ -dependency in order to find the relation in\nEq. ( 6.3 ):\n$$P(p,L)=L^{-\\beta/v} f(L/\\xi)=\\xi^{-\\beta/v}~.\\eqno(6.7)$$",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            357,
            520,
            448
          ],
          "text": "This will occur if and only if $f(u)$ is a power-law, that is, $f(u)=u^a$ . In order to\ncancel the $L$ -dependency, the power-law exponent for the $L$ -term must be zero:\n\\[\n\\begin{aligned}\nP(p, L) & \\propto L^{-\\beta/v}(L / \\xi)^a \\propto L^{-\\beta / v+a} \\xi^{-a} \\propto \\xi^{-\\beta / v} \\\\\n& \\Rightarrow-\\beta / v+a=0 \\Rightarrow a=\\beta / v \\text {. }\n\\end{aligned}\n\\eqno(6.8)\n\\]",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            456,
            520,
            506
          ],
          "text": "Indeed, we could have used this in order to find the exponent in the relation $\\xi^{-\\beta/\\nu}$ .\nIt would simply have been enough to assume that $P(p,L)\\propto \\xi^x$ for some exponent\n$x$ in the limit of $\\xi\\ll L$ .",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            510,
            520,
            654
          ],
          "text": "In order to satisfy these conditions, the scaling form of $P(p,L)$ must therefore\nbe\n\\[ P(p,L)=L^{-\\beta/v}f(L/\\xi)~,\\]\nwhere\n\\[ f(u)=\\left\\{\\begin{array}{l}\n\\text{const. for } u\\ll1\\\\\nu^{\\beta/v}&\\text{for } u\\gg1\n\\end{array}\\right.\\]",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            663,
            520,
            788
          ],
          "text": "Testing the Scaling Ansatz We can now test the scaling ansatz by plotting\n$P(p,L)$ according to the ansatz, following a strategy similar to what we developed\nfor $n(s,\\, p)$ . We rewrite the scaling function $P(p,L)=L^{-\\beta/v}f(L/\\xi)$ in terms of\n$|p-p_c|$ by inserting $\\xi=\\xi_0|p-p_c|^{-v}$ :\n$$ P(p,L)=L^{-\\beta/v}f(L/\\xi) \\eqno (6.12)\\\\  = L^{-\\beta/v} f(L\\xi_0|p-p_c|^v) \\eqno (6.13)$$",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 99,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            81,
            58
          ],
          "text": "90",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            417,
            44,
            520,
            62
          ],
          "text": "6 Finite Size Scaling",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_099_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_099_figure_002.png",
          "bbox": [
            251,
            80,
            520,
            268
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            80,
            206,
            145
          ],
          "text": "Fig. 6.2 Scaling data\ncollapse plot of $P(p,L)$ with\n$L^{1/v}(p-p_c)$ along the\n$x$ -axis and $L^{\\beta/v}\\, P(p,L)$\nalong the $y$ -axis",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            233,
            294,
            404,
            313
          ],
          "text": "= L ^ { - \\beta / \\nu } f ( ( \\xi _ { 0 } L ^ { 1 / \\nu } ( p - p _ { c } ) ) ^ { \\nu } )",
          "reading_order": 4
        },
        {
          "label": "equ",
          "bbox": [
            233,
            313,
            385,
            340
          ],
          "text": "$$\n=L^{-\\beta / v} \\tilde{f}\\left(L^{1 / v}\\left(p-p_{c}\\right)\\right) \\text {. }\n$$",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            349,
            385,
            403
          ],
          "text": "Which again can be rewritten as\n$$L^{\\beta/v}P(p,L)=\\tilde f(L^{1/v}(p-p_c))$$",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            412,
            520,
            496
          ],
          "text": "Consequently, if we plot $L^{1/v}(p-p_c)$ along the $x$ -axis and $L^{\\beta/v}P(p,L)$ along\nthe $y$ -axis, we expect the data from simulations for various $L$ -values to fall onto a\ncommon curve, the curve $f(u)$ . This is illustrated in Fig. 6.2 , which shows that the\nmeasured data is consistent with the scaling ansatz. We call such as plot a scaling\ndata collapse plot.",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            510,
            520,
            593
          ],
          "text": "Comparing to Theory at $p=p_c$ Finally, we can now use this theory to\nunderstand the behavior for $P(p_c,L)$ . In this case we find that $P(p_c,L)=c L^{-\\beta/v}$ .\nWe can therefore measure $-\\beta/v$ from the plot of $P(p_c,L)$ in Fig. 6.1 . While the\ndata in this figure is too poor to produce a reliable result, the figure demonstrates the\nprinciple.",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            72,
            609,
            520,
            690
          ],
          "text": "Varying $L$ to Gain Insight The take-home message is that instead of trying to\nsimulate one single simulation with as large $L$ as possible, we instead vary $L$\nsystematically and then use this variation to estimate the relevant exponents $v$ and\n$\\beta$ . The methods demonstrated here usually provide much better results in term of\nprecision of the exponents than a direct measurement for a large system size.",
          "reading_order": 9
        },
        {
          "label": "para",
          "bbox": [
            72,
            707,
            520,
            754
          ],
          "text": "Alternative Approaches We could instead have started with a scaling ansatz of\n$P(p,L)=(p-p_c)^\\beta g(L/\\xi) = \\xi^{-\\beta/v}g(L/\\xi)$ . However, the end result would be\nthe same. We leave this as an exercise for the eager reader.",
          "reading_order": 10
        }
      ]
    },
    {
      "page_number": 100,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            192,
            62
          ],
          "text": "6.3 Average Cluster Size",
          "reading_order": 0
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            80,
            260,
            98
          ],
          "text": "6.3 Average Cluster Size",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            116,
            520,
            206
          ],
          "text": "We can characterize the distribution of cluster sizes using moments of the cluster\nnumber distribution . The $k$ -th moment $M_{k}(p,L)$ is defined as:\n\\[ M_{k}(p,L)=\\sum_{s=1}^{\\infty} s^{k}n(s,p;L)~.\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:l2}\\]",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            215,
            520,
            313
          ],
          "text": "We have already introduced the second moment, $M_{2}(p,L)$ , which we called the\naverage cluster size, $S(p,L)$ .\n$$S(p,L)=M_{2}(p,L)=\\sum_{s=1}^{\\infty} s^{2} n(s, p; L) .\\qquad\\qquad\\qquad(6.18)$$",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            322,
            520,
            371
          ],
          "text": "Now, let us see if we can apply the finite-size scaling approach to develop a scaling\ntheory for $S(p,L)$ . First, we will measure $S(p,L)$ , and then develop and test a\nscaling theory.",
          "reading_order": 5
        },
        {
          "label": "sec",
          "bbox": [
            72,
            403,
            409,
            421
          ],
          "text": "Measuring Moments of the Cluster Number Density",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            438,
            520,
            600
          ],
          "text": "How would we measure $S(p,L)$ ? We recall that we measure the cluster number\ndensity from\n\\[\n    \\overline{n(s, p; L)}=\\frac{N_s}{L^d}~,\\eqno(6.19)\n  \\]\nwhere $N_s$ is the number of clusters of size $s$ . Thus we can estimate $S(p,L)$ from:\n\\[\n    \\overline{S(p,L)}=\\sum_{s=1}^\\infty s^2\\overline{n(s, p; L)}=\\sum_{s=1}^\\infty s^2\\frac{N_s}{L^d}~.\\eqno(6.20)\n  \\]",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            617,
            520,
            743
          ],
          "text": "We realize that we can perform this sum by summing over all possible $s$ and then\nincluding how many clusters we have for a given $s$ , or we can alternatively sum over\nall the observed clusters $s_i$ . (Try to convince yourself that this is the same by looking\nat a sequence of clusters of sizes 1, 2, 1, 5, 1, 2.). Thus, we can estimate the second\nmoment from the sum:\n\\[\n    \\overline{S(p,L)}=\\sum_i s_i^2/L^2~.\n\\]",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 101,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            83,
            62
          ],
          "text": "92",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            417,
            44,
            520,
            62
          ],
          "text": "6 Finite Size Scaling",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            116
          ],
          "text": "And similarly by summing over $s_{i}^{k}$ for the $k$-th moment. We implement this in the\nfollowing program:",
          "reading_order": 2
        },
        {
          "label": "code",
          "bbox": [
            79,
            134,
            497,
            591
          ],
          "text": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.ndimage import measurements\nLL = [25,50,100,200]\np = np.linspace(0.4,0.75,50)\nnL = len(LL)\nnx = len(p)\nS = np.zeros((nx,nL),float)\nfor iL in range(nL):\nL = LL[iL]\nM = int(2000*25/L)\nfor i in range(M):\nz = np.random.rand(L,L)\nfor ip in range(nx):\nm = z<p[ip]\nlw, num = measurements.label(m)\nlabelList = np.arange(lw.max() + 1)\narea = measurements.sum(m, lw, labelList)\n# Remove spanning cluster by setting area to zero\nperc_x = np.intersect1d(lw[0,:],lw[-1,:])\nperc = perc_x[np.where(perc_x>0)]\nif (len(perc)>0):\narea[perc[0]] = 0\nS[ip,iL] = S[ip,iL] + np.sum(area*area)\nS[:,iL] = S[:,iL]/(L**2*M)\n# Plotting the results\nplt.figure(figsize=(6,4))\nfor iL in range(nL):\nL = LL[iL]\nlab = \"$L=\"+str(L)+\"$\"\nplt.plot(p,S[:,iL],label=lab)\nplt.ylabel('$S(p,L)$’)\nplt.xlabel('$p$’)\nplt.legend()",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            609,
            520,
            636
          ],
          "text": "The resulting plot of $S(p,L)$ as a function of $p$ for various values of $L$ is shown\nin Fig. 6.3 .",
          "reading_order": 4
        },
        {
          "label": "sec",
          "bbox": [
            72,
            672,
            243,
            689
          ],
          "text": "Scaling Theory for $S(p,L)$",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            706,
            513,
            770
          ],
          "text": "How can we understand these plots and how can we develop a theory for $S(p,L)$\nWe previously found that $S$ diverges as $p$ approaches $p_c$ :",
          "reading_order": 6
        }
      ]
    },
    {
      "page_number": 102,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            192,
            62
          ],
          "text": "6.3 Average Cluster Size",
          "reading_order": 0
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_102_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_102_figure_002.png",
          "bbox": [
            72,
            80,
            520,
            259
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            268,
            385,
            286
          ],
          "text": "Fig. 6.3 (a) Plot of $S(p, L)$. (b) Plot of $S\\left(p_{c} ; L\\right)$ as a function of $L$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            313,
            520,
            412
          ],
          "text": "where the exponent is $\\gamma=43/18$ for $d=2$ . Following the approach for finite-size\nscaling introduced above, we introduce the finite size $L$ through a scaling function\n$f(L/\\xi)$ , giving us a finite-size scaling ansatz (our hypothesis):\n$$S(p, L)=S_0|p-p_c|^{-\\gamma} f\\left(\\frac{L}{\\xi}\\right)~. \\eqno(6.23)$$",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            428,
            520,
            510
          ],
          "text": "We rewrite the first expression by introducing $\\xi=\\xi_0|p-p_c|^{-v}$ so that $S_0|p-p_c|^{-\\gamma}=\\xi^{\\gamma/v}$ , giving:\n$$ S(p,L)=\\xi^{\\gamma/v}f\\left(\\frac{L}{\\xi}\\right)~. \\eqno(6.24)$$",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            519,
            520,
            654
          ],
          "text": "Now, we see from Fig. that when $p=p_c$ , $S(p_c,L)$ does not diverge, but is\nlimited by $L$ , as we would expect for a finite system. Thus we know that in the\nlimit when $p\\to p_c$ , $S(p,L)$ can only depend on $L$ . This implies that the function\n$f(L/\\xi)$ in this limit must be so that the $\\xi$ in $f(L/\\xi)$ cancels the $\\xi^{\\gamma/\\nu}$ in front of it.\nThis can only happen if $f(L/\\xi)\\propto (L/\\xi)^{\\gamma/\\nu}$ :\n$$S(p,L)\\propto \\xi^{\\gamma/\\nu}\\left(\\frac{L}{\\xi}\\right)^{\\gamma/\\nu}\\propto L^{\\gamma/\\nu}~.\\eqno(6.25)$$",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            671,
            304,
            685
          ],
          "text": "Thus, we have found that $S(p_c,L)\\propto L^{\\gamma/\\nu}$",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            80,
            688,
            520,
            752
          ],
          "text": "This allows us to write the scaling form of $S(p,L)$ in a different way:\n\\[ S(p,L)= L^{\\gamma/v} g\\left(\\frac{L}{\\xi}\\right)~.\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:hsdefn-bound}\\]",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 103,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            83,
            58
          ],
          "text": "94",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            417,
            44,
            520,
            62
          ],
          "text": "6 Finite Size Scaling",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_103_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_103_figure_002.png",
          "bbox": [
            251,
            80,
            528,
            268
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            80,
            215,
            145
          ],
          "text": "Fig. 6.4 A data-collapse plot\nof the rescaled average cluster\nsize $L^{-\\gamma/v}S(p,L)$ as a\nfunction of $L^{1/v}(p-p_c)$ for\nvarious $L$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            295,
            528,
            403
          ],
          "text": "We can test this prediction by plotting $S(p,L) L^{-\\gamma/v}$ as a function of $L/\\xi$ :\n$$\n\\begin{aligned}\nS(p,L) L^{-\\gamma/v}&=g\\left(\\frac{L}{\\xi}\\right)=g\\left(L(p-p_c)^{-v}\\right)\\\\\n&=g\\left(\\left(L^{1/v}(p-p_c)\\right)^v\\right)=\\tilde g\\left(L^{1/v}(p-p_c)\\right)~.\n\\end{aligned}\n$$",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            410,
            520,
            439
          ],
          "text": "The resulting plot is shown in Fig. 6.4 , which indeed demonstrates that the measured\ndata is consistent with the scaling theory. Success!",
          "reading_order": 5
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            472,
            269,
            484
          ],
          "text": "6.4 Percolation Threshold",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            501,
            520,
            552
          ],
          "text": "Finally, we will demonstrate one of the most elegant applications of finite-size\nscaling theory to the percolation probability $\\Pi(p,L)$ and to see how a finite system\nsize will affect the effective percolation threshold.",
          "reading_order": 7
        },
        {
          "label": "sec",
          "bbox": [
            72,
            582,
            377,
            600
          ],
          "text": "Measuring the Percolation Probability $\\Pi (p,L)$",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            72,
            618,
            520,
            681
          ],
          "text": "We can measure the percolation probability for a set of finite system sizes using the\nmethods we developed previously. Here, we have implemented the measurement in\nthe following program which is very similar to the program developed to measure\n$P(p,L)$",
          "reading_order": 9
        },
        {
          "label": "code",
          "bbox": [
            79,
            698,
            340,
            797
          ],
          "text": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.ndimage import measurements\nLL = [25,50,100,200]\np = np.linspace(0.4,0.75,50)\nnL = len(LL)\nnx = len(p)",
          "reading_order": 10
        }
      ]
    },
    {
      "page_number": 104,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            199,
            62
          ],
          "text": "6.4 Percolation Threshold",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            509,
            44,
            520,
            58
          ],
          "text": "35",
          "reading_order": 1
        },
        {
          "label": "code",
          "bbox": [
            79,
            80,
            439,
            377
          ],
          "text": "Ni = np.zeros((nx,nL),float)\nPi = np.zeros((nx,nL),float)\nfor iL in range(nL):\nL = LL[iL]\nN = int(2000+25/L)\nfor i in range(N):\nz = np.random.rand(L,L)\nfor ip in range(nx):\nm = z<p[ip]\nlw, num = measurements.label(m)\nperc_x = np.intersect1d(lw[0,:],lw[-1,:])\nperc = perc_x[np.where(perc_x>0)]\nif (len(perc)>0):\nNi[ip,iL] = Ni[ip,iL] + 1\nPi[:,iL] = Ni[:,iL]/N\nfor iL in range(nL):\nL = LL[iL]\nlab = \"$L=\"+str(L)+\"$\"\nplt.plot(p,Pi[:,iL],label=lab)\nplt.ylabel('$\\Pi(p,L)$’)\nplt.xlabel('$p$’)\nplt.legend()",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            88,
            394,
            484,
            412
          ],
          "text": "The resulting plot of $\\Pi(p,L)$ for various values of $L$ is shown in Fig. 6.5 .",
          "reading_order": 3
        },
        {
          "label": "sec",
          "bbox": [
            72,
            439,
            332,
            458
          ],
          "text": "Measuring the Percolation Threshold $p_{c}\\!\\,$",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            474,
            520,
            506
          ],
          "text": "Let us now assume that we do not a priori know $p_c$ or any of the scaling exponents.\nHow can we use this data-set to estimate the value for $p_c$ ?",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            510,
            520,
            539
          ],
          "text": "The simplest approach may be to estimate $p_c$ as the value for $p$ that makes\n$\\varPi(p,L)=1/2$ . This corresponds to intersection between the horizontal line",
          "reading_order": 6
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_104_figure_007.png)",
          "figure_path": "figures/percolation_studies_page_104_figure_007.png",
          "bbox": [
            89,
            564,
            511,
            779
          ],
          "reading_order": 7
        },
        {
          "label": "cap",
          "bbox": [
            72,
            794,
            188,
            806
          ],
          "text": "Fig. 6.5 Plot of $\\Pi(p,L)$",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 105,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            83,
            58
          ],
          "text": "96",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            417,
            44,
            520,
            62
          ],
          "text": "6 Finite Size Scaling",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_105_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_105_figure_002.png",
          "bbox": [
            72,
            80,
            520,
            277
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            286,
            367,
            297
          ],
          "text": "Fig. 6.6 (a) Plot of $\\Pi(p,L)$ . (b) Plot of $p_{1/2}$ as a function of $L$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            330,
            520,
            439
          ],
          "text": "$\\Pi=1/2$ and the curves in Fig. 6.5 . This is illustrated in Fig. 6.6 . Here, we\nhave also plotted $p_{1/2}$ as a function of $L$ , where $p_{1/2}$ is the value for $p$ so that\n$\\Pi(p_{1/2}, L)=1/2$ . These values for $p_{1/2}$ are calculated by a simple interpolation\nas illustrated in the following program. (Notice that as usual in this book, we do not\naim for high precision in this program. The simulations are for small system sizes\nand few samples, but are meant to illustrate the principle and be reproduceable for\nyou.)",
          "reading_order": 4
        },
        {
          "label": "code",
          "bbox": [
            79,
            456,
            496,
            582
          ],
          "text": "for iL in range(nL):\nipc = np.argmax(Pi[:,iL]>0.5) # Find first i where Pi>0.5\n# Interpolate from ipc-1 to ipc to find intersection\nppc = p[ipc-1] + (0.5-Pi[ipc-1,iL])*\\\n(p[ipc]-p[ipc-1])/(Pi[ipc,iL]-Pi[ipc-1,iL])\nPic = 0.5\nplt.plot(LL[iL],ppc,’o’)\nplt.xlabel(’$L$’)\nplt.ylabel(’$p_{1/2}$’)",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            599,
            520,
            663
          ],
          "text": "From Fig. 6.6 we see that as $L$ increases the value for $p_{1/2}$ gradually approaches\n$p_c$ . Well, we cannot really see that it is approaching $p_c$ , but we guess that it will.\nHowever, in order extrapolate the curve to infinite $L$ we need to develop a theory\nfor how $p_{1/2}$ behaves. We need to develop a finite size scaling theory for $\\Pi(p, L)$ .",
          "reading_order": 6
        },
        {
          "label": "sec",
          "bbox": [
            72,
            689,
            322,
            709
          ],
          "text": "Finite-Size Scaling Theory for $\\Pi (p,L)$",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            725,
            520,
            757
          ],
          "text": "We apply the same method as before to develop a theory for $\\varPi(p,L)$ . First. we\nnotice that at $p_c~\\varPi(p_c,L)$ does not either diverge or go to zero. This means that",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 106,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            197,
            58
          ],
          "text": "6.4 Percolation Threshold",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            502,
            44,
            512,
            58
          ],
          "text": "9",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            152
          ],
          "text": "$\\Pi(p,L)$ cannot be a function of $\\xi$ alone, but instead must have the scaling form:\n$$\\Pi(p,L)=\\xi^{0}f\\left(\\frac{L}{\\xi}\\right)\\enspace.\\qquad\\qquad\\qquad\\qquad(6.29)$$",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            161,
            520,
            224
          ],
          "text": "We rewrite this in terms of $(p-p_c)$ by inserting $\\xi=\\xi_0|p-p_c|^{-v}$ :\n$$\\Pi(p,L)=f\\left(L\\xi_0|p-p_c|^{v}\\right)=f\\left(\\xi_0\\left(L^{1/v}(p-p_c)\\right)^{v}\\right)~.\\eqno(6.30)$$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            232,
            520,
            295
          ],
          "text": "We introduce a new function $\\Phi(u)=f\\left(\\xi_{0} u^{1/v}\\right)$:\n$$\\Pi(p,L)=\\Phi\\left(L^{1/v}(p-p_{c})\\right)\\text{.}\\qquad\\qquad\\qquad\\qquad(6.31)$$",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            304,
            313,
            324
          ],
          "text": "This is our finite-size scaling ansatz (theory).",
          "reading_order": 5
        },
        {
          "label": "sec",
          "bbox": [
            72,
            357,
            326,
            376
          ],
          "text": "Estimating $p_{c}\\,$ Using the Scaling Ansatz",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            385,
            520,
            482
          ],
          "text": "How can we use this theory to estimate $p_c$ ? We follow a technique similar to what\nwe used above: We find the value $p_x$ that makes $\\Pi(p_x,L)=x$ . Above, we did this\nfor $x=1/2$ , but we can do this more generally. Actually, as $L\\to\\infty$ , we expect\nany such $p_x$ to converge to $p_c$ . We notice from above that $p_x$ is a function of $L$ :\n$p_x=p_x(L)$ .\nWe insert this into the scaling ansatz:",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            482,
            520,
            672
          ],
          "text": "_",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            72,
            688,
            520,
            798
          ],
          "text": "If we know $\\nu$ , we see that this gives a method to estimate the value of $p_c$ .\nFigure shows a plot of $p_{1/2}-p_c$ as a function of $L^{-1/\\nu}$ for $\\nu=4/3$ . We can\nuse this plot to extrapolate to find $p_c$ in the limit when $L\\to\\infty$ as indicated in the\nplot. The resulting value for $p_c$ extrapolated from $L=50$ , 100, 200 is $p_c=0.5935$ ,\nwhich is surprisingly good given the small system sizes and small sample sizes used\nfor this estimate. (The best known value is $p_c=0.5927$ ). This demonstrates the\npower of finite size scaling.",
          "reading_order": 9
        }
      ]
    },
    {
      "page_number": 107,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            84,
            62
          ],
          "text": "98",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            412,
            44,
            520,
            62
          ],
          "text": "6 Finite Size Scaling",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_107_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_107_figure_002.png",
          "bbox": [
            251,
            80,
            511,
            259
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            80,
            200,
            176
          ],
          "text": "Fig. 6.7 Plot of $p_{1/2}$ as a\nfunction of $L^{-1/v}$ . The\ndashed line indicates a linea\nfit to the data for\n$L=50,\\,100,\\,200$ . The\nextrapolated value for $p_c$ at\n$L\\to\\infty$ is $p_c=0.5935$",
          "reading_order": 3
        },
        {
          "label": "sec",
          "bbox": [
            72,
            286,
            367,
            304
          ],
          "text": "Estimating $p_{c}$ and $v$ Using the Scaling Ansatz",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            321,
            520,
            415
          ],
          "text": "However, this approach depends on us knowing the value for $v$ . What if we did not\nknow neither $v$ nor $p_c$ ? How can we estimate both from the scaling ansatz? One\nalternative is to generate plots of $p_x$ as a function of $L^{-1/v}$ for several values of $x$ .\nThen we adjust the values of $v$ until we get a straight line, in that case we can read\nof the intersect with the $p_x$ axis as the value for $p_c$ .\nHowever, we can do even better by noticing a trick: For two $x$ values $x_1$ and $x_2$ ,",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            415,
            520,
            528
          ],
          "text": "we get\n\\[dp=p_{\\Pi =x_1}(L)-p_{\\Pi =x_2}(L)=(C_{x_1}-C_{x_2})L^{-v}~,\\tag*{6.35}\\]\nand we can therefore plot log( $dp$ ) as a function of log( $L$ ) to get $v$ , and then use\nthis to estimate $p_c$ . As an exercise, the reader is encouraged to demonstrate that this\nscaling ansatz is valid for $d=1$ , and in this case find $C_x$ explicitly.",
          "reading_order": 6
        },
        {
          "label": "sec",
          "bbox": [
            72,
            561,
            135,
            573
          ],
          "text": "Exercises",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            591,
            367,
            609
          ],
          "text": "Exercise 6.1 (Finite­Size Scaling in One Dimension)",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            72,
            627,
            412,
            641
          ],
          "text": "(a) Show that the scaling ansatz for $\\Pi(p,L)$ is valid for $d=1$",
          "reading_order": 9
        },
        {
          "label": "para",
          "bbox": [
            71,
            644,
            331,
            657
          ],
          "text": "(b) Find an explicit expression for $C_x$ for $d=1$",
          "reading_order": 10
        },
        {
          "label": "para",
          "bbox": [
            72,
            672,
            520,
            737
          ],
          "text": "In 6.2 (Finite-Size Scaling in Two Dimensions) In this exercise we will\nuse the scaling ansatz to provide estimates of $v$ , $p_c$ and the average percolation\nprobability $\\langle p \\rangle$ in a system of size $L$ .\nWe define $p_x$ so that $\\Pi(p_x, L)=x$ . Notice that $p_x$ is a function of system size",
          "reading_order": 11
        },
        {
          "label": "para",
          "bbox": [
            72,
            737,
            520,
            752
          ],
          "text": "$L$ used for the simulation.",
          "reading_order": 12
        },
        {
          "label": "para",
          "bbox": [
            72,
            770,
            520,
            799
          ],
          "text": "(a) Find $p_x$ for $x=0.3$ and $x=0.8$ for $L=25,\\,50,\\,100,\\,200,\\,400,\\,800$ . Plot $p_x$ as\na function of $L$ .",
          "reading_order": 13
        }
      ]
    },
    {
      "page_number": 108,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            108,
            58
          ],
          "text": "Exercise",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            502,
            44,
            520,
            62
          ],
          "text": "99",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            107,
            80,
            520,
            134
          ],
          "text": "According to the scaling theory we have\n$$p_{x_{1}}-p_{x_{2}}=\\left(C_{x_{1}}-C_{x_{2}}\\right) L^{-1 / v} .\\qquad\\qquad\\qquad(6.36)$$",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            71,
            143,
            520,
            179
          ],
          "text": "(b) Plot log $\\left(p_{0.8}-p_{0.3}\\right)$ as a function of log $(L)$ to estimate the exponent $v$. How\ndoes it compare to the exact result?",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            89,
            179,
            520,
            250
          ],
          "text": "In the following, please use the exact value $\\nu=4/3$ . The scaling theory also\npredicted that\n$$p_x=p_c+C_xL^{-1/\\nu}~. \\eqno(6.37)$$",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            258,
            520,
            290
          ],
          "text": "(c) Plot $p_x$ as a function of $L^{-1/\\nu}$ to estimate $p_c$ . Generate a data-collapse plot for\n$\\varPi(p, L)$ to find the function $\\Phi(u)$ described above.",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            71,
            290,
            520,
            340
          ],
          "text": "(d) Plot $\\Pi'(p,L)$ as a function of $p$ for the various $L$ values used above. Generate\na data-collapse plot of $\\Pi'(p,L)$ . Find $\\langle p \\rangle$ and plot $\\langle p \\rangle$ as a function of $L^{-1/v}$\nto find $p_c$ .",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            357,
            340,
            370
          ],
          "text": "Exercise 6.3 (Finite Size Scaling of n(s, pc, L))",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            385,
            520,
            421
          ],
          "text": "(a) Develop a finite size scaling ansatz/theory for $n(s,\\,p_c,\\,L)$ . You should provide\narguments for the behavior in the various limits.",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            71,
            421,
            423,
            451
          ],
          "text": "(b) Plot $n(s,\\,p_c,\\,L)$ as a function of $s$ for $L=100,\\,200,\\,400,\\,800$\n(c) Demonstrate the validity of the scaling theory by producing a",
          "reading_order": 9
        },
        {
          "label": "para",
          "bbox": [
            72,
            451,
            520,
            467
          ],
          "text": "$$\n\\quad { \\mathrm { f o r } } \\, n ( s , p _ { c } , L ) .\n$$",
          "reading_order": 10
        },
        {
          "label": "para",
          "bbox": [
            72,
            636,
            520,
            701
          ],
          "text": "Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0\nInternational License ( http://creativecommons.org/licenses/by/4.0/ ), which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as long as you give appropriate\ncredit to the original author(s) and the source, provide a link to the Creative Commons license and\nindicate if changes were made.",
          "reading_order": 11
        },
        {
          "label": "para",
          "bbox": [
            72,
            704,
            520,
            770
          ],
          "text": "The images or other third party material in this chapter are included in the chapter's Creative\nCommons license, unless indicated otherwise in a credit line to the material. If material is not\nincluded in the chapter's Creative Commons license and your intended use is not permitted by\nstatutory regulation or exceeds the permitted use, you will need to obtain permission directly from\nthe copyright holder.",
          "reading_order": 12
        }
      ]
    },
    {
      "page_number": 109,
      "elements": [
        {
          "label": "sec",
          "bbox": [
            72,
            98,
            233,
            116
          ],
          "text": "Renormalization",
          "reading_order": 0
        },
        {
          "label": "para",
          "bbox": [
            528,
            98,
            546,
            134
          ],
          "text": "7",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            304,
            520,
            501
          ],
          "text": "In this chapter we will introduce the powerful theoretical methods of renormal-\nization. The fundamental idea is that at $p=p_c$ , a rescaling of the system does\nnot change the most important features. By a rescaling we typically mean a coarse-\ngraining of the system, such as merging $2\\times 2$ cells into a single cell. The rule we use\nto choose the occupation probability of the new, coarse-grained cell, $p'$ , is a function\nof the probability $p$ of the original lattice, $p'=R(p)$ . In renormalization theory,\nwe use properties of this mapping, $R(p)$ , to deduce properties of the system such\nas critical exponents. In this chapter, you will be introduced to the fundamentals of\nrenormalization theory in the context of percolation systems, in which the geometric\nnature of the remapping allow us to build intuition about renormalization as a\nconcept. We will also apply the theory to different lattice structures and for one,\ntwo and three-dimensional systems.",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            501,
            520,
            613
          ],
          "text": "We have now learned that when $p$ approaches $p_c$ , the correlation length grows\nto infinity, and the spanning cluster becomes a self-similar fractal structure. This\nimplies that the spanning cluster at $p_c$ has statistical self-similarity: if we cut out\na piece of the spanning cluster, and rescale the lengths in the system, the rescaled\nsystem will have the same statistical geometrical properties as the original system.\nIn particular, the rescaled system will have the same mass scaling relation: it will\nalso be a self-similar fractal with the same scaling properties.",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            616,
            520,
            725
          ],
          "text": "What happens when $p\\neq p_c$ ? In this case, there will be a finite correlation length,\n$\\xi$ , and a rescaling of the lengths in the system implies that the correlation length is\nalso rescaled. A rescaling by a factor $b$ corresponds to making a coarse-graining\nover $b^d$ sites in order to form the new lattice. Now, we will simply assume that this\nalso implies that the correlation length is reduced by a factor $b$ : $\\xi'=\\xi/b$ . After a\nfew iterations of this rescaling procedure, the correlation length will correspond to\nthe lattice size and the lattice will be uniform.",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            725,
            520,
            774
          ],
          "text": "We could have made this argument even simpler by initially stating that we divide\nthe system into parts that are larger than the correlation length. Again, this would\nlead to a system that is homogeneous from the smallest lattice spacing an upwards.",
          "reading_order": 5
        },
        {
          "label": "foot",
          "bbox": [
            72,
            806,
            396,
            845
          ],
          "text": "© The Author(s) 2024\nA. Malthe-Sørenssen, Percolation Theory Using Python, Lecture Notes\nin Physics 1029, https://doi.org/10.1007/978-3-031-59900-2_7",
          "reading_order": 6
        },
        {
          "label": "foot",
          "bbox": [
            501,
            806,
            520,
            816
          ],
          "text": "101",
          "reading_order": 7
        }
      ]
    },
    {
      "page_number": 110,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            58
          ],
          "text": "102",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            421,
            44,
            520,
            62
          ],
          "text": "7 Renormalization",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            128
          ],
          "text": "We can conclude that when $p<p_c$ , the system behaves as a uniform, unconnected\nsystem and when $p>p_c$ , the system is uniform and connected.",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            128,
            520,
            209
          ],
          "text": "group argument . It is only exactly at $p=p_c$ that an iterative rescaling is a non-\ntrivial fix point: the system iterates onto itself because it is a self-similar fractal.\nWhen $p$ is away from $p_c$ , rescaling iterations will make the system progressively\nmore homogeneous, and effectively bring the rescaled $p$ towards either 0 or 1.\nIn this chapter we will provide an introduction to the theoretical framework for",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            209,
            520,
            259
          ],
          "text": "renormalization. This is a powerful set of techniques, introduced for equilibrium\ncritical phenomena by Kadanoff [ 19 ] in 1966 and by Wilson [ 39 ] in 1971. Wilson\nlater received the Nobel prize for his work on critical phenomena.",
          "reading_order": 4
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            286,
            327,
            306
          ],
          "text": "7.1 The Renormalization Mapping",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            322,
            520,
            439
          ],
          "text": "What happens when we coarse-grain a percolation system? What does it mean to\ncoarse-grain? It means that we replace a $2\\times2$ cell with a single cell using a specified\nrule, which aims at retaining connectivity. An example of such a rule is given in\nFig. 7.1 . For each possible $2\\times2$ configuration, we show if it maps onto an occupied\nor an empty cell. Let us now apply this rule to a 64 $\\times$ 64 system for three different\nvalues of $p$ as illustrated in Fig. 7.2 . We iterate the procedure several time, reducing\nthe system size with a factor of 2 each time.",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            448,
            520,
            596
          ],
          "text": "Behavior Through Iterations What happens in this system? When $p=p_c$ , then\n$\\xi$ is infinte. This means that $\\xi$ does not change we divide the system size by 2.\nWe see that the system appears similar throughout the iteration, and the final single\nsite is occupied. This is because the system is a self-similar fractal and does not\nchange significantly through the iterations. What happens when $p>p_c$ ? In this\ncase, we see that the system becomes more homogeneous through each iteration\nand eventually the whole system is filled. This means that the effective percolation\nprobability becomes higher through the iterations. Similarly, when $p>p_c$ , the\nsystem becomes more homogeneous, but also more empty, as the iterations proceed.",
          "reading_order": 7
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_110_figure_008.png)",
          "figure_path": "figures/percolation_studies_page_110_figure_008.png",
          "bbox": [
            63,
            627,
            520,
            752
          ],
          "reading_order": 8
        },
        {
          "label": "cap",
          "bbox": [
            72,
            761,
            520,
            799
          ],
          "text": "Fig. 7.1 Illustration of a renormalization rule for a site percolation problem with a rescaling\n$b=2$ . The top row shows the 16 configurations $c$ . The middle row show the 6 classes $k$ with\nmultiplicities $g(k)$",
          "reading_order": 9
        }
      ]
    },
    {
      "page_number": 111,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            233,
            62
          ],
          "text": "7.1 The Renormalization Mappin",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            520,
            58
          ],
          "text": "103",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_111_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_111_figure_002.png",
          "bbox": [
            72,
            80,
            520,
            277
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            286,
            520,
            323
          ],
          "text": "Fig. 7.2 Illustration of averaging using a rescaling $b=2$ , so that a cell of size $b\\times b=2\\times 2$ is\nreduced to a single site, producing a “ renormalized ” system of size $L/2$ . We iterate the procedure\nuntil $L=1$ , that is, only a single site is left",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            357,
            520,
            385
          ],
          "text": "This means that the effective percolation probability becomes lower through the\niterations.",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            403,
            520,
            576
          ],
          "text": "Renormalization Means Changing the Occupation Probability In the original\nlattice the occupation probability is $p$ . However, through our coarse-graining\nprocedure, we may change the occupation probability for the new, averaged sites.\nWe will therefore call the new occupation probability $p'$ , the probability to occupy\na renormalized site. We write the mapping between the original and the new\noccupation probabilities as\n\\[ p'=R(p)~,\\eqno{(7.1)}\\]\nwhere the renormalization function $R(p)$ , which provides the mapping, depends on\nthe details of the rule used for renormalization.",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            599,
            520,
            806
          ],
          "text": "Selecting a Renormalization Rule There are many choices for the mapping\nbetween the original and the renormalized lattice. We have illustrated a particular\nmapping with a rescaling $b=2$ in Fig. 7.1 . Such a mapping describes how each of\nthe $4^2=16$ possible configurations $c$ of the $2\\times 2$ system is mapped onto a $1\\times 1$\nsingle site through a function $f(c)$ , where $f(c)$ is 1 if the new site is occupied and\n0 if it is empty. The renormalization mapping is then\n$$R(p)=\\sum_{c}P(c) f(c)~, \\eqno(7.2)$$\nwhere $P(c)$ is the probability for configuration $c$ . It is often practical to organize\nthe configurations into classes $k$ , where each class has the same number of occupied\nsites and hence the same probability $P(k)$ , and the number of configurations in class",
          "reading_order": 6
        }
      ]
    },
    {
      "page_number": 112,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            58
          ],
          "text": "104",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            421,
            44,
            511,
            58
          ],
          "text": "7 Renormalizatio",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            161
          ],
          "text": "$k$ is called the multiplicity g( k ) of the class. Expressed in terms of the classes k, the\nrenormalization mapping is\nR(p)=sum_{k}g(k)P(k)f(k)\\;.\\eqno(7.3)",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            178,
            520,
            295
          ],
          "text": "For the particular mapping provided in Fig. 7.1 , the renormalization mapping\nbecomes\n$$\\begin{aligned}\nR(p)&=1\\cdot p^4\\cdot 1+4\\cdot p^3(1-p)^1\\cdot 1+4\\cdot p^2(1-p)^2\\cdot 1\\\\\n&+2\\cdot p^2(1-p)^2\\cdot 0+4\\cdot p^1(1-p)^3\\cdot 0+1\\cdot (1-p)^4\\cdot 0\\\\\n&=p^4+4p^3(1-p)+4p^2(1-p^2)~.\n\\end{aligned}$$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            304,
            520,
            421
          ],
          "text": "This illustrates a particular rule, but there are many possible rules. Usually, we\nwant to ensure that important aspects of the percolation system is preserved by the\nmapping. For example, we would want the mapping to conserve connectivity. That\nis, we would like to ensure that\n\\[ \\Pi(p,L)=\\Pi(p',\\frac{L}{b})~.\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:f2-bound}\\]",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            430,
            520,
            493
          ],
          "text": "However, even though we may ensure this on the level of the mapping, this does\nnot ensure that the mapping actually conserves connectivity when applied to a large\ncluster. It may, for example, connect clusters that were unconnected in the original\nlattice, or disconnect clusters that were connected, as illustrated in Fig. 7.3 .",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            510,
            520,
            541
          ],
          "text": "Properties of the Renormalization Mapping First, we will not consider the\ndetails of the renormalization mapping $p'=R(p)$ , but instead assume that such",
          "reading_order": 6
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_112_figure_007.png)",
          "figure_path": "figures/percolation_studies_page_112_figure_007.png",
          "bbox": [
            134,
            573,
            450,
            716
          ],
          "reading_order": 7
        },
        {
          "label": "cap",
          "bbox": [
            72,
            725,
            520,
            779
          ],
          "text": "Fig. 7.3 Illustration of a single step of renormalization on an $8\\times 8$ lattice of sites. We see that the\nrenormalization procedure introduces new connections: the blue cluster is now much larger than\nin the original. However, the procedure also removes previously existing connections: the original\nyellow cluster is split into two separate clusters",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 113,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            233,
            62
          ],
          "text": "7.1 The Renormalization Mappin",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            512,
            58
          ],
          "text": "10",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            128
          ],
          "text": "a map exists and study its qualitative features. Then we will address detailed\nproperties of the renormalization mapping through two worked examples.\nFor any choice of mapping, the rescaling will result in a change in the correlation",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            128,
            520,
            197
          ],
          "text": "length $\\xi$ :\n$$\\xi^{\\prime}=\\xi\\left(p^{\\prime}\\right)=\\frac{1}{b} \\xi(p) .\\qquad\\qquad\\qquad\\qquad\\qquad(7.6)$$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            206,
            476,
            219
          ],
          "text": "We will use this relation to address the behavior of fixpoints of the mapping",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            88,
            250,
            502,
            322
          ],
          "text": "Fixpoint A fixpoint of a mapping R(p) is a point p∗ that does not change\nwhen the mapping is applied. That is\n\\begin{equation}  p^*=R(p^*)~.\\end{equation}",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            365,
            520,
            439
          ],
          "text": "Trivial Fixpoints At a fixpoint, the iteration relation for the correlation length\nbecomes:\n$$\\xi(p^*)=\\frac{\\xi(p^*)}{b}~. \\eqno(7.8)$$",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            448,
            520,
            501
          ],
          "text": "The only possible solutions for this equation are that $\\xi=0$ or $\\xi=\\infty$ . We call\nthe case when $\\xi=0$ a trivial fixed point. There are two trivial fixed points for any\nrenormalization mapping at $p=0$ and at $p=1$ .",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            518,
            520,
            663
          ],
          "text": "Stable and Unstable Fixpoints Let us assume that there exists a non-trivial\nfixpoint $p^*$ , and let us address the behavior for $p$ close to $p^*$ . We notice that for any\nfinite $\\xi$ , iterations by the renormalization relation will reduce $\\xi$ . That is, both for\n$p<p^*$ and for $p>p^*$ iterations will make $\\xi$ smaller. This implies that iterations\nwill take the system further away from the non-trivial fixpoint, where the correlation\nlength is infinite. The non-trivial fixpoint is therefore an unstable fixpoint . Similarly,\nfor $p$ close to a trivial fixpoint, where $\\xi=0$ , iterations will decrease $\\xi$ , and the\nrenormalized system will move closer to the fixpoint in each iteration. The trivial\nfixpoint is therefore stable .",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            72,
            672,
            520,
            806
          ],
          "text": "Graphical Interaction of the Renormalization Relation Iterations by the renor-\nmalization relation $p'=R(p)$ may be studied on the graph $R(p)$ , as illustrated in\nFig. 7.4 . Consecutive iterations take the system along the arrows illustrated in the\nfigure. Notice that the line $p'=p$ is drawn as a dotted reference line. In the figure,\nthe two end points, $p=0$ and $p=1$ are the only stable fixpoints, and the point $p^*$\nis the only unstable fixpoint. The actual shape of the function $R(p)$ depends on the\nrenormalization rule, and the shape may be more complex than what is illustrated in\nFig. 7.4 .",
          "reading_order": 9
        }
      ]
    },
    {
      "page_number": 114,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            58
          ],
          "text": "106",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            421,
            44,
            520,
            62
          ],
          "text": "7 Renormalization",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_114_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_114_figure_002.png",
          "bbox": [
            134,
            80,
            457,
            385
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            393,
            520,
            501
          ],
          "text": "Fig. 7.4 Illustration the renormalization mapping $p'=R(p)$ as a function of $p$ . The non-trivial\nfixpoint $p^*=R(p^*)$ is illustrated. Two iterations sequences are illustrated by the lines with arrows.\nLet us look at the path starting from $p>p^*$ . Through the first application of the mapping, we read\noff the resulting value of $p'$ . This value will then be the input value for the next application of\nthe renormalization mapping. A fast way to find the corresponding position along the $p$ axis is to\nreflect the $p'$ value from the line $p'=p$ shown as a dotted line. This gives the new $p$ value, and\nthe mapping is applied again producing yet another $p'$ which is even further from $p^*$ . With the\ndrawn shape of $R(p)$ there is only one non-trivial fixpoint, which is unstable",
          "reading_order": 3
        },
        {
          "label": "sec",
          "bbox": [
            72,
            528,
            331,
            546
          ],
          "text": "Iterating the Renormalization Mapping",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            563,
            520,
            657
          ],
          "text": "We are now ready for a more quantitative argument for the effect of iterations\nthrough the renormalization mapping $R(p)$ . First, we notice that the non-trivial\nfixpoint corresponds to the percolation threshold of the renormalization model, since\nthe correlation length is diverging for this value of $p$ . (This does not imply that $p^*$\nis equal to $p_c$ . As we shall see, $p^*$ depends on the choice of $R(p)$ ).\nWe will now assume that $R(p)$ is differentiable, which it should be since $R(p)$",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            657,
            520,
            806
          ],
          "text": "is based on sums of polynomials of $p$ and $1-p$ . Let us study the behavior close to\n$p^*$ through a Taylor expansion of the mapping $p'=R(p)$ . First, we notice that\n\\begin{equation}\n    p'-p^*=R(p)-R(p^*)~,\n    \\end{equation}\nbecause $p'=R(p)$ and $p^*=R(p^*)$ . The Taylor expansion of $R(p)$ for a $p$ close\nto $p^*$ is:\n\\begin{equation}\n    R(p)=R(p^*)+R'(p^*)(p-p^*)+\\mathscr{O}(p-p^*)^2~.\n    \\end{equation}",
          "reading_order": 6
        }
      ]
    },
    {
      "page_number": 115,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            233,
            62
          ],
          "text": "7.1 The Renormalization Mappin",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            520,
            58
          ],
          "text": "107",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            134
          ],
          "text": "If we define $\\varLambda=R'(p^{*})$, we get that to first order in $p-p^{*}$:",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            143,
            520,
            226
          ],
          "text": "We see that the value of $\\varLambda$ characterizes the fixpoint. For $\\varLambda>1$ the new point $p'$\nwill be further away from $p^*$ than the initial point $p$ . Consequently, the fixpoint is\nunstable. By a similar argument, we see that for $\\varLambda<1$ the fixpoint is stable. For\n$\\varLambda=1$ we call the fixpoint a marginal fixpoint.\nLet us now assume that the fixpoint is indeed the percolation threshold. In this",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            226,
            520,
            403
          ],
          "text": "case, when $p$ is close to $p_c$ , we know that the correlation length is\n\\[\n    \\xi(p)=\\xi_0(p-p_c)^{-v}~,\\eqno(7.12)\n  \\]\nfor the initial point, and\n\\[\n    \\xi(p')=\\xi_0(p'-p_c)^{-v}\\eqno(7.13)\n  \\]\nfor the renormalized point. We will now use for $p^*=p_c$ , giving\n\\[\n    p'-p_c=A(p-p_c)~.\\eqno(7.14)\n  \\]",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            421,
            520,
            474
          ],
          "text": "Inserting this into ( 7.13 ) gives\n\\[\n\\xi(p^{\\prime})=\\xi_{0}\\left(p^{\\prime}-p_{c}\\right)^{-v}=\\xi_{0}\\left(A\\left(p-p_{c}\\right)\\right)^{-v}=\\xi_{0} A^{-v}\\left(p-p_{c}\\right)^{-v}\\,.\\qquad(7.15)\n\\]",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            483,
            520,
            537
          ],
          "text": "We can rewrite this using $\\xi(p)$\n$$\\xi(p')=A^{-v}\\xi(p)~.\\eqno(7.16)$$",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            546,
            224,
            564
          ],
          "text": "However, we also know that",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            250,
            573,
            520,
            609
          ],
          "text": "$$\\xi(p^{\\prime})=\\frac{1}{b} \\xi(p) .\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad(7.17)$$",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            72,
            625,
            253,
            638
          ],
          "text": "Consequently, we have found that",
          "reading_order": 9
        },
        {
          "label": "para",
          "bbox": [
            269,
            654,
            520,
            672
          ],
          "text": "b=A^{v} .\\space(7.18)",
          "reading_order": 10
        },
        {
          "label": "para",
          "bbox": [
            72,
            689,
            520,
            792
          ],
          "text": "This implies that the exponent $v$ is a property of the fixpoint of the mapping $R(p)$ .\nWe can find $v$ from\n\\[ v=\\frac{\\ln b}{\\ln A}~,\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:lorenz2}\\]\nwhere we remember that $\\Lambda=R'(p_c)$ .",
          "reading_order": 11
        }
      ]
    },
    {
      "page_number": 116,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            58
          ],
          "text": "108",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            421,
            44,
            520,
            62
          ],
          "text": "7 Renormalization",
          "reading_order": 1
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            80,
            179,
            98
          ],
          "text": "7.2 Example",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            116,
            520,
            162
          ],
          "text": "In the following we provide several examples of the application of the renormal-\nization theory. Our renormalization procedure can be summarized in the following\nsteps",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            179,
            323,
            197
          ],
          "text": "1. Coarse-grain the system into cells of size $b^d$",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            197,
            520,
            227
          ],
          "text": "2. Find a rule to determine the new occupation probability, $p'$ , from the old\noccupation probability, $p\\colon p'=R(p)$ .",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            227,
            520,
            259
          ],
          "text": "3. Determine the non-trivial fixpoints, $p^*$ , of the renormalization mapping: $p^*=R(p^*)$ , and use these points as approximations for $p_c$ : $p_c=p^*$ .",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            259,
            520,
            291
          ],
          "text": "4. Determine the rescaling factor $\\varLambda $ from the renormalization relation at the fixpoint:\n$\\varLambda =R'(p^{*})$.",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            291,
            304,
            305
          ],
          "text": "5. Find $v$ from the relation $v=\\ln b/\\ln A$.",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            72,
            322,
            520,
            372
          ],
          "text": "It is important to realize that the renormalization mapping $R(p)$ is not unique.In\norder to obtain useful results we should ensure that the mapping preserves connec-\ntivity on average.",
          "reading_order": 9
        },
        {
          "label": "sub_sub_sec",
          "bbox": [
            72,
            403,
            328,
            421
          ],
          "text": "Example: One-Dimensional Percolation",
          "reading_order": 10
        },
        {
          "label": "para",
          "bbox": [
            72,
            439,
            520,
            565
          ],
          "text": "Let us first address the one-dimensional percolation problem using the renormal-\nization procedure. We have illustrated the one-dimensional percolation problem in\nFig. 7.5 . We generate the renormalization mapping by ensuring that it conserves\nconnectivity. The probability for two sites to be connected over a distance $b$ is $p^{b}$\nwhen the occupation probability for a single site is $p$ . A renormalization mapping\nthat conserves connectivity is therefore:\n\\[ p'=\\varPi(p,b)=p^{b}~.\\tag{7.20}\\]",
          "reading_order": 11
        },
        {
          "label": "para",
          "bbox": [
            72,
            582,
            520,
            694
          ],
          "text": "The fixpoints for this mapping are\n\\[p^*=(p^*)^b~,\\eqno{(7.21)}\\]\nwith only two possible solutions, $p^*=0$ , and $p^*=1$ . An example of a\nrenormalization iteration is shown in Fig. 7.6 . The curve illustrates that $p^*=0$\nis the only attractive or stable fixpoint, and that $p^*=1$ is an unstable fixpoint.",
          "reading_order": 12
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_116_figure_013.png)",
          "figure_path": "figures/percolation_studies_page_116_figure_013.png",
          "bbox": [
            242,
            716,
            520,
            806
          ],
          "reading_order": 13
        },
        {
          "label": "cap",
          "bbox": [
            72,
            725,
            189,
            788
          ],
          "text": "Fig. 7.5 Illustration of a\nrenormalization rule for a\none-dimensional site\npercolation system with\n$b=3$",
          "reading_order": 14
        }
      ]
    },
    {
      "page_number": 117,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            143,
            62
          ],
          "text": "7.2 Examples",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            512,
            58
          ],
          "text": "10",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_117_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_117_figure_002.png",
          "bbox": [
            125,
            80,
            466,
            295
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            304,
            512,
            331
          ],
          "text": "Fig. 7.6 Illustration of a renormalization rule for a one-dimensional site percolation system with\n$b=3$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            358,
            520,
            537
          ],
          "text": "We can also apply the theory directly to find the exponent $\\nu$ . The renormalization\nrelation is $p'=R(p)=p^b$ . We can therefore find $\\varLambda$ from:\n$$\\varLambda=\\left.\\frac{\\partial R}{\\partial p}\\right|_{p^*}=b(p^*)^{b-1}=b~,\\eqno(7.22)$$\nwhere we are now studying the unstable fixpoint $p^*=1$ . We can therefore\ndetermine $\\nu$ from ( 7.19 ):\n$$\\nu=\\frac{\\ln b}{\\ln \\varLambda}=1~.$$",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            546,
            520,
            672
          ],
          "text": "We notice that $b$ was eliminated in this procedure, which is essential since we do\nnot want the exponent to depend on details such as the size of renormalization cell.\nThe result for the scaling of the correlation length is therefore\n\\[\n    \\xi \\propto \\frac{1}{1-p}~, \\eqno(7.24)\n  \\]\nwhen $1-p\\ll 1$ .",
          "reading_order": 5
        },
        {
          "label": "sec",
          "bbox": [
            72,
            698,
            361,
            718
          ],
          "text": "Example: Renormalization on 2d Site Lattice",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            734,
            518,
            783
          ],
          "text": "Let us now use this method to address a renormalization scheme for two-\ndimensional site percolation. We will use a scheme with $b=2$ . The possible\nconfigurations for a $2\\times 2$ lattice are shown in Fig. 7.7 .",
          "reading_order": 7
        }
      ]
    },
    {
      "page_number": 118,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            90,
            58
          ],
          "text": "110",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            421,
            44,
            520,
            58
          ],
          "text": "7 Renormalization",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_118_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_118_figure_002.png",
          "bbox": [
            72,
            80,
            512,
            206
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            215,
            520,
            255
          ],
          "text": "Fig. 7.7 Possible configurations for a $2\\times2$ site percolation system. The top row indicates various\nconfigurations and the middle row how the configurations are categorized into $7$ classes $k$ , where\n$g(k)$ is the number of configurations in class $k$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            286,
            520,
            546
          ],
          "text": "In order to preserve connectivity, we need to ensure that classes $k=1$ and $k=2$\nare occupied also in the renormalized lattice. However, we have some freedom as to\nwhich configurations to include in the class $k=3$ and $k=4$ . We may choose only\nto consider spanning in one direction or spanning in both directions. In the mapping\nin Fig. 7.7 we only include horizontal spanning. Then the renormalization relation\nbecomes\n$$p'=R(p)=\\sum_{k}g(k)P(k)f(k)=1\\cdot p^4\\cdot 1+4\\cdot p^3(1-p)^1\\cdot 1$$\n$$+2\\cdot p^2(1-p)^2\\cdot 1+2\\cdot p^2(1-p)^2\\cdot 0+2\\cdot p^2(1-p)^2\\cdot 0\\\\+4\\cdot p^1(1-p)^3\\cdot 0+1\\cdot (1-p)^4\\cdot 0=p^4+4p^3(1-p)+2p^2(1-p^2)\\;.$$\n$$(7.25)$$\nwhere $f(k)=1$ if class $k$ is mapped onto an occupied site and $f(k)=0$ if class $k$\nis mapped onto an empty site. The renormalization relation is illustrated in Fig. 7.8 .",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            546,
            520,
            609
          ],
          "text": "We will now follow steps 3 and 4. First, in step 3, we determine the fixpoints of\nthe renormalization relation. That is, we find the solutions to the equation\n\\[p^*=R(p^*)=(p^*)^4+4(p^*)^3(1-p^*)+2(p^*)^2(1-p^*)^2~.\\eqno{(7.26)}\\]",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            627,
            520,
            680
          ],
          "text": "The trivial solution $p^*=0$ is not of interest. Therefore we divide by $p^*$ to produce\n\\[(p^*)^3+4(p^*)^2(1-p^*)+2(p^*)(1-p^*)^2=1~.\\tag{7.27}\\]",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            689,
            520,
            743
          ],
          "text": "The other trivial fixpoint is $p^{*}=1$. We divide the equation by $1-p^{*}$ to get\n\\[(p^{*})^{2}+p^{*}-1=0~.\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:thm_bound}\\]",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            752,
            520,
            824
          ],
          "text": "The solutions to this second order equation are\n\\[p^{*}=-\\frac{1 \\pm \\sqrt{1+4}}{2}=\\frac{\\sqrt{5} \\pm 1}{2} \\simeq 0.62~.\\eqno(7.29)\\]",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 119,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            143,
            62
          ],
          "text": "7.2 Examples",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            511,
            58
          ],
          "text": "11",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_119_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_119_figure_002.png",
          "bbox": [
            143,
            80,
            457,
            295
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            304,
            520,
            332
          ],
          "text": "Fig. Plot of the renormalization relation $p'=R(p)=p^4+4 p^3(1-p)+2 p^2(1-p)^2$ for a\ntwo-dimensional site percolation problem",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            358,
            520,
            430
          ],
          "text": "We have therefore found an estimate of $p_c$ by setting $p_c=p^*$ . This does not\nproduce the correct value for $p_c$ in a two-dimensional site percolation system, but\nthe result is still reasonably correct. We can similarly estimate the exponent $\\nu$ by\ncalculating $R'(p^*)$ .",
          "reading_order": 4
        },
        {
          "label": "sec",
          "bbox": [
            72,
            456,
            404,
            474
          ],
          "text": "Example: Renormalization on 2d Triangular Lattice",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            492,
            520,
            603
          ],
          "text": "We will now use the same method to address percolation on site percolation on a\ntriangular lattice. A triangular lattice is a lattice where each point has six neighbors.\nIn solid state physics, the lattice is known as the hexagonal lattice because of its\nhexagonal rotation symmetry. Site percolation on the triangular lattice is particularly\nwell suited for renormalization treatment, because a coarse grained version of the\nlattice is also a triangular lattice, as illustrated in Fig. 7.9 , with a lattice spacing\n$b=\\sqrt{3}$ times the original lattice size.",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            603,
            520,
            734
          ],
          "text": "We will use the majority rule for the renormalization mapping. That is, we will\nmap a set of three sites onto an occupied site if a majority of the sites are occupied,\nmeaning that two or more sites are occupied. Otherwise, the renormalized site is\nempty. This mapping is illustrated in Fig. 7.9 . This mapping does, as the reader may\neasily check, on the average conserve connectivity. The renormalization mapping\nbecomes\n\\[p'=R(p)=p^3+3p^2(1-p)=3p^2-2p^3~.\\tag{$7.30}\\]",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            751,
            520,
            797
          ],
          "text": "The fixpoints of this mapping are the solutions of the equation\n\\[p^*=3(p^*)^2-2(p^*)^3~.\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:frequistic_rho}\\]",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 120,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            58
          ],
          "text": "112",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            421,
            44,
            511,
            58
          ],
          "text": "7 Renormalizatio",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_120_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_120_figure_002.png",
          "bbox": [
            125,
            80,
            457,
            394
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            403,
            520,
            457
          ],
          "text": "Fig. 7.9 Illustration of a renormalization scheme for site percolation on a triangular lattice. The\nrescaling factor is $b=\\sqrt{3}$ , and we use the majority rule for the mapping, that is, classes $k=1$ and\n$k=2$ are occupied, and classes $k=3$ and $k=4$ are mapped onto empty sites. Here, $g(1)=1$ ,\n$g(2)=3$ , $g(3)=3$ and $g(4)=1$ , giving $8=2^3$ configurations",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            483,
            520,
            537
          ],
          "text": "We observe that the trivial fixpoints $p^*=0$ and $p^*=1$ indeed satisfy ( 7.31 ) . The\nnon-trivial fixpoint is $p^*=1/2$ . We are pleased to observe that this is the exact\nsolution for $p_c$ for site percolation on the triangular lattice.",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            537,
            520,
            609
          ],
          "text": "We can use this relation to determine the scaling exponent $\\nu$ . First, we calcu-\nlate $A$ :\n$$\n\\Lambda=R^{\\prime}\\left(p^{*}\\right)=\\left.6 p(1-p)\\right|_{p=\\frac{1}{2}}=\\frac{3}{2} .\n$$",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            625,
            506,
            716
          ],
          "text": "As a result we find the exponent $\\nu$ from\n$$\\frac{1}{\\nu}=\\frac{\\ln \\Lambda}{\\ln b}=\\frac{\\ln 3/2}{\\ln \\sqrt{3}}\\simeq 1.355~,\\eqno(7.3)$$",
          "reading_order": 6
        }
      ]
    },
    {
      "page_number": 121,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            143,
            62
          ],
          "text": "7.2 Examples",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            520,
            58
          ],
          "text": "113",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_121_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_121_figure_002.png",
          "bbox": [
            72,
            89,
            511,
            224
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            241,
            520,
            313
          ],
          "text": "Fig. 7.10 ( a ) Illustration of a renormalization scheme for bond percolation on a square lattice\nin two dimensions. The rescaling factor is $b=2$ . ( b ) In general, the renormalization involves\na mapping from 8 to two bonds. However, we will consider percolation only in the horizontal\ndirection. This simplifies the mapping, to the figure shown in ( c ). For this mapping, the classes are\nshown and enumerated in ( d )",
          "reading_order": 3
        },
        {
          "label": "sec",
          "bbox": [
            72,
            340,
            376,
            358
          ],
          "text": "Example: Renormalization on 2d Bond Lattice",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            375,
            520,
            519
          ],
          "text": "As our last example of renormalization in two-dimensional percolation problems,\nwe will study the bond percolation problem on a square lattice. The renormalization\nprocedure is shown in Fig. 7.10 . In the renormalization procedure, we replace 8\nbonds by 2 new bonds. We consider connectivity only in the horizontal direction,\nand may therefore simplify the lattice, by only considering the mapping of the H-\ncell, a mapping of five bonds onto one bond in the horizontal direction. The various\nconfigurations are shown in the figure. In Table 7.1 we have shown the number of\nsuch configurations, and the probabilities for each configuration, which is needed in\norder to calculate the renormalization connection probability $p'$ .",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            519,
            528,
            779
          ],
          "text": "The resulting renormalization equation is given as\n\\[p'=R(p)=\\varPi = \\sum_{c=1}^{13} n(c) P(c) \\varPi| c~,\\eqno(7.34)\\]\nwhere we have used $k$ to denote the various classes, $P(k)$ is the probability for\none instance of class $k$ , $n(k)$ is the number of different configurations due to\nsymmetry consideration in class $k$ , and $\\varPi| k$ is the spanning probability given that\nthe configuration is in class $k$ . The resulting relation is\n\\[\\begin{split} p'&= R(p)\\\\&= p^5+p^4(1-p)+4p^4(1-p)+2p^3(1-p)^2\\\\&\\quad+2p^3(1-p)^2+4p^3(1-p)^2+2p^2(1-p)^3\\\\&= 2p^5-5p^4+2p^3+2p^2~.\\eqno(7.38)\\end{split}\\]",
          "reading_order": 6
        }
      ]
    },
    {
      "page_number": 122,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            58
          ],
          "text": "114",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            421,
            44,
            520,
            62
          ],
          "text": "7 Renormalization",
          "reading_order": 1
        },
        {
          "label": "tab",
          "bbox": [
            340,
            80,
            520,
            439
          ],
          "text": "<table><tr><td>k</td><td rowspan=\"2\">P( k ) p 5 (1 − p ) 0</td><td rowspan=\"2\">n ( k ) 1</td><td rowspan=\"2\">Π| k  1</td></tr><tr><td colspan=\"2\">1</td></tr><tr><td>2</td><td>p 4 (1 − p ) 1</td><td>1</td><td>1</td></tr><tr><td>3</td><td>p 4 (1 − p ) 1</td><td>4</td><td>1</td></tr><tr><td>4</td><td>p 3 (1 − p ) 2</td><td>2</td><td>1</td></tr><tr><td>5</td><td>p 3 (1 − p ) 2</td><td>2</td><td>1</td></tr><tr><td>6</td><td>p 3 (1 − p ) 2</td><td>2</td><td>0</td></tr><tr><td>7</td><td>p 3 (1 − p ) 2</td><td>4</td><td>1</td></tr><tr><td>8</td><td>p 2 (1 − p ) 3</td><td>2</td><td>1</td></tr><tr><td>9</td><td>p 2 (1 − p ) 3</td><td>4</td><td>0</td></tr><tr><td>10</td><td>p 2 (1 − p ) 3</td><td>2</td><td>0</td></tr><tr><td>11</td><td>p 2 (1 − p ) 3</td><td>2</td><td>0</td></tr><tr><td>12</td><td>p 1 (1 − p ) 4</td><td>5</td><td>0</td></tr><tr><td>13</td><td>p 0 (1 − p ) 5</td><td>1</td><td>0</td></tr></table>",
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            80,
            208,
            206
          ],
          "text": "A 7.1 A list of the\npossible classes $k$ for\nrenormalization of a bond\nlattice. The probability for\npercolation given that the\nclass is $k$ is denoted $\\varPi|k$ . The\nspanning probability for the\nwhole cell is then $\\varPi(p)=p'=\\sum_{k}n(k)P(k)\\varPi|k$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            474,
            520,
            573
          ],
          "text": "The fixpoints for this mapping are $p^*=0$ , $p^*=1$ , and $p^*=1/2$ . The fixpoint\n$p^*=1/2$ provides the exact solution for the percolation threshold on the bond\nlattice in two dimensions. We find $\\varLambda$ by derivation\n$$\\varLambda=R'(p^*)=\\frac{13}{8}~. \\eqno(7.39)$$",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            582,
            520,
            689
          ],
          "text": "The corresponding estimate for the exponent $\\nu$ is\n$$\n\\nu=\\frac{\\ln b}{\\ln A}\\simeq1.428~,\\eqno(7.40)\n$$\nwhich should be compared with the exact result of $\\nu=4/3$ for two-dimensional\npercolation.",
          "reading_order": 5
        }
      ]
    },
    {
      "page_number": 123,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            108,
            58
          ],
          "text": "Exercise",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            520,
            62
          ],
          "text": "115",
          "reading_order": 1
        },
        {
          "label": "sec",
          "bbox": [
            72,
            80,
            135,
            98
          ],
          "text": "Exercises",
          "reading_order": 2
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            116,
            331,
            128
          ],
          "text": "Exercise 7.1 (Renormalization of nnn-Model)",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            143,
            520,
            208
          ],
          "text": "(a) Develop a renormalization scheme for a two-dimensional site percolation\nsystem with next-nearest neighbor (nnn) connectivity. That is, list the 16\npossible configurations, and determine what configuration they map onto in the\nrenormalized lattice.",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            71,
            213,
            403,
            227
          ],
          "text": "(b) Find the renormalized occupation probability $p'=R(p)$ .",
          "reading_order": 5
        },
        {
          "label": "list",
          "bbox": [
            72,
            230,
            233,
            243
          ],
          "text": "(c) Plot $R(p)$ and $f(p)=p$.",
          "reading_order": 6
        },
        {
          "label": "list",
          "bbox": [
            71,
            243,
            322,
            259
          ],
          "text": "(d) Find the fixpoints $p^{*}$ so that $R\\left(p^{*}\\right)=p^{*}$.",
          "reading_order": 7
        },
        {
          "label": "list",
          "bbox": [
            72,
            259,
            304,
            277
          ],
          "text": "(e) Find the rescaling factor $\\Lambda=R^{\\prime}\\left(p^{*}\\right)$.",
          "reading_order": 8
        },
        {
          "label": "list",
          "bbox": [
            72,
            277,
            304,
            291
          ],
          "text": "(f) Determine the exponent $v=\\ln A/\\ln b$",
          "reading_order": 9
        },
        {
          "label": "list",
          "bbox": [
            72,
            294,
            358,
            307
          ],
          "text": "(g) How can we improve the estimates of $p_c$ and $\\nu$ ?",
          "reading_order": 10
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            322,
            511,
            340
          ],
          "text": "Exercise 7.2 (Renormalization of Three-Dimensional Site Percolation Model)",
          "reading_order": 11
        },
        {
          "label": "list",
          "bbox": [
            72,
            357,
            520,
            388
          ],
          "text": "(a) Find all $2^8$ possible configurations for the $2\\times 2\\times 2$ renormalization cell for\nthree-dimensional site percolation.",
          "reading_order": 12
        },
        {
          "label": "list",
          "bbox": [
            71,
            388,
            520,
            421
          ],
          "text": "(b) Determine a renormalization scheme - what configurations map onto an occu-\npied site?",
          "reading_order": 13
        },
        {
          "label": "list",
          "bbox": [
            72,
            421,
            403,
            439
          ],
          "text": "(c) Find the renormalized occupation probability $p^{\\prime}=R(p)$.",
          "reading_order": 14
        },
        {
          "label": "list",
          "bbox": [
            71,
            439,
            233,
            452
          ],
          "text": "(d) Plot $R(p)$ and $f(p)=p$.",
          "reading_order": 15
        },
        {
          "label": "list",
          "bbox": [
            72,
            456,
            322,
            469
          ],
          "text": "(e) Find the fixpoints $p^{*}$ so that $R(p^{*})=p^{*}$.",
          "reading_order": 16
        },
        {
          "label": "list",
          "bbox": [
            72,
            469,
            297,
            485
          ],
          "text": "(f) Find the rescaling factor $\\Lambda=R^{\\prime}\\left(p^{*}\\right)$.",
          "reading_order": 17
        },
        {
          "label": "list",
          "bbox": [
            72,
            485,
            305,
            501
          ],
          "text": "(g) Determine the exponent $v=\\ln{\\varLambda}/\\ln{b}$ .",
          "reading_order": 18
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            519,
            520,
            531
          ],
          "text": "Exercise 7.3 (Renormalization of Three-Dimensional Bond Percolation Model)",
          "reading_order": 19
        },
        {
          "label": "para",
          "bbox": [
            72,
            536,
            520,
            582
          ],
          "text": "In this exercise we will develop an H-cell renormalization scheme for bond\npercolation in three dimensions. The three-dimensional H-cell is illustrated in\nFig. 7.11 .",
          "reading_order": 20
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_123_figure_021.png)",
          "figure_path": "figures/percolation_studies_page_123_figure_021.png",
          "bbox": [
            287,
            609,
            528,
            824
          ],
          "reading_order": 21
        },
        {
          "label": "cap",
          "bbox": [
            72,
            609,
            206,
            636
          ],
          "text": "Fig. 7.11 Illustrations of the\n3d H-cell",
          "reading_order": 22
        }
      ]
    },
    {
      "page_number": 124,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            58
          ],
          "text": "116",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            421,
            44,
            520,
            62
          ],
          "text": "7 Renormalization",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            367,
            98
          ],
          "text": "(a) Find all $2^12$ possible configurations for this H-cell.",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            71,
            98,
            520,
            147
          ],
          "text": "(b) Determine a renormalization scheme - what configurations map onto an occu­\npied site?\n(c) Find the renormalized occupation probability $p'=R(p)$ .",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            147,
            403,
            163
          ],
          "text": "(d) Plot $R(p)$ and $f(p)=p$.",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            164,
            322,
            179
          ],
          "text": "(e) Find the fixpoints $p^{*}$ so that $R\\left(p^{*}\\right)=p^{*}$.",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            179,
            297,
            197
          ],
          "text": "(f) Find the rescaling factor $\\Lambda=R^{\\prime}\\left(p^{*}\\right)$.",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            197,
            305,
            215
          ],
          "text": "(g) Determine the exponent $\\nu=\\ln {\\varLambda }/\\ln b$.",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            72,
            231,
            520,
            260
          ],
          "text": "Exercise 7.4 (Numerical Study of Renormalization) Use the following program\nto study the renormalization of a given sample of a percolation system.",
          "reading_order": 9
        },
        {
          "label": "code",
          "bbox": [
            80,
            277,
            340,
            333
          ],
          "text": "# Coarsening procedure\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.ndimage import measurements",
          "reading_order": 10
        },
        {
          "label": "code",
          "bbox": [
            80,
            349,
            511,
            806
          ],
          "text": "def coarse(z,f):\n#function zz = coarse(z,f)\n# The original array is z\n# The transfer function is f given as a vector\n# with 16 possible places\n# f applied to a two-by-two matrix should return\n# the renormalized values\n#\n# The various values of f correspond to the following\n# configurations of the two-by-two region that is renormalized,\n# where I have used X to mark a present site, and O to mark an\n# empty sites\n#\n0\n00\n4\n00\n8\n00\n12\n00\n##\n00\nXX\nXX\n##\n1\nX0\n5\nX0\n9\nX0\n13\nX0\n##\n00\nXX\n0X\n0X\nxx\n##\n3\nXX\n7\nXX\n11\nXX\n15\nXX\n##\n00\nX0\n0X\n0X\nXX\nXX\n##\nnx = np.shape(z)[0]\nny = np.shape(z)[1]\nif (nx%2==1): # Must be even number\nraise ValueError(’nx must be even’)\nif (ny%2==1): # Must be even number\nraise ValueError(’ny must be even’)\nnx2 = int(nx/2)\nny2 = int(ny/2)\nzz = np.zeros((nx2,ny2),float) # Generate return matrix",
          "reading_order": 11
        }
      ]
    },
    {
      "page_number": 125,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            108,
            58
          ],
          "text": "Exercise",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            520,
            58
          ],
          "text": "117",
          "reading_order": 1
        },
        {
          "label": "code",
          "bbox": [
            107,
            85,
            408,
            188
          ],
          "text": "x = np.zeros((2,2),float)\nfor iy in range(0,ny,2):\nfor ix in range(0,nx,2):\nx = z[ix,iy]*1 + z[ix,iy+1]*2 + \\\nz[ix+1,iy]*4 + z[ix+1,iy+1]*8\nxx = f[int(x)]\nzz[int((ix+1)/2),int((iy+1)/2)] = xx\nreturn zz",
          "reading_order": 2
        },
        {
          "label": "code",
          "bbox": [
            79,
            206,
            494,
            448
          ],
          "text": "# Example of use of the coarsening procedure\nL = 64\nm = np.random.rand(L,L)\nngen = 7\npercimg = []\np = 0.65\nz = (m<p)*1.0\n# Set up array for transformation f\nf = [0,0,0,1,0,0,0,1,0,0,1,1,1,1]\n# Generate labels and loop for next\nfor i in range(ngen):\nlw,num = measurements.label(z)\narea = measurements.sum(z,lw,index=np.arange(lw.max()+1))\nareaImg = area[lw]\npercimg.append(areaImg)\nif (i<ngen-1): # coarse grain for next level\nzz = coarse(z,f)\nz = zz",
          "reading_order": 3
        },
        {
          "label": "code",
          "bbox": [
            80,
            456,
            340,
            552
          ],
          "text": "# Plot the results\nfig = plt.figure(figsize=(4*ngen,3.5))\nfor i in range(ngen):\nax = fig.add_subplot(1,ngen,i+1)\nzi = percimg[i]\nax.imshow(zi)\nax.set_aspect('equal')",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            571,
            520,
            618
          ],
          "text": "Perform successive iterations for $p=0.3$ , $p=0.4$ , $p=0.5$ , $p=p_c$ , $p=0.65$ ,\n$p=0.70$ , and $p=0.75$ , in order to understand the instability of the fixpoint at\n$p=p_c$ .",
          "reading_order": 5
        }
      ]
    },
    {
      "page_number": 126,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            58
          ],
          "text": "118",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            421,
            44,
            511,
            58
          ],
          "text": "7 Renormalizatio",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            518,
            162
          ],
          "text": "Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0\nInternational License ( http://creativecommons.org/licenses/by/4.0/ ), which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as long as you give appropriate\ncredit to the original author(s) and the source, provide a link to the Creative Commons license and\nindicate if changes were made.\nThe images or other third party material in this chapter are included in the chapter's Creative",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            162,
            518,
            216
          ],
          "text": "Commons license, unless indicated otherwise in a credit line to the material. If material is not\nincluded in the chapter's Creative Commons license and your intended use is not permitted by\nstatutory regulation or exceeds the permitted use, you will need to obtain permission directly from\nthe copyright holder.",
          "reading_order": 3
        }
      ]
    },
    {
      "page_number": 127,
      "elements": [
        {
          "label": "header",
          "bbox": [
            528,
            107,
            546,
            134
          ],
          "text": "8",
          "reading_order": 0
        },
        {
          "label": "sec",
          "bbox": [
            72,
            98,
            233,
            125
          ],
          "text": "Subset Geometry",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            304,
            520,
            519
          ],
          "text": "So far, we have studied the geometry of the percolation system. Now, we will\ngradually address the physics of processes that occur in a percolation system.\nWe have addressed one physics-like property of the system, the density of the\nspanning cluster, and we found that we could build a theory for the density $P$ as a\nfunction of the porosity (occupation probability) $p$ of the system. In order to address\nother physical properties, we need to have a clear description of the geometry of\nthe percolation system close to the percolation threshold. In this chapter, we will\ndevelop a simplified geometric description that will be useful, indeed essential,\nwhen we discuss physical process in disordered media. We will introduce various\nsubsets of the spanning cluster — sets that play roles in specific physical processes.\nWe will start by introducing singly connected bonds , the backbone and dangling\nends and provide a simplified image of the spanning cluster in terms of the blob\nmodel for the percolation system [ 2 , 9 , 16 , 34 ] .",
          "reading_order": 2
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            546,
            287,
            564
          ],
          "text": "8.1 Singly Connected Bonds",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            582,
            520,
            628
          ],
          "text": "We will start with an example of a subset of the spanning cluster, the set of singly\nconnected sites (or bonds). This will demonstrate what we mean by a subset and\nhow the subset is connected to a physical problem.",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            88,
            663,
            502,
            694
          ],
          "text": "Singly Connected Site A singly connected site is a site with the property that\nif it is removed, the spanning cluster will no longer be spanning.",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            734,
            520,
            781
          ],
          "text": "We can relate this to a physical property: If we study fluid flow in the spanning\ncluster, all the fluid has to go through the singly connected sites. These sites are\nalso often referred to as red sites, because if we were studying a set of random",
          "reading_order": 6
        },
        {
          "label": "foot",
          "bbox": [
            72,
            806,
            396,
            845
          ],
          "text": "© The Author(s) 2024\nA. Malthe-Sørenssen, Percolation Theory Using Python, Lecture Notes\nin Physics 1029, https://doi.org/10.1007/978-3-031-59900-2_8",
          "reading_order": 7
        },
        {
          "label": "foot",
          "bbox": [
            501,
            806,
            520,
            816
          ],
          "text": "119",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 128,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            58
          ],
          "text": "120",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            419,
            44,
            520,
            62
          ],
          "text": "8 Subset Geometry",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_128_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_128_figure_002.png",
          "bbox": [
            72,
            80,
            520,
            394
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            411,
            520,
            449
          ],
          "text": "Fig. 8.1 Illustration of the spanning cluster, the singly connected bonds (red), the backbone (blue),\nand the dangling ends (green) for a $256\\times256$ bond percolation system at $p=p_c$ . (Figure from\nMartin Søreng)",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            474,
            520,
            528
          ],
          "text": "resistors, the highest current would have to go through the singly connected bonds,\nand they would therefore heat up and become “red”. Several examples of subsets of\nthe spanning cluster, including the singly connected bonds, are shown in Fig. 8.1 .",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            537,
            520,
            620
          ],
          "text": "Scaling Hypothesis We have learned that the spanning cluster may be described\nby the mass scaling relation $M\\propto L^D$ , where $D$ is termed the fractal dimension of\nthe spanning cluster. Here, we will make a daring hypothesis, which we will also\nsubstantiate: We propose that subsets of the spanning cluster obey similar scaling\nrelations.",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            620,
            520,
            788
          ],
          "text": "For example, we propose that the mass of the singly connected sites ( $M_{SC}$ ) has\nthe scaling form\n\\[ M_{SC} \\propto L^{D_{SC}}~,\\eqno(8.1)\\]\nwhere we call the dimension $D_{SC}$ the fractal dimension of the singly connected\nsites. Because the set of singly connected sites is a subset of the spanning cluster,\nwe know that $M_{SC} \\le M$ . It therefore follows that\n\\[ D_{SC} \\le D~.\\eqno(8.2)\\]",
          "reading_order": 6
        }
      ]
    },
    {
      "page_number": 129,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            260,
            62
          ],
          "text": "8.2 Self-Avoiding Paths on the Cluster",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            512,
            58
          ],
          "text": "12",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            128
          ],
          "text": "Based on this simple example, we will generalize the approach to other subsets of\nthe spanning cluster. However, first we will introduce a new concept, a self-avoiding\npath on the spanning cluster.",
          "reading_order": 2
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            161,
            358,
            179
          ],
          "text": "8.2 Self-Avoiding Paths on the Cluster",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            196,
            520,
            306
          ],
          "text": "The study of percolation is the study of connectivity, and many of the physical\nproperties that we are interested in depends on various forms of connecting paths\non the spanning cluster between two opposite edges. We can address the structure\nof connected paths between the edges by studying self-avoiding paths (SAPs). A\nSelf-Avoiding Path (SAP) is a set of connected sites that correspond to the sites on\nthe path of a walk on the spanning cluster that does not intersect itself going from\none side to the opposite side.",
          "reading_order": 4
        },
        {
          "label": "sec",
          "bbox": [
            72,
            339,
            161,
            351
          ],
          "text": "Minimal Path",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            367,
            520,
            467
          ],
          "text": "The shortest path between the two edges is called the shortest SAP between the two\nedges. (Notice, that there may be more than one path the satisfy this criterion. We\nchose one of these paths randomly). We call this the minimal path and denote its\nlength $L_{\\min}$ . The length here refers to the number of sites in the path, which we also\ncall the mass of the path, $M_{\\min}=L_{\\min}$ . We will use mass instead of length in the\nfollowing to describe the paths.",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            467,
            520,
            537
          ],
          "text": "We assume that mass of the minimal path also scales with the system size\naccording to the scaling form:\n\\[M_{\\min} \\propto L^{D_{\\min}}~.\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:summarize}\\]",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            546,
            502,
            564
          ],
          "text": "Where we have introduced the scaling exponent of the minimal path to be $D_{\\min }$.",
          "reading_order": 8
        },
        {
          "label": "sec",
          "bbox": [
            72,
            597,
            251,
            612
          ],
          "text": "Maximum and Average Patl",
          "reading_order": 9
        },
        {
          "label": "para",
          "bbox": [
            72,
            627,
            520,
            692
          ],
          "text": "Similarly, we call the longest SAP between the two edges the longest path with a\nmass $M_{\\max}$ . Again, we assume that the mass has a scaling form, $M_{\\max} \\propto L^{D_{\\max}}$ . We\nnotice that $M_{min} \\leq M_{max}$ . Consequently, a similar relation holds for the exponents\n$D_{\\min} \\leq D_{\\max}$ .",
          "reading_order": 10
        },
        {
          "label": "para",
          "bbox": [
            72,
            696,
            520,
            757
          ],
          "text": "We also introduce the term the average path , meaning the average mass (length)\nof all possible SAPs going between opposite sides of the system, $\\langle M_{SAP} \\rangle \\propto L^{D_{SAP}}$ .\nThe dimension $D_{SAP}$ will lie between the dimensions of the minimal and the\nmaximal path.",
          "reading_order": 11
        }
      ]
    },
    {
      "page_number": 130,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            58
          ],
          "text": "122",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            419,
            44,
            512,
            62
          ],
          "text": "8 Subset Geometric",
          "reading_order": 1
        },
        {
          "label": "sec",
          "bbox": [
            72,
            80,
            138,
            94
          ],
          "text": "Backbone",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            116,
            520,
            226
          ],
          "text": "Intersection of All Self-Avoiding Paths The notion of SAPs can also be used\nto address the physical properties of the cluster, such as we saw for the singly\nconnected bonds. The set of singly connected bonds is the set of intersections\nbetween all SAPs connecting the two sides. That is, the singly connected bonds\nis the set of points that any path must go through in order to connect the two sides.\nFrom this definition, we notice that the dimension $D_{SC}<D_\\text{min}$ , and as we will see\nfurther on, $D_{SC}=1/v$ which is smaller than 1 for two-dimensional systems.",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            241,
            520,
            290
          ],
          "text": "Another of All Self-Avoiding Paths Another useful set is the union of all SAPs that\nconnect the two edges of the cluster. This set is called the backbone with dimension\n$D_B$ .",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            88,
            322,
            502,
            358
          ],
          "text": "Backbone The backbone is the union of all self-avoiding paths on the\nspanning cluster that connect two opposite edges.",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            394,
            520,
            540
          ],
          "text": "This set has a simple physical interpretation for a random porous material, since it\ncorresponds to the sites that are accessible to fluid flow if a pressure is applied across\nthe material. The remaining sites are called dangling ends . The backbone are all the\nsites that have at least two different paths leading into them, one path from each side\nof the cluster. The remaining sites only have one (self-avoiding) path leading into\nthem, and we call this set of sites the dangling ends. The spanning cluster consists\nof the backbone plus the dangling ends, as illustrated in Fig. 8.2 . The dangling ends\nare therefore pieces of the cluster that can be cut away by the removal of a single\nbond.",
          "reading_order": 6
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_130_figure_007.png)",
          "figure_path": "figures/percolation_studies_page_130_figure_007.png",
          "bbox": [
            72,
            564,
            515,
            716
          ],
          "reading_order": 7
        },
        {
          "label": "cap",
          "bbox": [
            72,
            725,
            511,
            756
          ],
          "text": "Fig. 8.2 Illustration of the spanning cluster consisting of the backbone (red) and the dangling end\n(blue) for a $512\\times512$ site percolation system for (a) $p=0.58$ , (b) $p=0.59$ , and (c) $p=0.61$",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 131,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            253,
            62
          ],
          "text": "8.2 Self-Avoiding Paths on the Cluster",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            512,
            58
          ],
          "text": "12",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            143
          ],
          "text": "We have arrived at the following hierarchy of exponents describing various\nsubsets of paths through the cluster:\n\\[D_{SC} \\leq D_{\\min} \\leq D_{SAP} \\leq D_{\\max} \\leq D_B \\leq D \\leq d~,\\addtocounter{equation}{1}\\tag{\\theequation}\\label{equ:f2-defnocurf3}\\]",
          "reading_order": 2
        },
        {
          "label": "sec",
          "bbox": [
            72,
            178,
            260,
            197
          ],
          "text": "Scaling of the Dangling Ends",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            212,
            520,
            273
          ],
          "text": "Generally, we will find that the dimension of the backbone, $D_B$ , is smaller than the\ndimension of the spanning cluster. For example, in two dimensions, we find that\n$D_B\\simeq1.6$ , whereas $D\\simeq1.89$ . This has implications for the relative size of the\nbackbone and the dangling ends.",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            277,
            520,
            474
          ],
          "text": "The spanning cluster consists of the backbone and the dangling ends. Therefore,\nthe mass of the spanning cluster, $M$ , must equal the sum of the masses of the\nbackbone and the dangling ends $M=M_B+M_{DE}$ . Since we know that $M\\propto L^D$\nand $M_B\\propto L^{D_B}$ , we find that\n$$M_{DE}=M-M_B=M_0L^D-M_{0,B}L^{D_B}~,\\eqno(8.5)$$\nwhere $M_0$ and $M_{0,B}$ are constant prefactors. To see what happens when $L\\rightarrow\\infty$ ,\nwe divide by $M$ :\n$$\\frac{M_{DE}}{M}=1-\\frac{M_{0,B}L^{D_B}}{M_0L^D}=1-cL^{D_B-D}~,\\eqno(8.6)$$",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            483,
            520,
            564
          ],
          "text": "Since $D_B\\leq D$ , we see that the fraction $M_{DE}/M$ goes to a constant (one) as $L$\napproaches infinity. Consequently, we have found that $M_{DE}\\propto M\\propto L^D$ . This also\nimplies that as the system size goes to infinity most of the mass is in the dangling\nends. This means that the backbone occupies a smaller and smaller portion of the\ntotal mass of the system as the system size increases.",
          "reading_order": 6
        },
        {
          "label": "sec",
          "bbox": [
            72,
            596,
            308,
            611
          ],
          "text": "Argument for the Scaling of Subsets",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            627,
            520,
            756
          ],
          "text": "We can provide a better argument for why the various subsets should scale with the\nsystem size $L$ to various exponents. We notice that the following relation between\nthe masses must be true:\n\\[ L^1 \\leq M_{\\min} \\leq M_{SAP} \\leq M_{\\max} \\leq M_{BB} \\leq M \\leq L^d~, \\tag*{8.7}\\]\nwhere the first inequality $L^1 \\leq M_{\\min}$ follows because even the minimum path must\nbe at least of length $L$ to go from one side to the opposite side.",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            72,
            756,
            520,
            788
          ],
          "text": "Now, if this is to be true for all values of $L$ , it can be argued that because all\nthe masses are between two scaling relations, $L^1$ and $L^d$ , also the scaling of the",
          "reading_order": 9
        }
      ]
    },
    {
      "page_number": 132,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            58
          ],
          "text": "124",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            419,
            44,
            520,
            62
          ],
          "text": "8 Subset Geometry",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            116
          ],
          "text": "intermediate masses, $M_x$ , must be power-laws with some power-law exponents,\n$M_x\\propto L^{D_x}$ , with the hierarchy of exponents given in ( 8.4 ) .",
          "reading_order": 2
        },
        {
          "label": "sec",
          "bbox": [
            72,
            143,
            304,
            161
          ],
          "text": "Blob Model for the Spanning Cluste",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            179,
            520,
            290
          ],
          "text": "Let us now try to formulate our geometric description of the spanning cluster into a\nmodel of the spanning cluster [ 36 ] . We have found that the spanning cluster can be\nsubdivided first into two parts: the backbone and the dangling ends. The backbone\nmay again be divided into two parts: a set of blobs where the are several parallel\npaths and a set of sites, the singly connected sites, that connect the blobs to each\nother and the blobs to the dangling ends. Thus, we have ended up with a model with\nthree components:",
          "reading_order": 4
        },
        {
          "label": "list",
          "bbox": [
            88,
            304,
            182,
            322
          ],
          "text": "the dangling ends",
          "reading_order": 5
        },
        {
          "label": "list",
          "bbox": [
            88,
            322,
            361,
            340
          ],
          "text": "a set of blobs where there are several parallel paths",
          "reading_order": 6
        },
        {
          "label": "list",
          "bbox": [
            88,
            340,
            520,
            367
          ],
          "text": "the singly connected points, connecting the blobs to each other and the blobs to\nthe dangling ends.",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            385,
            520,
            467
          ],
          "text": "Each of the blobs and the dangling ends will again have a similar substructure of\ndangling ends, blobs with parallel paths, and singly connected bonds as illustrated\nin Fig. 8.3 . This cartoon image of the clusters provides very useful intuition about\nthe geometrical structure of percolation clusters, which we will use when we address\nthe physics of disordered systems in the next chapters.",
          "reading_order": 8
        },
        {
          "label": "sec",
          "bbox": [
            72,
            500,
            475,
            519
          ],
          "text": "Mass-Scaling Exponents for Subsets of the Spanning Clusters",
          "reading_order": 9
        },
        {
          "label": "para",
          "bbox": [
            72,
            535,
            520,
            600
          ],
          "text": "The exponents can be calculated either by numerical simulations, where the masses\nof the various subsets are measured as a function of system size at $p=p_c$ , or by the\nrenormalization group method. Numerical results based on computer simulations\nusing the code provided in this book are listed in Table 8.1 . You can find up-to-date",
          "reading_order": 10
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_132_figure_011.png)",
          "figure_path": "figures/percolation_studies_page_132_figure_011.png",
          "bbox": [
            224,
            627,
            520,
            779
          ],
          "reading_order": 11
        },
        {
          "label": "cap",
          "bbox": [
            72,
            627,
            207,
            707
          ],
          "text": "Fig. 8.3 Illustration of the\nhierarchical blob-model for\nthe percolation cluster\nshowing the backbone (bold),\nsingly connected bonds (red)\nand blobs (blue)",
          "reading_order": 12
        }
      ]
    },
    {
      "page_number": 133,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            233,
            62
          ],
          "text": "8.3 Renormalization Calculation",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            520,
            58
          ],
          "text": "125",
          "reading_order": 1
        },
        {
          "label": "tab",
          "bbox": [
            72,
            98,
            520,
            134
          ],
          "text": "<table><tr><td>d</td><td>D SC</td><td>D min</td><td>D max</td><td>D B</td><td>D</td><td>D DE</td></tr><tr><td>2</td><td>0.75</td><td>1.1</td><td>1.5</td><td>1.6</td><td>1.89</td><td>1.89</td></tr></table>",
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            80,
            457,
            98
          ],
          "text": "Table 8.1 A list of known exponent for the various subset types in two dimensions",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            170,
            520,
            200
          ],
          "text": "results for exponents in the percolation system at the Wikipedia page: https://en.\nwikipedia.org/wiki/Percolation_critical_exponents .",
          "reading_order": 4
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            232,
            314,
            250
          ],
          "text": "8.3 Renormalization Calculation",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            267,
            520,
            361
          ],
          "text": "We will now use the renormalization group approach to address the scaling exponent\nfor various subsets of the spanning cluster at $p=p_c$ . For this, we will here\nuse the renormalization procedure for bond percolation on a square lattice in\ntwo dimensions following Hong and Stanley [ 17 ] , where we have found that the\nrenormalization procedure produces the exact result for the percolation threshold,\n$p_c=p^*=1/2$ , which is a fixpoint of the mapping.",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            361,
            528,
            555
          ],
          "text": "Our strategy will be to assume that all the bonds have a mass $M=1$ in the\noriginal lattice, and then find the mass $M'$ in the renormalized lattice, when the\nlength has been rescaled by $b$ . For a property that displays a self-similar scaling, we\nwill expect that\n$$ M'\\propto b^{D_x}M~, \\eqno(8.8)$$\nwhere $D_x$ denotes the dimension for the particular subset we are looking at. We can\nuse this to determine the fractal exponent $D_x$ from\n$$ D_x=\\frac{\\ln M'/M}{\\ln b}~. \\eqno(8.9)$$",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            564,
            520,
            680
          ],
          "text": "We will do this by calculating the average value of the mass of the H-cell, by\ntaking the mass of the subset we are interested in for each configuration, $M_x(c)$ ,\nand multiplying it by the probability of that configuration, summing over all\nconfigurations:\n\\[\n    \\langle M \\rangle = \\sum_{c} M_x(c) P(c)~. \\eqno(8.10)\n  \\]",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            72,
            696,
            520,
            806
          ],
          "text": "We have now calculated the average mass in the original 2 by 2 lattice, and this\nshould correspond to the average renormalized mass, $\\langle M^{\\prime}\\rangle=p^{\\prime}M^{\\prime}$ , which is the\nmass of the renormalized bond, $M^{\\prime}$ multiplied with the probability for that bond to\nbe present $p^{\\prime}$ . That is, we will find $M^{\\prime}$ from:\n$$\np^{\\prime}M^{\\prime}=\\sum_{c} M(c) P(c),\n$$",
          "reading_order": 9
        }
      ]
    },
    {
      "page_number": 134,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            58
          ],
          "text": "126",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            419,
            44,
            520,
            62
          ],
          "text": "8 Subset Geometry",
          "reading_order": 1
        },
        {
          "label": "tab",
          "bbox": [
            107,
            141,
            475,
            403
          ],
          "text": "<table><tr><td>c</td><td>P( c )</td><td>MSC</td><td>L min</td><td>L AVG</td><td>L max</td><td>M BB</td><td>M</td></tr><tr><td>1</td><td>p5  (1 − p )0</td><td>0</td><td>2</td><td>2.5</td><td>3</td><td>5</td><td>5</td></tr><tr><td>2</td><td>p4  (1 − p )1</td><td>0</td><td>2</td><td>2</td><td>2</td><td>4</td><td>4</td></tr><tr><td>3</td><td>4 p4  (1 − p )1</td><td>1</td><td>2</td><td>2.5</td><td>3</td><td>4</td><td>4</td></tr><tr><td>4</td><td>2 p3  (1 − p )2</td><td>2</td><td>2</td><td>2</td><td>2</td><td>2</td><td>3</td></tr><tr><td>5</td><td>2 p3  (1 − p )2</td><td>3</td><td>3</td><td>3</td><td>3</td><td>3</td><td>3</td></tr><tr><td>6</td><td>4 p3  (1 − p )2</td><td>2</td><td>2</td><td>2</td><td>2</td><td>2</td><td>3</td></tr><tr><td>7</td><td>2 p2  (1 − p )3</td><td>2</td><td>2</td><td>2</td><td>2</td><td>2</td><td>2</td></tr><tr><td>{ M x }</td><td></td><td>26/2 5</td><td>34/2 5</td><td>36.5/2 5</td><td>39/2 5</td><td>47/2 5</td><td>53/2 5</td></tr><tr><td>D x</td><td></td><td>In 13 N In2</td><td>In 17 N In2</td><td>In 18 S In2</td><td>In 19 I n 2</td><td>In 17 In 2</td><td>In 15 S In2</td></tr><tr><td>D x</td><td></td><td>0.7004</td><td>1.0875</td><td>1.1898</td><td>1.2854</td><td>1.5546</td><td>1.7279</td></tr><tr><td>D x,n</td><td></td><td>3/4</td><td>1.13</td><td></td><td>1.4</td><td>1.6</td><td>91/48</td></tr></table>",
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            80,
            520,
            135
          ],
          "text": "Table 8.2 Numerical exponents for the exponent describing various subsets of the spanning\ncluster defined using the set of Self-Avoiding Walks going from one side to the opposite side of the\ncluster. The last line shows the exponents found from numerical simulations in a two-dimensional\nsystem",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            439,
            520,
            487
          ],
          "text": "We will study our system at the nontrivial fixpoint $p=p^*=1/2=p_c$ . The\nspanning configurations $c$ for bond renormalization in two dimensions, are shown\ntogether with their probabilities and the masses of various subsets in Table 8.2 .",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            487,
            520,
            537
          ],
          "text": "This use of the renormalization group method to estimate the exponents demon-\nstrates the power of the renormalization arguments. Similar arguments will be used\nto address other properties of the percolation system.",
          "reading_order": 5
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            564,
            316,
            582
          ],
          "text": "8.4 Deterministic Fractal Models",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            600,
            520,
            761
          ],
          "text": "We have found that we can calculate the behavior of infinite-dimensional and one-\ndimensional systems exactly. However, for finite dimensions such as for $d=2$ or\n$d=3$ we must rely on numerical simulations and renormalization group arguments\nto determine the exponents and the behavior of the system. However, in order to\nlearn about physical properties in systems with scaling behavior, we may be able\nto construct simpler models that contain many of the important features of the\npercolation cluster. For example, we may be able to introduce deterministic, iterative\nfractal structures that reproduce many of the important properties of the percolation\ncluster at $p=p_c$ , but that are deterministic systems. The idea is that we can use\nsuch a system to study other properties of the physics on fractal structures.",
          "reading_order": 7
        }
      ]
    },
    {
      "page_number": 135,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            233,
            62
          ],
          "text": "8.4 Deterministic Fractal Models",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            520,
            58
          ],
          "text": "127",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_135_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_135_figure_002.png",
          "bbox": [
            125,
            80,
            457,
            241
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            250,
            520,
            288
          ],
          "text": "Fig. 8.4 Illustration of first three generations of the Mandelbrot-Given curve. The length is scaled\nby a factor $b=3$ for each iteration, and the mass of the whole structure is increased by a factor of\n8. The fractal dimension is therefore $D=\\ln 8/\\ln 3 \\simeq 1.89$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            313,
            520,
            483
          ],
          "text": "Mandelbrot-Given Curve An example of an iterative fractal structure that\nhas many of the important features of the percolation clusters at $p=p_c$ is\nthe Mandelbrot-Given curve. The curve is generated by the iterative procedure\ndescribed in Fig. 8.4 . Through each generation, the length is rescaled by a factor\n$b=3$ , and the mass is rescaled by a factor $8$ . That is, for generation $l$ , the mass is\n$m(l)=8^{l}$ , and the linear size of the cluster is $L(l)=3^{l}$ . If we assume a scaling on\nthe form $m=L^D$ , we find that\n\\[\nD=\\frac{\\ln 8}{\\ln 3}\\simeq1.89~.\n\\eqno(8.12)\n\\]",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            491,
            520,
            537
          ],
          "text": "This is surprisingly similar to the fractal dimension of the percolation cluster. We\ncan also look at other dimensions, such as for the singly connected bonds, the\nminimum path, the maximum path and the backbone.",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            555,
            520,
            730
          ],
          "text": "Single Connected Bonds Let us first address the singly connected bonds. In the\nzero'th generation, the system is simply a single bond, and the length of the singly\nconnected bonds, $L_{SC}$ is 1. In the first generation, there are two bonds that are\nsingly connecting, and in the second generation there are four bonds that are singly\nconnecting. The general relation is that\n$$L_{SC}=2^l\\;,\\eqno(8.13)$$\nwhere $l$ is the generation of the structure. The dimension, $D_{SC}$ , of the singly\nconnected bonds is therefore $D_{SC}=\\ln 2/\\ln 3\\simeq0.63$ , which should be compared\nwith the exact value $D_{SC}=3/4$ for two-dimensional percolation.",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            743,
            520,
            809
          ],
          "text": "Minimum Path The minimum path will for all generations be the path going\nstraight through the structure, and the length of the minimal path will therefore\nbe equal to the length of the structure. The scaling dimension $D_{min}$ is therefore\n$D_{min}=1$ .",
          "reading_order": 7
        }
      ]
    },
    {
      "page_number": 136,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            58
          ],
          "text": "128",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            419,
            44,
            512,
            62
          ],
          "text": "8 Subset Geometric",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            112
          ],
          "text": "Maximum Path The maximum path increases by a factor 5 for each iteration. The\ndimension of the maximum path is therefore Dmax = ln 5/ln 3 ≃ 1.465.",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            125,
            520,
            179
          ],
          "text": "Backbone We can similarly find that the mass of the backbone increases by a\nfactor $D_B=\\ln6/\\ln3\\simeq1.631$ 6 for each iteration, and the dimension of the backbone is therefore .",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            196,
            520,
            259
          ],
          "text": "Model System This deterministic iterative fractal can be used to perform quick\ncalculations of various properties on a fractal system, and may also serve as a useful\nhierarchical lattice on which to perform simulations when we are studying processes\noccurring on a fractal structure.",
          "reading_order": 4
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            286,
            197,
            306
          ],
          "text": "8.5 Lacunarity",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            322,
            520,
            467
          ],
          "text": "The fractal dimension describes the scaling properties of structures such as the\npercolation cluster at $p=p_c$ . However, structures that have the same fractal\ndimension, may have a very different appearance. As an example, let us study\nseveral variations of the Sierpinski gasket introduced in Sect. 5.3 . As illustrated in\nFig. 8.5 , we can construct several rules for the iterative generation of the fractal\nthat all result in the same fractal dimension, but have different visual appearance.\nThe fractal dimension $D=\\ln{3}/\\ln{2}$ for both of the examples in Fig. 8.5 , but by\nincreasing the number of triangles that are used in each generation, the structures\nbecome more homogeneous. How can we quantify this difference?",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            483,
            518,
            515
          ],
          "text": "Distribution of Mass In order to quantify this difference, Mandelbrot invented\nthe concept of lacunarity . We measure lacunarity from the distribution of mass-",
          "reading_order": 7
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_136_figure_008.png)",
          "figure_path": "figures/percolation_studies_page_136_figure_008.png",
          "bbox": [
            107,
            537,
            475,
            707
          ],
          "reading_order": 8
        },
        {
          "label": "cap",
          "bbox": [
            72,
            716,
            518,
            797
          ],
          "text": "Fig. 8.5 Two versions of the Siepinski gasket. In version 1, the next generation is made from 3\nof the structures from the last generation, and the spatial rescaling is by a factor $b=3$ . In version\n2, the next generation is made from 9 of the structures from the last generation, and the spatial\nrescaling $D_2=\\ln{9}/\\ln{4}=\\ln{3^2}/\\ln{2^2}=\\ln{3}/\\ln{2}=D_1$ is by a factor $b=6$ . The resulting fractal dimension is . The two structures therefore have the same fractal dimension. However, version 1\nhave large fluctuations that version 2",
          "reading_order": 9
        }
      ]
    },
    {
      "page_number": 137,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            146,
            62
          ],
          "text": "8.5 Lacunarity",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            520,
            58
          ],
          "text": "129",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            179
          ],
          "text": "sizes. We can characterize and measure the fractal dimension of a fractal structure\nusing box-counting, as explained in Sect. 5.3 . The structure, such as the percolation\ncluster, is divided into boxes of size $\\ell$ . In each box, $i$ , there will be a mass $m_{i}(\\ell)$ .\nThe fractal dimension is found by calculating the average mass per box of size $\\ell$ :\n$$\\langle m_{i}(\\ell)\\rangle_{i}=A\\ell^{D}~.\\eqno(8.14)$$",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            196,
            520,
            322
          ],
          "text": "However, there will variations in the masses $m(\\ell)$ in the boxes, characterized by a\ndistribution $P(m,\\,\\ell)$ , which gives the probability for mass $m$ in a box of size $\\ell$ . We\ncan characterize this distribution by its moments:\n$$\\langle m^k(\\ell)\\rangle=A_k\\ell^{kD}~,\\eqno(8.15)$$\nwhere this particular scaling form implies that the structure is unifractal: the scaling\nexponents for all the moments are linearly related.",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            340,
            520,
            627
          ],
          "text": "Unifractal Scaling For a unifractal structure, we expect the distribution of masses\nto have the scaling form\n\\[P(m, \\ell)=\\ell^x f(\\frac{m}{\\ell^D})~,\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:scaling_exponent_kernel}\\]\nwhere the scaling exponent $x$ is yet undetermined. In this case, the moments can be\nfound by integration over the probability density\n\\[\\begin{split}\n    \\langle m^k\\rangle&=\\int P(m, \\ell)m^k\\,\\mathrm{d}m\\\\\n    &=\\int m^k\\ell^x f(\\frac{m}{\\ell^D})\\,\\mathrm{d}m\\\\\n    &=\\ell^{(kD+x+D}\\int (\\frac{m}{\\ell^D})^kf(\\frac{m}{\\ell^D})\\,\\mathrm{d}(\\frac{m}{\\ell^D})\\\\\n    &=\\ell^{D(k+1)+x}\\int x^k f(x)\\,\\mathrm{d}x\n\\end{split}\\]",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            636,
            520,
            743
          ],
          "text": "We can determine the unknown scaling exponent $x$ from the scaling of the zero'th\nmoment, that is, from the normalization of the probability density: $\\langle m^0 \\rangle=1$ implies\nthat $D(0+1)+x=0$ , and therefore, that $x=-D$ . The scaling ansatz for the\ndistribution of masses is therefore\n$$P(m,\\,\\ell)=\\ell^{-D}f(\\frac{m}{\\ell^D})\\;.\\eqno(8.21)$$",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            752,
            520,
            815
          ],
          "text": "And we found that the moments can be written as\n\\[ \\langle m^{k}\\rangle=\\ell^{D(k+1)-D}\\int x^{k}f(x)dx=A_{k}\\ell^{kD}~,\\qquad\\qquad\\qquad(8.22)",
          "reading_order": 6
        }
      ]
    },
    {
      "page_number": 138,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            58
          ],
          "text": "130",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            412,
            44,
            520,
            62
          ],
          "text": "8 Subset Geometry",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            128
          ],
          "text": "as we assumed above. Consequently, the distribution of masses is characterized by\nthe distribution $P(m,\\,\\ell)$ , which in turn is described by the fractal dimension, $D$ , and\nthe scaling function $f(u)$ , which gives the shape of the distribution.",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            143,
            520,
            268
          ],
          "text": "Properties of the Distribution of Masses The distribution of masses can be broad,\nwhich would correspond to “ large holes\", or narrow, which would correspond\nto a more uniform distribution of mass. The width of the distribution can be\ncharacterized by the mean-square deviation of the mass from the average mass:\n\\[\n    \\Delta=\\frac{\\langle m^2\\rangle-\\langle m\\rangle^2}{\\langle m\\rangle^2}=\\frac{A_2-A_1^2}{A_1^2}~.\n\\]",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            277,
            520,
            341
          ],
          "text": "This number describes another part of the mass distribution relation than the scaling\nrelation, and can be used to characterize fractal set. For the percolation problem,\nthis number is assumed to be universal, independent of lattice type, but dependent\non the embedding dimensionality of the system.",
          "reading_order": 4
        },
        {
          "label": "sec",
          "bbox": [
            72,
            374,
            135,
            386
          ],
          "text": "Exercises",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            403,
            520,
            439
          ],
          "text": "Exercise 8.1 (Singly Connected Bonds) Use the example programs from the text\nto find the singly connected bonds.",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            456,
            520,
            501
          ],
          "text": "(a) Run the programs to visualize the singly connected bonds. Can you understand\nhow this algorithms finds the singly connected bonds? Why are some of the\nbonds of a different color?",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            71,
            501,
            520,
            550
          ],
          "text": "(b) Find the mass, $M_{SC}$ , of the singly connected bonds as a function of system size\n$L$ for $p=p_c$ and use this to estimate the exponent $D_{SC}$ : $M_{SC}\\propto L^{D_{SC}}$ .\n(c) Can you find the behavior of $P_{SC}=M_{SC}/L^d$ as a function of $p-p_c$ ?",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            72,
            550,
            475,
            555
          ],
          "text": "↑\n. www.serv.org. [2019-07-30]. (原始内容存档于2019-08-15).",
          "reading_order": 9
        },
        {
          "label": "para",
          "bbox": [
            72,
            564,
            520,
            744
          ],
          "text": "Exercise 8.2 (Left/Right-Turning Walker) We have provided a subroutine and\nan example program that implements the left/right-turning walker algorithm. The\nalgorithm works on a given clusters. From one end of the cluster, two walkers are\nstarted. The walkers can only walk according to the connectivity rules on the lattice.\nThat is, for a nearest-neighbor lattice, they can only walk to their nearest neighbors.\nThe left-turning walker always tries to turn left from its previous direction. If this\nsite is empty, it tries the next-best site, which is to continue straight ahead. If that is\nempty, it tries to move right, and if that is empty, it moves back along the direction\nit came. The right-turning walker follows a similar rule, but prefers to turn right in\neach step. The first walker to reach the other end of the cluster stops, and the other\nwalker stops when it reaches this site.",
          "reading_order": 10
        },
        {
          "label": "para",
          "bbox": [
            72,
            744,
            520,
            797
          ],
          "text": "The path of the two walkers is illustrated in the Fig. 8.6 . The sites that are visited\nby both walkers constitute the singly connected bonds. The union of the two walks\nconstitutes what is called the external perimeter (Hull) of the cluster.",
          "reading_order": 11
        }
      ]
    },
    {
      "page_number": 139,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            108,
            58
          ],
          "text": "Exercise",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            511,
            58
          ],
          "text": "13",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_139_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_139_figure_002.png",
          "bbox": [
            251,
            80,
            520,
            270
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            80,
            200,
            107
          ],
          "text": "Fig. 8.6 Illustrations of the\nleft-right turning walker",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            295,
            520,
            349
          ],
          "text": "(a) Use the following programs to generate and illustrate of the singly connected\nbonds for a 100 $\\times$ 100 system. Check that the illustrated bonds correspond to\nthe singly connected bonds.",
          "reading_order": 4
        },
        {
          "label": "code",
          "bbox": [
            80,
            376,
            202,
            403
          ],
          "text": "import numpy as np\nimport numba",
          "reading_order": 5
        },
        {
          "label": "code",
          "bbox": [
            80,
            412,
            494,
            806
          ],
          "text": "@numba.njit(cache=True)\ndef walk(z):\n# Left turning walker\n# Returns left: nr of times walker passes a site\n# First, ensure that array only has one contact point at\n#\nleft and right : topmost points chosen\nnx = z.shape[0]\nny = z.shape[1]\ni = np.where(z[0,:] > 0)\nix0 = 0 # starting row for walker is always 0\niy0 = i[0][0] # starting column (first element where\n#\nthere is a matching column which is zero)\n# First do left-turning walker\ndirections = np.zeros((4,2))\ndirections [0,0] = -1 # west\ndirections [0,1] = 0\ndirections [1,0] = 0 # south\ndirections [1,1] = -1\ndirections [2,0] = 1 # east\ndirections [2,1] = 0\ndirections [3,0] = 0 # north\ndirections [3,1] = 1\nnwalk = 1\nix = ix0\niy = iy0\ndirection = 0 # 0 = west, 1 = south, 2 = east, 3 = north\nleft = np.zeros((nx,ny))\nright = np.zeros((nx,ny))\nwhile (nwalk >0):",
          "reading_order": 6
        }
      ]
    },
    {
      "page_number": 140,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            58
          ],
          "text": "132",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            412,
            44,
            520,
            62
          ],
          "text": "8 Subset Geometry",
          "reading_order": 1
        },
        {
          "label": "code",
          "bbox": [
            106,
            80,
            511,
            792
          ],
          "text": "left[ix,iy] = left[ix,iy] + 1\n# Turn left until you find an occupied site\nnfound = 0\nwhile (nfound==0):\ndirection = direction - 1\nif (direction < 0):\ndirection = direction + 4\n# Check this direction\niix = ix + int(directions[direction,0])\niiy = iy + int(directions[direction,1])\nif (iix >> nx):\nnwalk = 0 # Walker escaped\nnfound = 1\niix = nx\nix1 = ix\niy1 = iy\n# Is there a site here?\nelif(iix >> 0):\nif(iiy >> 0):\nif (iiy < ny):\nif (z[iix,iiy]>0): # site present\nix = iix\niy = iiy\nnfound = 1\ndirection = direction + 2\nif (direction > 3):\ndirection = direction - 4\n##left\nnwalk = 1\nix = ix0\niy = iyo\ndirection = 1 # l=left, 2 = down, 3 = right, 4 = up\nwhile(nwalk >0):\nright[ix,iy] = right[ix,iy] + 1\n# ix,iy\n# Turn right until you find an occupied site\nnfound = 0\nwhile (nfound==0):\ndirection = direction + 1\nif (direction > 3):\ndirection = direction - 4\n# Check this directionection\niix = ix + int(directions[direction,0])\niiy = iy + int(directions[direction,1])\nif (iix >> nx):\nif (iy >> = iy1):\nnwalk = 0 # Walker escaped\nnfound = 1\niix = nx\n# Is there a site here?\nelif(iix >> 0):\nif(iiy >> 0):",
          "reading_order": 2
        }
      ]
    },
    {
      "page_number": 141,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            108,
            58
          ],
          "text": "Exercise",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            520,
            58
          ],
          "text": "133",
          "reading_order": 1
        },
        {
          "label": "code",
          "bbox": [
            107,
            80,
            495,
            202
          ],
          "text": "if (iix < nx):\nif (z[iix,iiy]>0): # site present\nix = iix\niy = iiy\nnfound = 1\ndirection = direction - 2\nif (direction <0):\ndirection = direction + 4\n\nreturn left, right",
          "reading_order": 2
        },
        {
          "label": "code",
          "bbox": [
            79,
            224,
            493,
            450
          ],
          "text": "from scipy.ndimage import measurements\n# Generate spanning cluster (l-r spanning)\nlx = 200\nly = 200\np = 0.595\nncount = 0\nperc = []\nwhile (len(perc)==0):\nncount = ncount + 1\nif (ncount >1000):\nprint(\"Couldn’t make percolation cluster...\")\nbreak\nz=np.random.rand(lx,ly)<p\nlw,num = measurements.label(z)\nperc_x = np.intersect1d(lw[0,:],lw[-1,:]) # Percolating?\nperc = perc_x[np.where(perc_x > 0)]\nprint(\"ncount = \",ncount)",
          "reading_order": 3
        },
        {
          "label": "code",
          "bbox": [
            80,
            465,
            511,
            707
          ],
          "text": "import matplotlib.pyplot as plt\nif len(perc) > 0:\nzz = (lw == perc[0])\n# zz now contains the spanning cluster\nplt.figure(figsize={15,8}) # Display spanning cluster\nplt.subplot(2,3,1)\nplt.imshow(zz, interpolation='nearest', origin='lower')\nl,r = walk(zz)\nplt.subplot(2,3,2)\nplt.imshow(l, interpolation='nearest', origin='lower')\nplt.subplot(2,3,3)\nplt.imshow(r, interpolation='nearest', origin='lower')\nplt.subplot(2,3,4)\nzzz = l*r # Find points where both l and r are non-zero\nplt.imshow(zzz, interpolation='nearest', origin='lower')\nplt.subplot(2,3,5)\nzadd = zz + zzz\nplt.imshow(zadd, interpolation='nearest', origin='lower')",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            733,
            251,
            745
          ],
          "text": "(b) Measure the dimension $D_{SC}$ .",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            745,
            520,
            779
          ],
          "text": "(c) Modify the programs to find the external perimeter (Hull) of a spanning cluster\nin a 100 × 100 system.",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            779,
            331,
            797
          ],
          "text": "(d) Measure the dimension $D_P$ of the perimeter",
          "reading_order": 7
        }
      ]
    },
    {
      "page_number": 142,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            58
          ],
          "text": "134",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            412,
            44,
            520,
            62
          ],
          "text": "8 Subset Geometry",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            128
          ],
          "text": "(e) (Advanced) Develop a theory for the behavior of $P_H(p,L)$ , the probability for\na site to belong to the Hull as a function of $p$ and $L$ for $p>p_c$ .\n(f) (Advanced) Measure the behavior of $P_H(p,L)$ as a function of $p$ for $L=10^{-2}\\times 10^{-3}$",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            128,
            518,
            143
          ],
          "text": "$512\\times512$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            636,
            520,
            701
          ],
          "text": "Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0\nInternational License ( http://creativecommons.org/licenses/by/4.0/ ), which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as long as you give appropriate\ncredit to the original author(s) and the source, provide a link to the Creative Commons license and\nindicate if changes were made.",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            701,
            520,
            770
          ],
          "text": "The images or other third party material in this chapter are included in the chapter’s Creative\nCommons license, unless indicated otherwise in a credit line to the material. If material is not\nincluded in the chapter’s Creative Commons license and your intended use is not permitted by\nstatutory regulation or exceeds the permitted use, you will need to obtain permission directly from\nthe copyright holder.",
          "reading_order": 5
        }
      ]
    },
    {
      "page_number": 143,
      "elements": [
        {
          "label": "title",
          "bbox": [
            72,
            98,
            313,
            116
          ],
          "text": "Flow in Disordered Media",
          "reading_order": 0
        },
        {
          "label": "para",
          "bbox": [
            528,
            107,
            546,
            134
          ],
          "text": "9",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            304,
            520,
            421
          ],
          "text": "In this chapter, we introduce the basic concepts of disordered media. We introduce\nproperties of flow of current or fluids, and then address flow in a percolating system\nclose to $p_c$ . We will study the behavior numerically, develop a scaling theory, and\nfind properties using the renormalization group approach. Our initial studies will\nbe on the binary porous medium of the percolation system. However, we can also\nextend our results to more general random media, and we demonstrate how this can\nbe done towards the end of the chapter.",
          "reading_order": 2
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            448,
            287,
            465
          ],
          "text": "9.1 Introduction to Disorder",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            483,
            520,
            548
          ],
          "text": "We have now developed the tools to address the statistical properties of the geometry\nof a disordered system such as a model porous medium: the percolation system. In\nthe following chapters, we will apply this knowledge to address physical properties\nof disordered systems and to study physical processes in disordered materials.",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            548,
            520,
            725
          ],
          "text": "We have learned that the geometry of a disordered system displays fractal scaling\nclose to the percolation threshold. Material properties such as the density of singly\nconnected sites, or the backbone of the percolation cluster, display self-similar\nscaling. The backbone is the part of the spanning cluster that participates in fluid\nflow. The mass, $M_B$ , of the backbone scales with the system size, $L$ , according to\nthe scaling relation $M_B=L^{D_B}$ , where $D_B$ is smaller than the Euclidean dimension.\nThe density of the backbone therefore decreases with system size. This implies that\nmaterial properties which we ordinarily would treat as material constants, depend on\nthe size of the sample. In this part we will develop an understanding of the origin of\nthis behavior, and show how we can use the tools from percolation theory to address\nthe behavior in such systems.",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            725,
            520,
            774
          ],
          "text": "The behavior of a disordered system can in principle always be addressed by\ndirect numerical simulation. For example, for incompressible, single-phase fluid\nflow through a porous material, the effective permeability of a sample can be found",
          "reading_order": 6
        },
        {
          "label": "foot",
          "bbox": [
            72,
            806,
            396,
            845
          ],
          "text": "© The Author(s) 2024\nA. Malthe-Sørenssen, Percolation Theory Using Python, Lecture Notes\nin Physics 1029, https://doi.org/10.1007/978-3-031-59900-2_9",
          "reading_order": 7
        },
        {
          "label": "foot",
          "bbox": [
            501,
            806,
            520,
            816
          ],
          "text": "135",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 144,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            58
          ],
          "text": "136",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            376,
            44,
            520,
            58
          ],
          "text": "9 Flow in Disordered Media",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            179
          ],
          "text": "to very good accuracy from a detailed numerical model of fluid flow through the\nsystem. However, it is not practical to model fluid flow down to the smallest scale\nin more applied problems. We would therefore need to extrapolate from the small\nscale to the large scaling. This process, often referred to as up-scaling, requires that\nwe know the scaling properties of our system. We will address up-scaling in detail\nin the following chapters.",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            179,
            520,
            370
          ],
          "text": "We may argue that a system at the percolation threshold is anomalous and that\nany realistic system, such as a geological system, would be far away from the\npercolation threshold. In this case, the system will only display an anomalous, size-\ndependent behavior up to the correlation length, and over larger lengths the behavior\nwill be that of a homogeneous material. We should, however, be aware that many\nphysical properties are described by broad distributions of material properties, and\nthis will lead to a behavior similar to the behavior close to the percolation threshold,\nas we will discuss in detail in this part. In addition, several physical processes ensure\nthat the system is driven into or is exactly at the percolation threshold. One such\nexample is the invasion-percolation process, which gives a reasonable description of\noil-water emplacement processes such as secondary oil migration. For such systems,\nthe behavior is well described by the scaling theory we have developed.",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            370,
            520,
            451
          ],
          "text": "In this and following chapters, we will first provide an introduction to the scaling\nof material properties such as conductivity (Chap. 9 ), elasticity (Chap. 10 ) and\ndiffusion (Chap. 11 ). Then we will demonstrate how processes occurring in systems\nwith frozen disorder, such as a porous material, often lead to the formation of fractal\nstructures (Chap. 12 ).",
          "reading_order": 4
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            483,
            331,
            501
          ],
          "text": "9.2 Conductivity and Permeability",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            519,
            520,
            582
          ],
          "text": "We will start our studies of physics in disordered media by addressing flow, either\nin the form of incompressible fluid flow in a random, porous system or in the form\nof electric current in a random, porous materials. First, let us address the similarities\nbetween these two flow phenomena.",
          "reading_order": 6
        },
        {
          "label": "sec",
          "bbox": [
            72,
            609,
            376,
            628
          ],
          "text": "Electrical Conductivity and Resistor Networks",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            645,
            520,
            757
          ],
          "text": "Traditionally, the conductive properties of a disordered material have been\naddressed by studying the behavior of random networks of resistors called random\nresistor networks [ 1 , 23 , 24 ] . In this case, a voltage $V$ is applied across the disordered\nmaterial, such as a bond-percolation network, and the total current, $I$ , through the\nsample is measured, giving the conductance $G$ of the sample as the constant of\nproportionality $I=GV$ . (We recall that the current $I$ is the amount of charge\nflowing through a given cross-sectional area per unit time).",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 145,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            234,
            62
          ],
          "text": "9.2 Conductivity and Permeability",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            520,
            58
          ],
          "text": "137",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            116
          ],
          "text": "We remember from electromagnetism that we discern between conductance and\nconductivity:",
          "reading_order": 2
        },
        {
          "label": "list",
          "bbox": [
            88,
            125,
            511,
            161
          ],
          "text": "conductance, G , is a property of a specific sample—a given medium—with\nspecific dimensions",
          "reading_order": 3
        },
        {
          "label": "list",
          "bbox": [
            88,
            161,
            289,
            179
          ],
          "text": "conductivity, $g$, is a material property",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            188,
            520,
            259
          ],
          "text": "For an $L^{d}$ sample in a $d$ -dimensional system, the conductance of a homogeneous\nmaterial with conductivity $g$ is\n\\begin{equation}\nG=L^{d-1} g/L=L^{d-2} g~.\n\\end{equation}",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            277,
            520,
            403
          ],
          "text": "It is common in electromagnetism to use $\\sigma$ for conductivity. Here, we will instead\nuse $g$ to avoid confusion with the exponent $\\sigma$ , which we introduced previously\nfor the behavior of $s_{\\xi}$ . The conductance is inversely proportional to the length of\nthe sample in the direction of flow, and proportional to the cross-sectional $d-1$ -\ndimensional area. We can understand this by considering that there are $L^{d-1}$ parallel\nparts that contribute to the flow. Parallel-parts add to the conductance. In addition,\neach part has a length $L$ , and we recall from electromagnetism that resistance\nincreases with length and therefore conductance decreases with length.",
          "reading_order": 6
        },
        {
          "label": "sec",
          "bbox": [
            72,
            436,
            322,
            451
          ],
          "text": "Flow Conductivity of a Porous System",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            465,
            520,
            756
          ],
          "text": "We can also use fluid flow in porous medium as our basic physical system. If done\nin the limit of slow, incompressible fluid flow these two systems are practically\nidentical. For fluid flow in a porous medium of length $L$ and cross-sectional area\n$A$ , the system is described by Darcy's law which provide a relation between, $\\Phi$ , the\namount of fluid volume flowing through a given cross-sectional area, $A$ , per unit\ntime and the pressure drop $\\Delta p$ across the sample:\n$$\\Phi=\\frac{kA}{\\eta}\\frac{\\Delta p}{L}~,$$\nwhere $k$ is the called permeability of the material and is a property of the material\ngeometry, and $\\eta$ is the viscosity of the fluid. Again, we would like a description so\nthat $k$ is material property, and all the information about the geometry of the material\ngoes into the permeability of the sample through the length $L$ and the cross-sectional\narea $A$ . Generalized to a $d$ -dimensional system, the relation is\n$$\\Phi=\\frac{k L^{d-1}}{\\eta L}\\Delta p=L^{d-2}\\frac{k}{\\eta}\\Delta p~.\\eqno(9.3)$$",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            72,
            770,
            520,
            802
          ],
          "text": "From this, we see that the electric conductivity problem in this limit is the same\nas the Darcy-flow permeability problem, where $\\Delta p/L$ corresponds to the voltage",
          "reading_order": 9
        }
      ]
    },
    {
      "page_number": 146,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            58
          ],
          "text": "138",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            376,
            44,
            520,
            62
          ],
          "text": "9 Flow in Disordered Media",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            179
          ],
          "text": "difference, $V$ , and $k/\\eta$ corresponds to the conductivity $g$ . We will therefore not\ndiscern between the two problems in the following. We will simply call them\nflow problems and describe them using the current, $I$ , the conductivity, $g$ , the\nconductance $G$ , and the potential $V$ . We will study these problems on a $L^d$\npercolation lattice, using the theoretical, conceptual and computational tools we\nhave developed so far.",
          "reading_order": 2
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            206,
            376,
            224
          ],
          "text": "9.3 Conductance of a Percolation Lattice",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            241,
            520,
            290
          ],
          "text": "Let us first address the conductance of a $L^{d}$ percolation system. The system may be\neither a site or a bond percolation system, but many of the concepts we introduce\nare simpler to explain if we just consider a bond percolation system.",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            290,
            520,
            354
          ],
          "text": "We will start with a simplified system: a network of bonds that are present with\nprobability $p$ . We assume that all bonds have the same conductance, which we can\nset to 1 without loss of generality. The bonds are removed with probability $1-p$ ,\nand we model this by setting the conductance of a removed bond to be zero.",
          "reading_order": 5
        },
        {
          "label": "sub_sub_sec",
          "bbox": [
            72,
            385,
            328,
            403
          ],
          "text": "Finding the Conductance of the System",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            419,
            520,
            467
          ],
          "text": "The conductance of the $L^d$ sample is found by solving the flow problem illustrated\nin Fig. 9.1 . A potential difference $V$ is applied across the whole sample, and we\nfind (measure) the resulting current $I$ . We find the conductance from Ohm's law (or",
          "reading_order": 7
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_146_figure_008.png)",
          "figure_path": "figures/percolation_studies_page_146_figure_008.png",
          "bbox": [
            125,
            492,
            457,
            707
          ],
          "reading_order": 8
        },
        {
          "label": "cap",
          "bbox": [
            72,
            716,
            520,
            799
          ],
          "text": "Fig. 9.1 (a) Illustration of flow through a bond percolation system. The bonds shown in red are\nthe singly connected bonds: all the flux has to go through these bonds. The bonds shown in blue\nare the rest of the backbone: The flow only takes place on the singly connected bonds and the\nbackbone, the remaining bonds are the dangling ends, which do not participate in fluid flow. (b)\nIllustration of the potentials $V_i$ and $V_j$ in two adjacent sites and the current $I_{i,j}$ from site $i$ into\nsite $j$",
          "reading_order": 9
        }
      ]
    },
    {
      "page_number": 147,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            270,
            62
          ],
          "text": "9.3 Conductance of a Percolation Lattice",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            520,
            58
          ],
          "text": "139",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            143
          ],
          "text": "similarly from Darcy's law for fluid flow):\n\\[I=GV \\quad \\Rightarrow \\quad G=\\frac{I}{V}~.\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:fondr_tractiff}\\]",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            158,
            475,
            171
          ],
          "text": "In general, the conductance $G$ will be a function of $p$ and $L\\colon G=G(p,L)$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            188,
            520,
            268
          ],
          "text": "Local Potentials and Currents Let us look at the network in more detail.\nFigure 9.1 b illustrates a small part of the whole system. The two adjacent sites $i$\nand $j$ are connected with a bond of conductance $G_{i, j}$ . If the bond is present (with\nprobability $p$ in the percolation system), the conductance is $G_{i, j}$ is 1, otherwise it is\nzero.",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            268,
            520,
            385
          ],
          "text": "The current from site $i$ to site $j$ is related to the difference in potential between\nthe two sites:\n\\[I_{i,j}=G_{i,j}\\left(V_i-V_j\\right)~,\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:thrice}\\]\nwhere we notice that the current is positive if the potential is higher in site $i$ than in\nsite $j$ .",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            400,
            520,
            528
          ],
          "text": "Conservation of Current In addition, the continuity condition provides a conser-\nvation equation for the currents: The net charge (or fluid mass for Darcy flow) are\nconserved, and therefore the net current into any point inside the lattice must be\nzero. This corresponds to the condition that the sum of the current from site $i$ into\nall its neighboring sites $k$ must be zero:\n\\[\n    \\sum_{k} I_{i,k}=0 \\eqno{(9.6)}\n  \\]",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            537,
            520,
            627
          ],
          "text": "In electromagnetism this is called Kirchhoff's rule for currents. We can rewrite this\nin terms of the local potentials $V_{i}$ instead by inserting ( 9.5 ) in ( 9.6 ):\n\\begin{equation}\n    \\sum_{k} G_{i,k}\\left(V_{i}-V_{k}\\right)=0\\;.\n\\end{equation}",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            636,
            520,
            681
          ],
          "text": "This provides us with a set of equations for all the potentials $V_i$ , which we must solve\nto find the potentials and hence the currents between all the sites in a percolation\nsystem.",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            72,
            698,
            520,
            752
          ],
          "text": "Finding Currents and Potentials We can use this to find all the potentials for\na percolation system. Let us address a two-dimensional system of size $L\\times L$ .\nThe potential in a position $(x,y)$ on the lattice is $V(x,y)$ , where $x$ and $y$ are",
          "reading_order": 9
        }
      ]
    },
    {
      "page_number": 148,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            90,
            58
          ],
          "text": "140",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            376,
            44,
            520,
            62
          ],
          "text": "9 Flow in Disordered Media",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            215
          ],
          "text": "integers, $x=0,1,2,\\ldots,L-1$ and $y=0,1,2,\\ldots,L-1$ . We denote $G_{i,j}$ as\n$G(x_i,y_i;x_j,y_j)$ . We can then rewrite as",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            232,
            520,
            376
          ],
          "text": "In order to solve this two-dimensional problem, it is common to rewrite it as a one-\ndimensional system of equations with a single index. The index $i=x+yL$ uniquely\ndescribes a point so that $V(x,\\, y)=V_{i}$ . We see that $(x,\\, y)=i$ , $(x+1,\\, y)=i+1$ ,\n$(x-1,\\, y)=i-1$ , $(x,\\, y+1)=i+L$ , and $(x,\\, y-1)=i-L$ . We can rewrite\n( 9.11 ) using this indexing system:\n$$G_{i, i+1}\\left(V_{i}-V_{i+1}\\right)+G_{i, i-1}\\left(V_{i}-V_{i-1}\\right)+\\eqno{(9.12)}$$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            385,
            520,
            448
          ],
          "text": "This is effectively a set of $L^d$ equations for $V_i$ . In addition we have the boundary\nconditions that $V(0,\\;j)=V$ and $V(L-1,\\;j)=0$ for $j=0,1,\\ldots,L-1$ . This\ndefines the system as a tri-diagonal set of linear equations that can be solved easily\nnumerically.",
          "reading_order": 4
        },
        {
          "label": "sec",
          "bbox": [
            72,
            483,
            233,
            501
          ],
          "text": "Computational Methods",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            518,
            520,
            613
          ],
          "text": "We have now reformulated the conductivity problem on a percolation lattice into a\ncomputational problem that we can solve. We do this by generating random lattices\nof size $L\\times L$ , solve to find the potential $V(x,y)$ , and then study the effective\nconductivity, $G=I/V$ of the system by summing up all the currents exiting the\nsystem (or entering — these should be the same).\nWe can do this by generating a bond-lattice, where the values $G_{i,j}$ are either 0",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            613,
            520,
            773
          ],
          "text": "or 1. However, so far all our visualization methods have been constructed for site\nlattices. We will therefore study a site lattice, but instead generate $G_{i,j}$ between two\nsites based on whether the sites are present. We set $G_{i,j}$ for two nearest-neighbors\nto be present (1) if both sites $i$ and $j$ are present (1). Otherwise we set $G_{i,j}$ to zero,\nthat is, if at least one of the sites is empty we set $G_{i,j}$ to be zero. We assume all\nthe sites on the left and right boundaries to be present. This is where current flows\nin and where the potentials are set. In addition, we assume all the sites on the top\nand bottom boundaries to be empty. There is therefore no flow in from the top or\nbottom. We therefore only study percolation from the left to the right.",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            773,
            520,
            806
          ],
          "text": "sitetobond transforms your percolation matrix z to a bond matrix. The function\nFIND_CON solves the system of equations to find the potentials, $V_{i}$, and the",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 149,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            270,
            62
          ],
          "text": "9.3 Conductance of a Percolation Lattice",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            511,
            58
          ],
          "text": "14",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_149_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_149_figure_002.png",
          "bbox": [
            72,
            80,
            520,
            519
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            537,
            520,
            564
          ],
          "text": "Fig. 9.2 Plots of the spanning cluster, the potential, $V(x,y)$ , the absolute value of the current\nflowing into each site, and the singly connected bonds, the backbone and the dangling ends",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            591,
            520,
            638
          ],
          "text": "function coltomat transforms the resulting array of potentials back into a matrix\nform, $V(x,y)$ . The following programs are used to calculate the potentials and\ncurrents and visualize the results. The resulting plots are shown in Fig. 9.2 .",
          "reading_order": 4
        },
        {
          "label": "code",
          "bbox": [
            80,
            660,
            462,
            725
          ],
          "text": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.sparse import spdiags, dia_matrix, coo_matrix\nfrom scipy.sparse.linalg import spsolve\nfrom scipy.ndimage import measurements",
          "reading_order": 5
        },
        {
          "label": "code",
          "bbox": [
            80,
            741,
            457,
            806
          ],
          "text": "# Written by Marin Soreng 2004\n# Calculates the effective flow conductance Ceff of the\n# lattice A as well as the potential V in every site.\ndef FIND_COND (A, X, Y):\nV_in = 1.",
          "reading_order": 6
        }
      ]
    },
    {
      "page_number": 150,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            58
          ],
          "text": "142",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            376,
            44,
            520,
            62
          ],
          "text": "9 Flow in Disordered Media",
          "reading_order": 1
        },
        {
          "label": "code",
          "bbox": [
            107,
            80,
            495,
            286
          ],
          "text": "V_out = 0.\n# Calls MK_EQSYSTEM .\nB,C = MK_EQSYSTEM (A , X , Y )\n# Kirchhoff ’s equations solve for V\nV = spsolve(B, C)\n# The pressure at the external sites is added\n# ( Boundary conditions )\nV = np.concatenate((V_in+np.ones(X),V,V_out+np.ones (X)))\n# Calculate Ceff\n# second-last X elements of V multiplied with second-last\n# elem. of A, these are the second last column of the\n# system gives the conductivity of the system per row\nCeff = np.dot((V[-1-2*X:-1-X]-V_out).T,A[-1-2*X:-1-X,1])\n/ ( V_in - V_out )\nreturn V , Ceff",
          "reading_order": 2
        },
        {
          "label": "code",
          "bbox": [
            80,
            295,
            511,
            394
          ],
          "text": "# Sets up Kirchoff ’s equations for the 2 D lattice A .\n# A has X * Y rows and 2 columns . The rows indicate the site ,\n# the first column the bond perpendicular to the flow direction\n# and the second column the bond parallel to the flow direction\n#\n# The return values are [B , C ] where B * x = C .\n# This is solved for the site pressure by x = B \\ C .",
          "reading_order": 3
        },
        {
          "label": "code",
          "bbox": [
            80,
            403,
            511,
            725
          ],
          "text": "def MK_EQSYSTEM (A , X , Y ):\n# Total no of internal lattice sites\nsites = X *( Y - 2)\n# Allocate space for the nonzero upper diagonals\nmain_diag = np.zeros(sites)\nupper_diag1 = np.zeros(sites - 1)\nupper_diag2 = np.zeros(sites - X)\n# Calculates the nonzero upper diagonals\nmain_diag = A[X:X*(Y-1), 0] + A[X:X*(Y-1), 1] + \\\nA[0:X*(Y-2), 1] + A[X-1:X*(Y-1)-1, 0]\nupper_diag1 = A [X:X*(Y-1)-1, 0]\nupper_diag2 = A [X:X*(Y-2), 1]\nmain_diag[np.where(main_diag == 0)] = 1\n# Constructing B which is symmetric , lower=upper diagonals\nB = dia_matrix ((sites , sites)) # B *u = t\nB = - spdiags ( upper_diag1 , -1 , sites , sites )\nB = B + - spdiags ( upper_diag2 ,-X , sites , sites )\nB = B + B.T + spdiags ( main_diag , 0 , sites , sites )\n# Constructing C\nC = np.zeros(sites)\n#\nC = dia_matrix ( (sites , 1) )\nC[0:X] = A[0:X, 1]\nC[-1-X+1:-1] = 0*A [-1 -2*X + 1:-1-X, 1]\nreturn B , C",
          "reading_order": 4
        },
        {
          "label": "code",
          "bbox": [
            80,
            742,
            484,
            792
          ],
          "text": "def sitetobond ( z ):\n# Function to convert the site network z(L,L) into a\n# (L*L,2) bond network\n# g [i,0] gives bond perpendicular to direction of flow",
          "reading_order": 5
        }
      ]
    },
    {
      "page_number": 151,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            270,
            62
          ],
          "text": "9.3 Conductance of a Percolation Lattice",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            520,
            58
          ],
          "text": "143",
          "reading_order": 1
        },
        {
          "label": "code",
          "bbox": [
            107,
            80,
            450,
            296
          ],
          "text": "# g [i,1] gives bond parallel to direction of flow\n# z [ nx , ny ] -> g [ nx * ny , 2]\nnx = np.size (z ,1 - 1)\nny = np.size (z ,2 - 1)\nN = nx * ny\ngg_r = np.zeros ((nx , ny)) # First , find these\ngg_d = np.zeros ((nx , ny )) # First , find these\ngg_r [:, 0:ny - 1] = z [:, 0:ny - 1] * z [:, 1:ny]\ngg_r [: , ny\n- 1] = z [: , ny\n- 1]\ngg_d [0:nx - 1, :] = z [0:nx - 1, :] * z [1:nx, :]\ngg_d [nx - 1, :] = 0\n# Then , concatenate gg onto g\ng = np.zeros ((nx *ny ,2))\ng [:, 0] = gg_d.reshape(-1,order=’F’).T\ng [:, 1] = gg_r.reshape(-1,order=’F’).T\nreturn g",
          "reading_order": 2
        },
        {
          "label": "code",
          "bbox": [
            80,
            313,
            378,
            430
          ],
          "text": "def coltomat (z, x, y):\n# Convert z(x*y) into a matrix of z(x,y)\n# Transform this onto a nx x ny lattice\ng = np.zeros ((x, y))\nfor iy in range(1,y):\ni = (iy - 1) * x + 1\nii = i + x - 1\ng[:, iy - 1] = z[ i - 1: ii]\nreturn g",
          "reading_order": 3
        },
        {
          "label": "code",
          "bbox": [
            79,
            454,
            385,
            531
          ],
          "text": "# Generate spanning cluster (l - r spanning )\nlx = 400\nly = 400\np = 0.5927\nncount = 0\nperc = []",
          "reading_order": 4
        },
        {
          "label": "code",
          "bbox": [
            79,
            546,
            484,
            799
          ],
          "text": "while (len(perc)==0):\nncount = ncount + 1\nif (ncount >100):\nbreak\nz=np.random.rand(lx,ly)<p\nlw,num = measurements.label(z)\nperc_x = np.intersect1d(lw[0,:],lw[-1,:])\nperc = perc_x[np.where(perc_x > 0)]\nprint(\"Percolation attempt\", ncount)\nzz = np.asarray({lw == perc[0]})\n# zz now contains the spanning cluster\nzzz = zz.T # Transpose\ng = sitetobond ( zzz ) # Generate bond lattice\nV, c_eff = FIND_COND (g, lx, ly) # Find conductivity\nx = coltomat ( V , lx , ly ) # Transform to nx x ny lattice\nV = x * zzz\ng1 = g[:,0]\ng2 = g[: ,1]\nz1 = coltomat( g1 , lx , ly )",
          "reading_order": 5
        }
      ]
    },
    {
      "page_number": 152,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            58
          ],
          "text": "144",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            376,
            44,
            520,
            62
          ],
          "text": "9 Flow in Disordered Media",
          "reading_order": 1
        },
        {
          "label": "code",
          "bbox": [
            80,
            80,
            278,
            98
          ],
          "text": "z2 = coltomat( g2, lx, ly)",
          "reading_order": 2
        },
        {
          "label": "code",
          "bbox": [
            79,
            107,
            350,
            216
          ],
          "text": "# Plot results\nplt.figure(figsize=(16,16))\nax = plt.subplot(2,2,1)\nplt.imshow(zzz, interpolation=’nearest’)\nplt.title(\"Spanning cluster\")\nplt.subplot(2,2,2, sharex=ax, sharey=ax)\nplt.imshow(V, interpolation=’nearest’)\nplt.title(\"Potential\")",
          "reading_order": 3
        },
        {
          "label": "code",
          "bbox": [
            79,
            232,
            511,
            672
          ],
          "text": "# Calculate current from top to down from the potential\nf2 = np.zeros ( lx, ly ))\nfor iy in range(ly -1):\nf2[:, iy ] = ( V [:, iy ] - V [:, iy +1]) * z2 [:, iy ]\n# Calculate current from left to right from the potential\nf1 = np.zeros ( (lx, ly ))\nfor ix in range(lx-1):\nf1[ ix,:] = ( V [ ix,:] - V [ ix +1,:]) * z1 [ ix,:]\n# Find the sum of (absolute) currents in and out of each site\nfn = np.zeros (( lx, ly ))\nfn = fn + abs ( f1 )\nfn = fn + abs ( f2 )\n# Add for each column (expt leftmost) the offset up-down curren\nfn [:,1: ly ] = fn [:,1: ly ] + abs ( f2 [:,0: ly -1])\n# For the left-most one, add the inverse potential\n# multiplied with the spanning cluster bool information\nfn [:,0] = fn [:,0] + abs (( V [:,0] - 1.0)*( zzz [:,0]))\n# For each row (expt topmost) add the offset left-right current\nfn [1: lx,:] = fn [1: lx,:] + abs ( f1 [0: lx -1,:])\n# Plot results\nplt.subplot(2,2,3, sharex=ax, sharey=ax)\nplt.imshow(fn, interpolation='nearest')\nplt.title (\" Current \")\n# Singly connected\nzsc = fn > (fn.max() - 1e-6)\n# Backbone\nzbb = fn>le-6\n# Combine visualizations\nztt = ( zzz*1.0 + zsc*2.0 + zbb*3.0 )\nzbb = zbb / zbb.max()\nplt.subplot(2,2,4, sharex=ax, sharey=ax)\nplt.imshow(ztt, interpolation='nearest')\nplt.title (\" SC, BB and DE \")",
          "reading_order": 4
        },
        {
          "label": "sec",
          "bbox": [
            72,
            715,
            256,
            729
          ],
          "text": "Measuring the Conductance",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            743,
            520,
            793
          ],
          "text": "We can now use this program to measure the conductance $G(p,L)$ of the system\nand how it varies with both p and L. The idea is to calculate G from G=I/V,",
          "reading_order": 6
        }
      ]
    },
    {
      "page_number": 153,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            270,
            62
          ],
          "text": "9.3 Conductance of a Percolation Lattice",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            520,
            58
          ],
          "text": "145",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            286
          ],
          "text": "all the currents escaping (or entering) the system. In the program, we have set the\npotential on the left side to be 1. We recall that we describe positions with the index\n$j=x+yL$ , where the left side corresponds to $x=0$ and therefore $j=yL$ , which\nwe write at $iL$ with $i=y$ is the position along the $y$ -axis. The potentials along\nthe left side are therefore $V_{iL}=1$ for $i=0$ , $1$ , $\\ldots$ , $L-1$ . The conductance from\nsite $iL$ into a site on the right, that is, into $iL+1$ , is $G_i L, iL+1$ , which is 1. The\ncurrent into the system from the left side, that is from site $iL$ into site $iL+1$ , is\n$I_{iL, iL+1}=G_{iL, iL+1}(V_{iL}-V_{iL+1})$ . The total current $I$ into the system is therefore:\n$$I=\\sum_{i=0}^{L-1} I_{iL, iL+1}=\\sum_{i=0}^{L-1} G_{iL, iL+1}\\left(V_{iL}-V_{iL+1}\\right)=\\sum_{i=0}^{L-1}\\left(V_{iL}-V_{iL+1}\\right)~.$$",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            304,
            520,
            334
          ],
          "text": "We use the following program to find the conductance, $G(p,L)$ , for an $L\\times L$ system\nfor $L=400$ , as well as the density of the spanning cluster $P(p,L)$ .",
          "reading_order": 3
        },
        {
          "label": "code",
          "bbox": [
            79,
            356,
            511,
            797
          ],
          "text": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.ndimage import measurements\nLvals = [400]\npVals = np.logspace(np.log10(0.58), np.log10(0.85), 20)\nC = np.zeros((len(pVals),len(Lvals)),float)\nP = np.zeros((len(pVals),len(Lvals)),float)\nnSamples = 600\nG = np.zeros(len(Lvals))\nfor iL in range(len(Lvals)):\nL = Lvals[iL]\nlx = L\nly = L\nfor pIndex in range(len(pVals)):\np = pVals[pIndex]\nncount = 0\nfor j in range(nSamples):\nncount = 0\nperc = []\nwhile (len(perc)==0):\nncount = ncount + 1\nif (ncount > 1000):\nprint(\"Couldn’t make percolation cluster\")\nbreak\nz=np.random.rand(lx,ly)<p\nlw,num = measurements.label(z)\nperc_x = np.intersect1d(lw[0,:],lw[-1,:])\nperc = perc_x[np.where(perc_x > 0)]\nif len(perc) > 0: # Found spanning cluster\narea = measurements.sum(z, lw, perc[0])\nP[pIndex,iL] = P[pIndex,iL] + area # Find P(p,L\nzz = np.asarray({lw == perc[0]}) # zz=spanning\nzzz = zz.T",
          "reading_order": 4
        }
      ]
    },
    {
      "page_number": 154,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            50,
            90,
            62
          ],
          "text": "146",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            376,
            49,
            520,
            62
          ],
          "text": "9 Flow in Disordered Media",
          "reading_order": 1
        },
        {
          "label": "code",
          "bbox": [
            120,
            80,
            493,
            216
          ],
          "text": "g = sitetobond (zzz) # Generate bond lattice\nPvec, c_eff = FIND_COND(g, lx, ly)\nC[pIndex,iL] = C[pIndex,iL] + c_eff\nC[pIndex,iL] = C[pIndex,iL]/nSamples\nP[pIndex,iL] = P[pIndex,iL]/(nSamples*L*L)\not(pVals,C[:,-1],'-ob',label='$C$')\not(pVals,P[:,-1],'-or',label='$P$')\ngend()\nabel(r\"$p$\")\nabel(r\"$g,P$\")",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            232,
            520,
            378
          ],
          "text": "The resulting behavior for $L=400$ and $M=600$ different realizations is shown\nin Fig. 9.3 . We observe two things from this plot: First we see that the behaviors of\n$G(p, L)$ and $P(p, L)$ are qualitatively different around $p=p_c$ : $P(p, L)$ increases\nvery rapidly as $(p-p_c)^\\beta$ where $\\beta$ is less than 1. However, it appears that $G(p, L)$\nincreases more slowly. Indeed, from the plot it looks as if $G(p, L)$ increases as\n$(p-p_c)^x$ with an exponent $x$ that is larger than 1. How can this be? Why does the\ndensity of the spanning cluster increase very rapidly, but the conductance increases\nmuch slower? This may be surprising, but we will develop an explanation for this\nobservation in the following.",
          "reading_order": 3
        },
        {
          "label": "sec",
          "bbox": [
            72,
            411,
            423,
            426
          ],
          "text": "Conductance and the Density of the Spanning Cluster",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            446,
            520,
            492
          ],
          "text": "For an infinite system, that is when $L\\rightarrow\\infty$ , we cannot define a conductance\n$G$ . Instead, we must describe the system by its conductivity $g=L^{d-2}G$ (see\n( 9.1 ) ). The two-dimensional system is a special case where the conductance and the",
          "reading_order": 5
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_154_figure_006.png)",
          "figure_path": "figures/percolation_studies_page_154_figure_006.png",
          "bbox": [
            80,
            519,
            520,
            752
          ],
          "reading_order": 6
        },
        {
          "label": "cap",
          "bbox": [
            72,
            768,
            520,
            790
          ],
          "text": "Fig. 9.3 Plots of the conductance $G(p,L)$ and the density of the spanning cluster $P(p,L)$ for\n$L=400$",
          "reading_order": 7
        }
      ]
    },
    {
      "page_number": 155,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            351,
            62
          ],
          "text": "9.4 Scaling Arguments for Conductance and Conductivity",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            520,
            58
          ],
          "text": "147",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            511,
            128
          ],
          "text": "conductivity are identical. However, in general, we need to use this transformation\nto relate $G$ and $g$ .",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            128,
            520,
            225
          ],
          "text": "The effective conductivity is therefore zero. When $p$ is close to 1, the density of the\nspanning cluster will be proportional to $p$ , and we also expect the conductance to be\nproportional to $p$ in this range. This may lead us to assume that the density of the\nspanning cluster and the conductance of the sample are proportional also when $p$ is\nclose to $p_c$ . However, our direct measurements above (originally done by Last and\nThouless [ 24 ] ) show that $P$ and $G$ are not proportional when $p$ approaches $p_c$ .",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            225,
            520,
            403
          ],
          "text": "We have the tools to understand this behavior. The spanning cluster consists of\nthe backbone and dangling ends. However, it is only the backbone that contributes\nto conductance of the sample. We could remove all the dangling ends, and still get\nthe same behavior the conductance. This suggests, that it is the scaling behavior\nof the backbone that is important for the conductance. However, we have found\nthat the mass-scaling exponent of the backbone, $D_B$ , is smaller than $D$ , the mass\nscaling exponent for the spanning cluster. This indicates that most of the mass of the\nspanning cluster is found in the dangling ends. This is the reason for the difference\nbetween the behavior of $P(p)$ , and $G(p)$ for $p$ close to $p_c$ . In the following we will\ndevelop a detailed scaling argument for the behavior of the conductance $G$ and the\nconductivity $g$ of the percolation system.",
          "reading_order": 4
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            436,
            487,
            451
          ],
          "text": "9.4 Scaling Arguments for Conductance and Conductivity",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            465,
            520,
            582
          ],
          "text": "We will now use the same scaling techniques we introduced to find the behavior of\n$P(p,L)$ to develop a theory for the conductance $G(p,L)$ . First, we realize that we\ninstead of using $p$ as the variable, we may describe the conductance as a function\nof $\\xi$ and $L$ : $G(p,L)=G(\\xi,L)$ . Second, we realize that the system can only be\nconducting when there is a spanning cluster, that is, for $p\\geq p_c$ . We will address\ntwo limiting behaviors: (i) the case $L\\gg\\xi$ and (ii) the case $\\xi\\gg L$ , which means\nthat $p$ is close to $p_c$ .",
          "reading_order": 6
        },
        {
          "label": "sub_sub_sec",
          "bbox": [
            72,
            609,
            331,
            628
          ],
          "text": "Scaling Argument for $p>p_{c}\\!\\,$ and $L\\gg \\xi \\!\\,$",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            645,
            520,
            709
          ],
          "text": "When $L\\gg\\xi$ the system is effectively homogeneous over length scales larger\nthan $\\xi$ . , we know that over length scales larger than $\\xi$ , the system is effectively\nhomogeneous. If were subdivide the system into cells of size $\\xi$ , we get a total of\n$(L/\\xi)^d$ effectively homogeneous cells.",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            72,
            709,
            518,
            806
          ],
          "text": "$G=\\ell^{d-2} G_\\ell$ For a homogeneous system of $\\ell^d$ boxes of size $\\ell$ , the conductance is , where $G_\\ell$ is the conductance of a single box. We apply the same principle\nto this system: The conductance $G(\\xi,L)$ is given as\n$$G(\\xi,L)=(\\frac{L}{\\xi})^{d-2} G(\\xi,\\xi)~,\\eqno(9.15)$$",
          "reading_order": 9
        }
      ]
    },
    {
      "page_number": 156,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            58
          ],
          "text": "148",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            376,
            44,
            520,
            62
          ],
          "text": "9 Flow in Disordered Media",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            197
          ],
          "text": "where $(L/\\xi)=\\ell$ is the number of boxes and $G(\\xi,\\xi)=G_{\\ell}$ is the conductance\nof a single box. We recognize $G(\\xi,\\xi)$ as the conductance of a system where the\ncorrelation length $\\xi$ equals the system size, that is, $L=\\xi$ . We can then find the\nconductivity $g(\\xi,L)$ from :\n$$\ng(\\xi,L)=L^{-(d-2)} G(\\xi,L)=\\frac{G(\\xi,\\xi)}{\\xi^{d-2}}~.\\eqno(9.16)\n$$",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            206,
            520,
            286
          ],
          "text": "What is $G(\\xi,\\xi)$ ? A system with correlation length equal to the system size is\nindistinguishable from a system at $p=p_c$ . The conductance $G(\\xi,\\xi)$ is therefore\nthe conductance of the spanning cluster at $p=p_c$ in a system of size $L=\\xi$ .\nLet us therefore find the conductance of a finite system of size $L$ at the percolation\nthreshold.",
          "reading_order": 3
        },
        {
          "label": "sec",
          "bbox": [
            72,
            320,
            316,
            335
          ],
          "text": "Conductance of the Spanning Cluster",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            349,
            520,
            448
          ],
          "text": "What is the conductance, $G(\\infty,L)$ , of the spanning cluster at $p=p_c$ ? We know that\nthe spanning cluster consists of the backbone and the dangling ends, and that only\nthe backbone will contribute to the conductivity. The backbone can be described\nby the blob model (see Sect. 8.2 for a discussion of the blob model): The backbone\nconsists of blobs of bonds in parallel, and links of singly connected bonds between\nthem.",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            448,
            520,
            564
          ],
          "text": "Starting from a scaling hypothesis for the conductance, we will derive the\nconsequences of this assumption, and then test these consequences to see if the\ndata is consistent with our assumption. This will then corroborate the hypothesis.\nOur scaling hypothesis will be that the conductance of a system of size $L$ at $p_c$ can\nbe described by a scaling exponent $\\tilde{\\zeta}_R$ :\n$$G(\\infty, L) \\propto L^{-\\bar{\\zeta}_R}~. \\eqno(9.17)$$",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            582,
            520,
            645
          ],
          "text": "Finding Bounds for the Scaling Behavior In many cases, we cannot find the\nscaling exponents directly, but we may be able to find bounds for the scaling\nexponents. We will pursue this approach here. We will find bounds for the scaling\nof $G(\\infty,L)$ , and use them to determine bounds for the exponent $\\tilde{\\zeta}_R$ .",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            663,
            520,
            773
          ],
          "text": "Lower Bound for the Scaling Exponent First, we know that the spanning cluster\nconsists of blobs in series with the singly connected bonds. This implies that the\nresistivity $R=1/G$ of the spanning cluster is given as the resistivity of the singly\nconnected bonds $R_{SC}$ plus the resistivity of the blobs, $R_{blob}$ since resistances are\nadded for a series of resistances:\n\\[\n    1/G=R=R_{SC}+R_{blob}~. \\eqno(9.18)\n  \\]",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 157,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            351,
            62
          ],
          "text": "9.4 Scaling Arguments for Conductance and Conductivity",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            511,
            58
          ],
          "text": "14",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            179
          ],
          "text": "This implies that $R> R_{SC}$ . The singly connected bonds are connected in series,\none after another. Their total resistance is the sum of the resistances of each bond,\nwhich is the resistance of a single bond, multiplied with the number of sites, $M_{SC}$ .\nBecause $R_{blob}$ is positive, we see from ( 9.18 ) that\n\\[\n    R_{SC}= M_{SC}=R-R_{blob}<R~.~\\eqno(9.19)\n    \\]",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            188,
            520,
            250
          ],
          "text": "Because $M_{SC}\\propto L^{D_{SC}}$, and we have assumed that $R\\propto L^{\\bar{\\zeta}_{R}}$, we find that\n$$L^{Dsc}<L^{\\bar{\\zeta}_{R}}\\quad\\Rightarrow\\quad D_{SC}\\leq \\tilde{\\zeta}_{R}\\;.\\eqno(9.20)$$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            259,
            304,
            278
          ],
          "text": "This gives a lower bound for the exponent!",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            295,
            520,
            573
          ],
          "text": "Upper Bound for the Scaling Exponent We can find an upper bound by exam-\nining the minimal path. The resistance of the spanning cluster will be smaller than\nor equal to the resistance of the minimal path, since the spanning cluster will have\nsome regions, the blobs, where there are bonds in parallel. Adding parallel bonds\nwill always lower the resistance. Hence, the resistance is smaller than or equal to\nthe resistance of the minimal path. Since the minimal path is a series of resistances\nin series, the total resistance of the minimal path is the mass of the minimal path\nmultiplied by the resistance of a single bond. Consequently, the resistance of the\nspanning cluster is smaller than the mass of the minimal path, $M_{\\text{min}}$ , which we\nknow scales with system size, $M_{\\text{min}} \\propto L^{D_{\\text{min}}}$ . We have therefore found an upper\nbound for the exponent\n$$L^{\\bar{\\zeta}_R} \\propto R \\leq L_{min} \\propto L^{D_{min}}~, \\eqno(9.21)$$\nand therefore\n$$\\tilde{\\zeta}_R \\leq D_{min}~. \\eqno(9.22)$$",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            590,
            520,
            654
          ],
          "text": "Upper and Lower Bound Demonstrate the Scaling Relation We have therefore\ndemonstrated (or proved) the scaling relation\n\\[D_{SC} \\leq \\tilde{\\zeta}_R \\leq D_{min}~.\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:defn-bound}\\]",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            671,
            520,
            780
          ],
          "text": "Because this scaling relation shows that the scaling of $R$ is bounded by two power-\nlaws in $L$ , we have also proved that the resistance $R$ is a power-law, and that the\nexponents are within the given bounds. We notice that when the dimensionality of\nthe system is high, the probability of loops will be low, and blobs will be unlikely.\nIn this case\n\\[D_{SC}=\\tilde{\\zeta}_R=D_{min}=D_{max}~.\\tag*{9.24}\\]",
          "reading_order": 7
        }
      ]
    },
    {
      "page_number": 158,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            90,
            58
          ],
          "text": "150",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            376,
            44,
            520,
            62
          ],
          "text": "9 Flow in Disordered Media",
          "reading_order": 1
        },
        {
          "label": "sec",
          "bbox": [
            72,
            80,
            226,
            98
          ],
          "text": "Conductivity for $p>p_{c}$",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            116,
            520,
            180
          ],
          "text": "By scaling arguments, we have established that the conductance $G(\\infty,L)$ of the\nspanning cluster in a system of size $L$ is described by the exponent $\\tilde{\\zeta}_R$ :\n$$ G(\\infty,L) \\propto L^{-\\tilde{\\zeta}_R} \\text{ when } L \\leq \\xi \\; . \\eqno(9.25) $$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            197,
            520,
            286
          ],
          "text": "We use this to find an expression for $G(\\xi,\\xi)$ , which is the conductance of the\nspanning cluster at $p=p_c$ in a system of size $L=\\xi$ , by inserting $L=\\xi$ in\n( 9.25 ):\n$$ G(\\xi,\\xi) \\propto \\xi^{-\\bar{\\zeta}_R}~. \\eqno (9.26)$$",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            295,
            520,
            404
          ],
          "text": "We insert this in ( 9.16 ) in order to establish the behavior of the conductivity, $g$ , for\n$p>\\ p_c$ , finding that\n$$\n\t\\begin{aligned}\n\t\t& g=\\frac{G(\\xi,\\xi)}{\\xi^{d-2}}\\propto \\xi^{-(d-2+\\bar{\\zeta}_R)}\\\\\n\t\t\t&\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\quad\\propto (p-p_c)^{\\nu(d-2+\\bar{\\zeta}_R)}\\propto (p-p_c)^\\mu\n\t\t\\end{aligned}\n\t\t$$",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            421,
            358,
            474
          ],
          "text": "Where we have introduced the exponent $\\mu$ :\n$$\\mu=v(d-2+\\tilde{\\zeta}_R)~.$$",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            483,
            520,
            549
          ],
          "text": "We notice that for two-dimensional percolation, any value of $\\tilde{\\zeta}_R$ larger than $1/v$\nwill lead to $\\mu>1$ , which was what was observed in Fig. 9.3 . The exponent $\\mu$ is\ntherefore larger than 1, which is significantly different from the exponent $\\beta$ , which\nis less than 1, which describes the mass of the spanning cluster.",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            564,
            520,
            727
          ],
          "text": "Can the Results Be Generalized? We have therefore explained the difference\nbetween how $P(p,L)$ and $G(p,L)$ (or $g(p,L)$ ) scales with ( $p-p_c$ ) close to $p_c$ .\nThis is a useful insight and a useful result that provides important information about\nhow a random porous material behaves just as flow is starting to occur through it.\nNotice that when we study percolation systems, we have generally assumed that the\nporosity is uncorrelated. For real systems, the porosity may have correlations due to\nthe physical processes that have generated the porosity or the underlying materials.\nHowever, when we know how to describe uncorrelated systems like the percolation\nsystem, we may use similar theoretical, scaling and computational approaches to\nstudy the behavior of real and possibly correlated systems.",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 159,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            233,
            62
          ],
          "text": "9.5 Renormalization Calculation",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            511,
            58
          ],
          "text": "15",
          "reading_order": 1
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            80,
            314,
            98
          ],
          "text": "9.5 Renormalization Calculation",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            116,
            520,
            162
          ],
          "text": "Another theoretical approach to address and understand the behavior of the system\nis through the renormalization calculation. Here, we will use the renormalization\napproach for a square bond lattice in order to estimate the exponent $\\tilde{\\zeta}_R$ .",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            162,
            528,
            555
          ],
          "text": "In order to apply the renormalization approach, we calculate the average\nresistance $\\langle R \\rangle$ of a 2 $\\times$ 2 cell. We use the H-cell approach and only look at percolation\nin the horizontal direction. The various configurations $c$ and their degeneracy $g(c)$\nis illustrated in Table 9.1 . (The degeneracy is the number of configurations in the\nsame class). We assume that the resistance of a single bond is $R_0$ . The average\nresistance, $\\langle R \\rangle$ , of the renormalized cell is then the probability of the renormalized\ncell to be occupied, $p'$ , multiplied with the resistance of the renormalized cell, $R'$ ,\nso that $p'R'=\\langle R \\rangle$ . Using the scaling relation for the resistance, $R\\propto L^{\\bar{\\xi}_R}$ , we can\ndetermine the exponent from\n$$\\tilde{\\zeta}_R=\\frac{\\ln R'}{\\ln b}\\;. \\eqno(9.30)$$\nwhere all the values are calculated for $p^*$ , which we recall is $p^*=1/2$ for this\nscheme. The renormalization scheme and the values used are shown in Table 9.1 ,\nwhere we use $p'=p^*=1/2$ to calculate $R'$ . The resulting value for the\nrenormalized resistance is\n$$R'=\\frac{1}{p'}\\sum_c g(c)P(c)R(c)$$\n$$=\\frac{1}{p'}\\left(\\frac{1}{2}\\right)^5\\left(1+1+4\\cdot \\frac{5}{3}+2\\cdot 2+2\\cdot 3+4\\cdot 2+2\\cdot 2\\right)\\qquad \\eqref{eq:StrongFormerFnorm}$$",
          "reading_order": 4
        },
        {
          "label": "cap",
          "bbox": [
            72,
            582,
            203,
            698
          ],
          "text": "Table 9.1 Renormalization\nscheme for the scaling of the\nresistance $R$ in a random\nresistor network. The value\n$R(c)$ gives the resistance of\nconfiguration $c$ , and $g(c)$ is\nthe degeneracy, that is, the\nnumber of such\nconfigurations",
          "reading_order": 5
        },
        {
          "label": "tab",
          "bbox": [
            349,
            582,
            515,
            788
          ],
          "text": "<table><tr><td>c</td><td>P( c )</td><td>g( c )</td><td>R  c</td></tr><tr><td>1</td><td>p 5 (1 − p )0</td><td>1</td><td>1</td></tr><tr><td>2</td><td>p 4 (1 − p )1</td><td>1</td><td>1</td></tr><tr><td>3</td><td>p 4 (1 − p )1</td><td>4</td><td>5/3</td></tr><tr><td>4</td><td>p 3 (1 − p )2</td><td>2</td><td>2</td></tr><tr><td>5</td><td>p 3 (1 − p )2</td><td>2</td><td>3</td></tr><tr><td>6</td><td>p 3 (1 − p )2</td><td>4</td><td>2</td></tr><tr><td>7</td><td>p 2 (1 − p )3</td><td>2</td><td>2</td></tr></table>",
          "reading_order": 6
        }
      ]
    },
    {
      "page_number": 160,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            58
          ],
          "text": "152",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            376,
            44,
            512,
            62
          ],
          "text": "9 Flow in Disordered Medi",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            144
          ],
          "text": "Consequently, the exponent $\\tilde{\\zeta}_{R}$ is given by\n$$\\tilde{\\zeta}_{R}\\simeq\\frac{\\ln1.917}{\\ln2}\\simeq0.939~.\\eqno(9.34)$$",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            161,
            511,
            174
          ],
          "text": "This value is consistent with the scaling bounds set by the scaling relation in ( 9.24",
          "reading_order": 3
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            206,
            242,
            224
          ],
          "text": "9.6 Finite Size Scaling",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            241,
            403,
            286
          ],
          "text": "In general, the conductance and the conductivity is related by:\n$$G(p,L)=L^{d-2}g(p,L)$$",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            304,
            520,
            390
          ],
          "text": "We found that the scaling of the conductivity is:\n\\[g \\propto (p-p_c)^{\\mu} \\propto \\xi^{-\\mu/v}~,\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:expandinglaw}\\]\nwith the exponent $\\mu$ given as $\\mu=v\\left(d-2+\\tilde{\\zeta}_R\\right)$ .",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            393,
            520,
            485
          ],
          "text": "How can we use this scaling behavior as a basis for a finite-size scaling ansatz?\nWe extend the behavior of the infinite system to the finite size system by the\nintroduction of a finite size scaling function $f(L/\\xi)$ :\n$$g(\\xi, L)=\\xi^{-\\mu/v} f(\\frac{L}{\\xi})~.$$",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            501,
            520,
            636
          ],
          "text": "We find the behavior of the scaling function, $f(u)$ , by addressing the limiting\ncases. When $\\xi\\to\\infty$ , we know that $g(\\xi,L)$ will only depend on $L$ , which means\nthat $f(L/\\xi)$ must cancel the $\\xi^{-\\mu/v}$ term, that is, $f(u)\\propto u^{-\\mu/v}$ for $u\\ll1$ .\nSimilarly, when $\\xi\\ll L$ , we know that $g(\\xi,L)$ will only depend on $\\xi$ , which means\nthat $f(L/\\xi)$ must be a constant. The scaling function $f(u)$ therefore has the form\n$$f(u)=\\begin{cases}\n    \\text{const. when }u\\gg 1,~\\text{that is }L\\to\\infty\\\\\n    u^{-\\mu/v}&\\text{when }u\\ll1,~\\text{that is }\\xi\\to\\infty\n\\end{cases}\\eqno(9.38)$$",
          "reading_order": 8
        },
        {
          "label": "sec",
          "bbox": [
            72,
            663,
            287,
            680
          ],
          "text": "Finite-Size Scaling Observations",
          "reading_order": 9
        },
        {
          "label": "para",
          "bbox": [
            72,
            698,
            520,
            727
          ],
          "text": "How does the scaling ansatz correspond to the observations? We can use the\nprogram we have developed to measure the conductivity as a function of both",
          "reading_order": 10
        }
      ]
    },
    {
      "page_number": 161,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            180,
            62
          ],
          "text": "9.6 Finite Size Scaling",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            520,
            58
          ],
          "text": "153",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            109
          ],
          "text": "$p$ and system size $L$ . The following program has been modified for this type of\nmeasurement:",
          "reading_order": 2
        },
        {
          "label": "code",
          "bbox": [
            79,
            134,
            502,
            708
          ],
          "text": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.ndimage import measurements\nfrom matplotlib.colors import ListedColormap\nLvals = [25,50,100,200,400]\npVals = np.logspace(np.log10(0.58), np.log10(0.85), 20)\nC = np.zeros((len(pVals),len(Lvals)),float)\nP = np.zeros((len(pVals),len(Lvals)),float)\nnSamples = 600\nmu = np.zeros(len(Lvals))\nfor iL in range(len(Lvals)):\nL = Lvals[iL]\nfor pIndex in range(len(pVals)):\np = pVals[pIndex]\nncount = 0\nfor j in range(nSamples):\nncount = 0\nperc = []\nwhile (len(perc)==0):\nncount = ncount + 1\nif (incount > 1000):\nprint(\"Couldn’t make percolation cluster\")\nbreak\nz=np.random.rand(L,L)<p\nlw,num = measurements.label(z)\nperc_x = np.intersect1d(lw[0,:],lw[-1,:])\nperc = perc_x[np.where(perc_x > 0)]\nif len(perc) > 0:\nzz = np.asarray((lw == perc[0]))\n# zz now contains the spanning cluster\nzzz = zz.T\n#\n# Generate bond lattice from this\ng = sitetobond ( zzz )\n#\n# Generate conductivity matrix\nPvec, c_eff = FIND_COND(g, L, L)\nC[pIndex,iL] = C[pIndex,iL] + c_eff\nC[pIndex,iL] = C[pIndex,iL]/nSamples\nfor iL in range(len(Lvals)):\nL = Lvals[iL]\nplt.plot(pVals,C[:,iL],label=\"L=\"+str(L))\nplt.xlabel(r*$p$\")\nplt.ylabel(r*$g(p,L)$\")\nplt.legend()",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            725,
            520,
            773
          ],
          "text": "The results for $L=25,\\,50,\\,100,\\,200,\\,400$ are shown in Fig. 9.4 . Here, we plot\nboth the raw data, $g(p,\\, L)$ , and the behavior of $g(p_c,\\, L)$ as a function of $L$ on a\n$\\log-\\log$ -scale, showing that $g(p_c,\\, L)$ indeed scales as a power-law with $L$ .",
          "reading_order": 4
        }
      ]
    },
    {
      "page_number": 162,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            58
          ],
          "text": "154",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            376,
            44,
            520,
            62
          ],
          "text": "9 Flow in Disordered Media",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_162_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_162_figure_002.png",
          "bbox": [
            72,
            80,
            511,
            250
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            259,
            520,
            304
          ],
          "text": "Fig. $L=25,\\,50,\\,100,\\,200,\\,400$ a) Illustration of the conductivity $g(p,L)$ as a function of $p$ for . We see that at $p_c$ the conductivity $g(p_c,L)$ is scaling according to\n$g\\propto L^{-\\mu/v}$",
          "reading_order": 3
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_162_figure_004.png)",
          "figure_path": "figures/percolation_studies_page_162_figure_004.png",
          "bbox": [
            152,
            313,
            439,
            510
          ],
          "reading_order": 4
        },
        {
          "label": "cap",
          "bbox": [
            72,
            526,
            511,
            537
          ],
          "text": "Fig. 9.5 Finite-size data scaling collapse for $g(p,L)$ showing the validity of the scaling ansatz",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            564,
            520,
            707
          ],
          "text": "Scaling Data Collapse We can also test the scaling ansatz by plotting a finite-size\nscaling data collapse. We expect that the conductivity will behave as\n\\[g(p,L)=L^{-\\mu/v} \\tilde f\\left(L/\\xi\\right)~,\\eqno(9.39)\\]\nwhich we can rewrite by introducing $\\xi=\\xi_0(p-p_c)^{-v}$ to get:\n\\[g(p,L)=L^{-\\mu/v} \\tilde f\\left(\\left(L^{1/v}(p-p_c)\\right)^v\\right)~.\\eqno(9.40)\\]",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            716,
            520,
            752
          ],
          "text": "In Fig. 9.5 we demonstrate that this scaling form is valid by getting a data collapse\nwhen we plot $L^{\\mu/\\nu}g(p,L)$ as a function of $L^{1/\\nu}(p-p_c)$ .",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            769,
            520,
            798
          ],
          "text": "Estimating the Exponent $\\mu$ from the Data We can also use the results from the\nsimulations to measure $\\mu$ directly by plotting $g(p,L)$ as a function of $(p-p_c)$",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 163,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            251,
            62
          ],
          "text": "9.7 Internal Distribution of Currents",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            520,
            58
          ],
          "text": "155",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_163_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_163_figure_002.png",
          "bbox": [
            72,
            71,
            528,
            250
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            259,
            520,
            286
          ],
          "text": "Fig. 9.6 (a) Plot of $g(p,L)$ for increasing values of $L$ . (b) Plot of the exponent $\\mu$ calculated by a\nlinear fit for increasing system sizes $L$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            313,
            520,
            394
          ],
          "text": "and fitting a linear function on a log-log plot. We do this for increasing values of $L$\nin Fig. 9.6 (Notice that the curves for small values of $L$ clearly are not linear, and\nwe should, ideally, have fitted the linear curve to only the part of the curve that is\napproximately linear. We will not address methods to do this here, but you should\ndevelop such methods in your own research.).",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            412,
            520,
            492
          ],
          "text": "Implications of the Scaling Ansatz Our conclusion is that the conductivity is a\nfunction of $p$ , but also of system size, which implies that the conductivity of a\ndisordered system close to $p_c$ is not a simple material property as we are used to.\nWe therefore need to address the scaling behavior of the system in detail in order to\nunderstand the behavior of the conductivity and the conductance of the system.",
          "reading_order": 5
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            519,
            340,
            537
          ],
          "text": "9.7 Internal Distribution of Currents",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            555,
            520,
            618
          ],
          "text": "When we solve the flow problem on a percolation cluster, we find a set of currents\n$I_b=I_{i,j}$ for each bond $b=(i,\\, j)$ on the backbone. For all other bonds, the currents\nwill be identically zero. How can we describe the distribution of currents on the\nbackbone?",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            618,
            528,
            797
          ],
          "text": "For electrical flow, the conservation of energy is formulated in the expression:\n\\[RI^2=\\sum_b r_b I_b^2~, \\eqno(9.41)\\]\nwhere $R$ is the total resistance of the system, $I$ is the total current, $r_b$ is the resistivity\nof bond $b$ and $I_b$ is the current in bond $b$ . We can therefore rewrite the total resistance\n$R$ as\n\\[R=\\sum_b r_b(\\frac{I_b}{I})^2=\\sum_b r_b i_b^2~,\\eqno(9.42)\\]",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 164,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            58
          ],
          "text": "156",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            376,
            44,
            520,
            62
          ],
          "text": "9 Flow in Disordered Media",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            116
          ],
          "text": "where we have introduced the fractional current $i_b=I_b/I$ . We have written the\ntotal resistance as a sum of the square of the fractional currents in each of the bonds.",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            125,
            520,
            241
          ],
          "text": "The of Fractional Currents The fractional current $i_b$ is assigned to each\nbond of the backbone. We can describe the fractional currents by the probability\ndistribution for various values of $i_b$ by counting the number of bonds $n(i_b)$ having\nthe fractional current $i_b$ . The total number of bonds is the mass of the backbone:\n\\[\n    \\sum_b 1=M_B \\propto L^{D_B}~. \\eqno(9.43)\n  \\]",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            258,
            520,
            340
          ],
          "text": "The distribution of fractional currents is therefore given by $P(i_b)=n(i_b)/M_B$ . We\ncharacterize the distribution $P(i)$ through the moments of the distribution:\n$$\\langle i^{2q}\\rangle=\\frac{1}{M_B}\\sum_b i_b^{2q}=\\frac{1}{M_B}\\int i^{2q} n(i)di~.\\eqno(9.44)$$",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            358,
            520,
            387
          ],
          "text": "There is, unfortunately, no general way to simplify this relation, since we do not\nknow whether the function $n(i)$ has a simple scaling form.",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            403,
            520,
            537
          ],
          "text": "Moments of the Distribution of Currents However, we can address specific\nmoments of the distribution. We know that the mass of the backbone has a\nfractal scaling with exponent $D_B$ . This corresponds to the zero'th moment of the\ndistribution. We expect (or hypothesize) that at $p=p_c$ , the other moments has a\nscaling form:\n\\[\n    \\sum_b i^{2q}_b \\propto L^{y(q)}~. \\eqno(9.45)\n  \\]",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            546,
            421,
            564
          ],
          "text": "What can we say about the scaling exponents $y(q)$ for moment $q$",
          "reading_order": 7
        },
        {
          "label": "list",
          "bbox": [
            71,
            582,
            197,
            595
          ],
          "text": "• For $q=0$, the sum i",
          "reading_order": 8
        },
        {
          "label": "list",
          "bbox": [
            72,
            609,
            367,
            674
          ],
          "text": "$$\n\\sum _ { b } ( i _ { b } ^ { 2 } ) ^ { 0 } \\propto L ^ { y ( 0 ) } \\propto L ^ { D _ { B } } ~ ,\n$$\nthat is, $y ( 0 ) = D _ { B } $.",
          "reading_order": 9
        },
        {
          "label": "list",
          "bbox": [
            71,
            689,
            520,
            818
          ],
          "text": "• For $q\\rightarrow\\infty$ , the only terms that will be important in the sum are the terms where\n$i_b=1$ , because all other terms will be zero. The bonds with $i_b=1$ are the singly\nconnected bonds: all the current passes through these bonds. Therefore, we have\n$$\\sum_{b}(i^2_b)^\\infty\\propto L^{y(\\infty)}\\propto M_{SC}\\propto L^{Dsc}~,\\eqno(9.47)$$\nand we find that $y(\\infty)=D_{SC}$ .",
          "reading_order": 10
        }
      ]
    },
    {
      "page_number": 165,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            251,
            62
          ],
          "text": "9.7 Internal Distribution of Currents",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            511,
            58
          ],
          "text": "15",
          "reading_order": 1
        },
        {
          "label": "list",
          "bbox": [
            71,
            80,
            520,
            192
          ],
          "text": "• For $q=1$ , we find from ( 9.42 ) that the sum is given as the total resistance of the\ncluster\n$$\\sum_b (i^2_b)^1=R\\propto L^{\\bar{\\zeta}_R}~,$$\nwhich implies that $y(1)=\\tilde{\\zeta}_R$ .",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            206,
            520,
            313
          ],
          "text": "Multifractal Distribution The distribution of fractional currents is an example of a\nmulti-fractal distribution . The higher moments of this distribution have a non-trivial\nscaling relation\n$$M_q=\\langle i^{2q}\\rangle=\\frac{\\sum_b i_b^2}{M_B}\\propto L^{y(q)-D_B}~.~\\eqno{(9.49)}$$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            322,
            520,
            456
          ],
          "text": "Because each term in the sum $\\sum_b(i_b)^{2q}$ is monotonically decreasing in $q$ , the sum\nis also monotonically decreasing. We can therefore illustrate the curve $y(q)$ as in\nFig. 9.7 , where we see that $y(q)$ is a non-trivial function of $q$ . This is in contrast\nto a unifractal distribution . We have seen unifractals in e.g. cluster number density.\nThe $x=\\gamma(\\beta+1)/v$ moments of the cluster number density has the form $M_q~\\propto~\\xi^{xq}$ with . This means that all the moments are effectively described by a single\nexponent, $x$ . We call such distributions unifractal , whereas distributions where the\nrelationship is non-linear, such as for $y(q)$ , we call multifractal .",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            456,
            520,
            537
          ],
          "text": "In real resistor-networks, the case is even more complex, because the resistivity\nis due to impurities, and the impurities diffuse. Therefore, the fluctuations in the\nresistivity will also have a time-dependent part. This is the origin of thermal noise\nin the circuit. If we keep the total current $I$ constant, fluctuations in the resistivity\nwill lead to fluctuations in the voltage.",
          "reading_order": 5
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_165_figure_006.png)",
          "figure_path": "figures/percolation_studies_page_165_figure_006.png",
          "bbox": [
            72,
            573,
            528,
            744
          ],
          "reading_order": 6
        },
        {
          "label": "cap",
          "bbox": [
            72,
            761,
            520,
            788
          ],
          "text": "Fig. 9.7 Illustration of the exponents $y(q)$ characterizing the scaling of the moments of the\ndistribution of fractional currents, as a function $q$ , the order of the moment",
          "reading_order": 7
        }
      ]
    },
    {
      "page_number": 166,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            58
          ],
          "text": "158",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            376,
            44,
            520,
            62
          ],
          "text": "9 Flow in Disordered Media",
          "reading_order": 1
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            80,
            242,
            98
          ],
          "text": "9.8 Real Conductivity",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            116,
            520,
            215
          ],
          "text": "So far we have addressed conductivity of a percolation cluster. That is a system\nwhere the local conductances (or permeabilities) are either zero or a given constant\nconductance. That is, we have studied a system with local conductances $G_{i,j}$ so that\n$$G_b=G_{i,j}=\\left\\{\\begin{array}{l}1 \\text { with probability } p \\\\ 0 \\text { with probability } 1-p\\end{array}\\right..\\qquad\\qquad\\qquad(9.50)$$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            232,
            520,
            313
          ],
          "text": "However, in practice, we want to address systems with some distribution of conduc-\ntances, such as a binary mixture of good and bad conductors, with conductances:\n\\[G_b = G_{i,j} = \\left\\{\\begin{array}{l}\nG_2 \\\\\nG_1 \\\\\n\\end{array}\\right.\\text{with probability $p$}\\quad$.}",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            322,
            520,
            430
          ],
          "text": "Superconductor Networks However, in order to address this problem, let us\nfirst look at the conjugate problem to the random resistor network, the random\nsuperconductor network. We will assume that the conductances are\n\\[G_b=G_{i,j}= \\left\\{\\begin{array}{l}\n    \\infty  ~~\\text{with probability}~p\\\\\n    1~~\\text{with probability}~1-p\n\\end{array}\\right..\\qquad(9.52)\\]",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            439,
            520,
            555
          ],
          "text": "In this case, we expect the conductance to diverge when $p$ approaches $p_c$ from\nbelow, and that the conductance is infinite when $p>p_c$ . It can be shown that the\nbehavior for the random superconductor network is similar to that of the random\nresistor network, but that the exponent describing the divergence of the conductance\n(and consequently conductivity) when $p$ approaches $p_c$ is $s$ :\n\\[G\\propto (p_c-p)^{-s}~,\\eqno{(9.53)}\\]",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            573,
            520,
            689
          ],
          "text": "Combining the Two Approaches How can we address both these problems? For\nany system with a finite smallest conductance, $G_<$ , we can always use the smaller\nconductance as the unit for conductance, and write the functional form for the\nconductance of the whole system as\n\\[ G(G_1,G_2,p)=(\\frac{G(\\frac{G_1}{G_1},\\frac{G_2}{G_1},p)}{G_1})=G(\\frac{G_2}{G_1},p)~,\\eqno{(9.54)}\\]",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            698,
            520,
            801
          ],
          "text": "We will make a scaling ansatz for the general behavior of $G$ :\n\\[ G=G_2(p-p_c)^{\\mu}f_{\\pm}(\\frac{(\\frac{G_1}{G_2})}{(p-p_c)^y})\\;,\\]\nwhere the exponent $y$ is yet to be determined.",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 167,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            180,
            62
          ],
          "text": "9.8 Real Conductivity",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            520,
            58
          ],
          "text": "159",
          "reading_order": 1
        },
        {
          "label": "list",
          "bbox": [
            80,
            80,
            520,
            128
          ],
          "text": "The random resistor network we studied above corresponds to $G_1\\to0$ , and\n$G_2=c$ . In this case, we retrieve the scaling behavior for $p$ close to $p_c$ , by\nassuming that $f_+(0)$ is a constant.",
          "reading_order": 2
        },
        {
          "label": "list",
          "bbox": [
            80,
            128,
            520,
            250
          ],
          "text": "For the random superconductor network , the conductances are $G_2\\rightarrow\\infty$ , and\n$G_1={\\rm const}..$ We will therefore need to construct $f_-(u)$ in such a way that the\ninfinite conductance is canceled from the prefactor. That is, we need $f_-(u)\\propto u$ .\nWe insert this into ( 9.55 ) , getting\n$$G\\propto G_2(p-p_c)^\\mu\\frac{\\frac{G_1}{G_2}}{(p-p_c)^y}\\propto G_1|p-p_c|^{\\mu+y}~.\\eqno(9.56)$$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            259,
            520,
            313
          ],
          "text": "Because we know that the scaling exponent should be $\\mu+y=-s$ in this limit, we\nhave determined $y$ : $y=-\\mu-s$ , where $\\mu$ and $s$ are determined from the random\nresistor and random superconductor networks respectively.",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            322,
            520,
            439
          ],
          "text": "Finite $G_2$ and $G_1$ When $p\\rightarrow p_c$ the conductance $G$ should approach a constant\nnumber when both $G_2$ and $G_1$ are finite. However, $p\\rightarrow p_c$ corresponds to the\nargument $x\\rightarrow+\\infty$ in the function $f_{\\pm}(x)$ . The only way to ensure that the total\nconductance is finite, is to require that the two dependencies on $(p-p_c)$ cancel\nexactly. We achieve this by selecting\n$$f_{\\pm}(x)\\propto x^{\\mu/(\\mu+s)}~.\\eqno(9.57)$$",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            456,
            412,
            600
          ],
          "text": "We can insert this relation into ( 9.55 ), getting\n\\[G=G_2|p-p_c|^{\\mu}(\\frac{\\frac{G_1}{G_2}}{|p-p_c|^{\\mu+s}})^{\\mu/(\\mu+s)}~,\\]\nwhich results in\n\\[G=G_2(\\frac{G_1}{G_2})^{\\frac{\\mu}{\\mu+s}}~.\\]",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            609,
            376,
            672
          ],
          "text": "This expression can again be simplified to\n\\[G(p=p_c) = G^{\\frac{s}{\\mu+s}}_2 G^{\\frac{\\mu}{\\mu+s}}_1~,\\]",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            484,
            654,
            520,
            665
          ],
          "text": "(9.60)",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            72,
            680,
            386,
            734
          ],
          "text": "In two dimensions, $\\mu=s\\simeq1.3$ , and the relation becomes\n$$G\\propto(G_{1}G_{2})^{\\frac{1}{2}}~,$$",
          "reading_order": 9
        }
      ]
    },
    {
      "page_number": 168,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            90,
            58
          ],
          "text": "160",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            376,
            44,
            520,
            62
          ],
          "text": "9 Flow in Disordered Media",
          "reading_order": 1
        },
        {
          "label": "sec",
          "bbox": [
            72,
            80,
            135,
            98
          ],
          "text": "Exercises",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            116,
            520,
            179
          ],
          "text": "Exercise 9.1 (Density of the Backbone) The backbone of a spanning cluster is\nthe union of all self-avoiding walks from one side of the cluster to the opposite.\nThe backbone corresponds to the sites the contribute to the flow conductivity of the\nspanning cluster. The remaining sites are the dangling ends.",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            179,
            520,
            227
          ],
          "text": "$P_B=M_B/L^d$ We call the mass of the backbone $M_B$ , and the density of the backbone , where $L$ is the system size, and $d$ the dimensionality of the percolation\nsystem. Here, we will study two-dimensional site percolation.",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            241,
            520,
            340
          ],
          "text": "(a) Argue that the functional form of $P_B(p)$ when $p\\rightarrow p^+_c$ is\n$$P_B(p)=P_0(p-p_c)^x~,\\eqno{(9.62)}$$\nand find an expression for the exponent $x$ . You can assume that the fractal\ndimension of the backbone, $D_B$ , is known.",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            71,
            340,
            520,
            388
          ],
          "text": "(b) Assume that the functional form of $P_B(p)$ when $p\\to p^+_c$ and $\\xi\\ll L$ is\n$$P_B(p)=P_0(p-p_c)^x~,\\eqno{(9.63)}$$",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            89,
            403,
            520,
            439
          ],
          "text": "Determine the exponent $x$ by numerical experiment. If needed, you may use that\n$v=4 / 3$.",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            455,
            520,
            485
          ],
          "text": "Exercise 9.2 (Flow on Fractals) Use the example programs from the text to study\nfluid flow in a percolation system.",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            72,
            501,
            520,
            549
          ],
          "text": "(a) Run the example programs provided in the text to visualize the currents on the\nspanning cluster.\n(b) Modify the program to find the backbone and the dangling ends of the spanning",
          "reading_order": 9
        },
        {
          "label": "para",
          "bbox": [
            71,
            549,
            520,
            564
          ],
          "text": "这是一篇與中国政治人物相關的小作品。 你可以编辑或修订扩充其内容。",
          "reading_order": 10
        },
        {
          "label": "para",
          "bbox": [
            72,
            564,
            494,
            582
          ],
          "text": "(c) Use the program to find the singly connected bonds in the spanning cluster",
          "reading_order": 11
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            600,
            224,
            614
          ],
          "text": "Exercise 9.3 (Conductivity)",
          "reading_order": 12
        },
        {
          "label": "para",
          "bbox": [
            72,
            627,
            520,
            663
          ],
          "text": "(a) Find the conductivity as a function of $p-p_{c}$. Determine the exponent $\\bar{\\zeta}_{R}$ by\ndirect measurement.",
          "reading_order": 13
        },
        {
          "label": "para",
          "bbox": [
            71,
            663,
            431,
            680
          ],
          "text": "(b) Find the conductivity at $p=p_c$ as a function of system size $L$ .",
          "reading_order": 14
        },
        {
          "label": "para",
          "bbox": [
            72,
            697,
            520,
            743
          ],
          "text": "Exercise 9.4 (Current Distribution) Use the example programs from the text to\nfind the currents $I_b$ in each bonds $b$ on a spanning cluster at $p=p_c$ , $p=0.585$ ,\nand $p=0.60$ .",
          "reading_order": 15
        }
      ]
    },
    {
      "page_number": 169,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            116,
            58
          ],
          "text": "Exercises",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            511,
            58
          ],
          "text": "16",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            359,
            98
          ],
          "text": "(a) Find the total current I going through the system.",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            107,
            98,
            466,
            126
          ],
          "text": "In the following we will study the normalized currents, $i_b=I_b/I$ .\nand the distribution $P(i)$ of the normalized currents.",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            132,
            296,
            143
          ],
          "text": "(c) Measure moments of the distribution.",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            161,
            520,
            209
          ],
          "text": "Exercise 9.5 (Bivariate Porous Media) Rewrite the programs in the text to study\na bivariate distribution of conductances. That is, for each site, the conductance is 1\nwith probability $p$ and $g_0<1$ with probability $1-p$ .",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            224,
            358,
            241
          ],
          "text": "(a) Visualize the distribution of currents for $g_0=0.1$",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            71,
            241,
            403,
            259
          ],
          "text": "(b) Find the conductivity $g(p)$ for $\\sigma_{0}=0.1,0.01$, and 0.001 .",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            72,
            259,
            260,
            277
          ],
          "text": "(c) Plot $\\sigma\\left(p_{c}\\right)$ as a function of $\\sigma_{0}$.",
          "reading_order": 9
        },
        {
          "label": "para",
          "bbox": [
            71,
            277,
            520,
            306
          ],
          "text": "(d) (Advanced) Can you find a way to rescale the conductivities to produce a data-\ncollapse?",
          "reading_order": 10
        },
        {
          "label": "para",
          "bbox": [
            72,
            636,
            520,
            701
          ],
          "text": "Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0\nInternational License ( http://creativecommons.org/licenses/by/4.0/ ), which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as long as you give appropriate\ncredit to the original author(s) and the source, provide a link to the Creative Commons license and\nindicate if changes were made.",
          "reading_order": 11
        },
        {
          "label": "para",
          "bbox": [
            72,
            701,
            520,
            770
          ],
          "text": "The images or other third party material in this chapter are included in the chapter’s Creative\nCommons license, unless indicated otherwise in a credit line to the material. If material is not\nincluded in the chapter’s Creative Commons license and your intended use is not permitted by\nstatutory regulation or exceeds the permitted use, you will need to obtain permission directly from\nthe copyright holder.",
          "reading_order": 12
        }
      ]
    },
    {
      "page_number": 170,
      "elements": [
        {
          "label": "sec",
          "bbox": [
            72,
            98,
            439,
            125
          ],
          "text": "Elastic Properties of Disordered Media",
          "reading_order": 0
        },
        {
          "label": "sec",
          "bbox": [
            502,
            98,
            555,
            143
          ],
          "text": "10",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            304,
            520,
            370
          ],
          "text": "There are various physical properties that we may be interested in for a disordered\nmaterial. In the previous chapter, we studied flow problems in disordered materials\nusing the percolation system as a model disordered material. In this chapter we will\naddress mechanical properties of the disordered material.",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            370,
            520,
            483
          ],
          "text": "We will address the behavior of the disordered material in the limit of fractal\nscaling. In this limit we expect material properties such as Young's modulus to\ndisplay a non-trivial dependence on system size. That is, we will expect material\nproperties such as Young's modulus to have an explicit system size dependence. We\nwill use the terminology and techniques already developed to study percolation to\naddress the mechanical behavior of disordered systems such as the coefficients of\nelasticity [ 4 , 11 , 20 , 28 , 40 ]",
          "reading_order": 3
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            517,
            255,
            532
          ],
          "text": "10.1 Rigidity Percolation",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            546,
            520,
            645
          ],
          "text": "What are the elastic properties of a percolation system? First, we need to decide on\nhow to convert a percolation system into an elastic system. We will start by modeling\nan elastic material as a bond lattice, where each bond represents a local elastic\nelement. The element will in general have resistance to stretching and bending.\nSystems with only stretching stiffness are termed central force lattices. Here, we\nwill address systems with both stretching and bending stiffness.",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            663,
            520,
            761
          ],
          "text": "Models for Stretching and Bending Stiffness We can formulate the effect of\nbending and stretching through the elastic energy of the system. The energy will\nhave terms that depend on the elongation of bonds — these will be the terms that\nare related to stretching resistance. In addition, there will be terms related to the\nbending of bonds. Here we will introduce the bending terms through the angles\nbetween bonds. For any two bonds connected to the same site, there will be an",
          "reading_order": 6
        },
        {
          "label": "foot",
          "bbox": [
            72,
            806,
            396,
            845
          ],
          "text": "© The Author(s) 2024\nA. Malthe-Sørenssen, Percolation Theory Using Python, Lecture Notes\nin Physics 1029, https://doi.org/10.1007/978-3-031-59900-2_10",
          "reading_order": 7
        },
        {
          "label": "foot",
          "bbox": [
            501,
            806,
            520,
            816
          ],
          "text": "163",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 171,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            58
          ],
          "text": "164",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            321,
            44,
            512,
            62
          ],
          "text": "0 Elastic Properties of Disordered Medi",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_171_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_171_figure_002.png",
          "bbox": [
            287,
            80,
            520,
            304
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            80,
            215,
            188
          ],
          "text": "Fig. 10.1 Illustration of the\ninitial bond lattice (dashed,\ngray), and the deformed bond\nlattice. Three nodes $i$ , $j$ , $k$ are\nillustrated. The angle $\\phi_{ijk}$ is\nshown. The displacements $\\mathbf{u}_i$\nand $\\mathbf{u}_j$ are shown respectively\nwith cyan vectors",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            338,
            520,
            501
          ],
          "text": "energy associated with changes in the angle of the bond. This can be expressed as\n\\[U=\\sum_{ij} \\frac{1}{2} k_{ij}(\\mathbf{u}_i-\\mathbf{u}_j)^2+\\sum_{ijk} \\frac{1}{2} \\kappa_{ijk} \\phi_{ijk}^2~,\\tag*{$10.1$}\\]\nwhere $U$ is the total energy, the sums are over all particle pairs $ij$ or all particle\ntriplets $ijk$ . The force constant is $k_{ij}=k$ for bonds in contact and zero otherwise,\nand $\\kappa_{ijk}=\\kappa$ for triplets with a common vertice, and zero otherwise. The vector\n$\\mathbf{u}_i$ gives the displacement of node $i$ from its equilibrium position. The various\nquantities are illustrated in Fig. 10.1",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            519,
            520,
            645
          ],
          "text": "Let Modulus Let us address the effective elastic behavior of the percolation\nsystem using a material property such as Young's modulus, $E$ , or the shear modulus,\n$G$ . Let us consider a three-dimensional sample with cross-sectional area $A=L^2$ and\nlength $L$ . Young's modulus, $E$ , relates the tensile stress, $\\sigma_{zz}$ , applied normal to the\nsurface with area $A$ to the elongation $\\Delta L$ in the $z$ -direction.\n$$\\sigma_{zz}=\\frac{F_z}{A}=E\\frac{\\Delta L_z}{L}~,\\eqno(10.2)$$",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            654,
            520,
            725
          ],
          "text": "We can therefore write the relation between the force $F_{z}$ and the elongation $\\Delta L_{z}$ as\n$$F_{z}=\\frac{E A}{L} \\Delta L=\\frac{E L^{2}}{L} \\Delta L=L^{d-2} E \\Delta L .\\qquad(10.3)$$",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            734,
            520,
            782
          ],
          "text": "We recognize this as a result similar to the relation between the conductance and\nthe conductivity of the sample, and we will call $K=L^{d-2}E$ the compliance of the\nsystem. We recognize this as being similar to the spring constant of a spring.",
          "reading_order": 7
        }
      ]
    },
    {
      "page_number": 172,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            197,
            62
          ],
          "text": "10.1 Rigidity Percolation",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            520,
            58
          ],
          "text": "165",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            193
          ],
          "text": "Elastic Properties When $p<p_c$ What happens to the compliance of the system\nas a function of $p$ ? When $p<p_c$ there are no connecting paths from one side\nto another, and the compliance will therefore be zero. It requires zero force $F_z$\nto generate an elongation $\\Delta L_z$ in the system. Notice that we are only interested\nin the infinitesimal effect of deformation. If we compress the sample, we will of\ncourse eventually generate a contacting path, but we are only interested in the initial\nresponse of the system.",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            206,
            520,
            403
          ],
          "text": "Elastic Properties When $p>p_c$ When $p\\geq p_c$ there will be at least one\npath connecting the two edges. For a system with a bending stiffness, there will\nbe a load-bearing path through the system, and the deformation $\\Delta L_z$ of the system\nrequires a finite force, $F_z$ . The compliance $K$ will therefore be larger than zero. We\nhave therefore established that for a system with bending stiffness, the percolation\nthreshold for rigidity coincides with the percolation threshold for connectivity. For\na central force lattice, we know that the spanning cluster at $p_c$ will contain may\nsingly connected bonds. These bonds will be free to rotate, and as a result a central\nforce network will have a rigidity percolation threshold which is higher than the\nconnectivity threshold. Indeed, rigidity percolation for central force lattices will\nhave very high percolation thresholds in three dimensions and higher. Here, we will\nonly focus on lattices with bond bending terms.",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            421,
            520,
            582
          ],
          "text": "Behavior of E Close to p c Based on our experience with percolation systems, we\nmay hypothesize that Young's modulus will follow a power-law in $(p-p_c)$ when\n$p$ approaches $p_c$ :\n\\[E \\propto \\begin{cases}0 & \\text{for } p<p_c\\\\ (p-p_c)^\\tau & \\text{for } p>p_c\\end{cases}.\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:defnocounter2strut}\\]\nwhere $\\tau$ is an exponent describing the elastic system. We will now use our\nknowledge of percolation to show that this behavior is indeed expected, and to\ndetermine the value of the exponent $\\tau$ .",
          "reading_order": 4
        },
        {
          "label": "sec",
          "bbox": [
            72,
            609,
            287,
            630
          ],
          "text": "Developing a Theory for $E(p,L)$",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            645,
            520,
            726
          ],
          "text": "Let us address the Young's modulus $E(p,L)$ of a percolation system with occu-\npation probability $p$ and a system size $L$ . We could also write $E$ as a function\nof the correlation length $\\xi=\\xi(p)$ , so that $E=E(\\xi,L)$ . Young's modulus is\nin general related to the compliance through $E(\\xi,L)=K(\\xi,L)L^{d-2}$ . We can\ntherefore address the compliance of the system and then calculate Young's modulus.",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            743,
            520,
            791
          ],
          "text": "We the System into Boxes of Size ξ We will follow an approach similar to\nwhat we used to derive the behavior of P ( p, L ) . First, we address the case when the\ncorrelation length $\\xi \\ll L$ . In this case, we can subdivide the L d system into boxes",
          "reading_order": 7
        }
      ]
    },
    {
      "page_number": 173,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            58
          ],
          "text": "166",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            313,
            44,
            520,
            62
          ],
          "text": "10 Elastic Properties of Disordered Media",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_173_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_173_figure_002.png",
          "bbox": [
            251,
            80,
            520,
            322
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            80,
            208,
            227
          ],
          "text": "Fig. 10.2 Illustration of\nsubdivision of a system with\n$p=0.60$ into regions with a\nsize corresponding to the\ncorrelation length, $\\xi$ . The\nbehavior inside each box is as\nfor a system at $p=p_c$ ,\nwhereas the behavior of the\noverall system is that of a\nhomogeneous system of\nboxes of linear size $\\xi$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            348,
            520,
            396
          ],
          "text": "of linear size $\\xi$ as illustrated in Fig. 10.2 . There will be $(L/\\xi)^d$ such boxes. On this\nscale the system is homogeneous. Each box will have a compliance $K(\\xi,\\xi)$ , and\nthe total compliance will be $K(\\xi,\\, L)$ .",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            412,
            520,
            573
          ],
          "text": "Compliance of the Combined System We know that the total compliance of $n$\nelements in series is $1/n$ times the compliance of a single element. You can easily\nconvince yourself of this addition rule for spring constants, by addressing two\nsprings in series. Similarly, we know that adding $n$ elements in parallel will make the\ntotal system $n$ times stiffer, that is, the compliance will be $n$ times the compliance\nof an individual element. The total compliance $K(\\xi,L)$ of this system of $(L/\\xi)^d$\nboxes is therefore:\n$$ K(\\xi,L)=K(\\xi,\\xi)(\\frac{L}{\\xi})^{d-2}~. \\eqno{(10.5)}$$",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            582,
            404,
            654
          ],
          "text": "Young’s modulus can then be found as\n\\[E(\\xi,L)=L^{-(d-2)}K(\\xi,L)=\\frac{K(\\xi,\\xi)}{\\xi^{d-2}}~.\\]",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            663,
            520,
            726
          ],
          "text": "In order to progress further we need to find the compliance $K(\\xi,\\xi)$ . This is the\ncompliance of the percolation system at $p=p_c$ when the system size $L$ is equal\nto the correlation length $\\xi$ . We are therefore left with the problem of finding the\ncompliance of the spanning cluster at $p=p_c$ as a function of system size $L$ .",
          "reading_order": 7
        }
      ]
    },
    {
      "page_number": 174,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            197,
            62
          ],
          "text": "10.1 Rigidity Percolation",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            502,
            50,
            520,
            58
          ],
          "text": "167",
          "reading_order": 1
        },
        {
          "label": "sec",
          "bbox": [
            72,
            80,
            376,
            98
          ],
          "text": "Compliance of the Spanning Cluster at $p=p_{c}\\,$",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            116,
            520,
            179
          ],
          "text": "Again, we expect from experience that the compliance will scale with the system\nsize with a dimension $\\tilde{\\zeta}_K$ :\n$$ K \\propto L^{\\bar{\\zeta}_K} \\; . \\eqno(10.7)$$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            197,
            520,
            245
          ],
          "text": "We will follow our now standard approach: We assume a scaling behavior, establish\na set of bounds for $K$ , which will also serve as a proof of the scaling behavior of $K$ ,\nand then use this result to develop a general theory for $K(p,L)$ .",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            259,
            520,
            456
          ],
          "text": "Energy, Force and Elongation of the System We will use arguments based on the\ntotal energy of the system. The total energy of a system subjected to a force $F=F_z$\nresulting in an elongation $\\Delta L$ is:\n$$U=\\frac{1}{2}K(\\Delta L)^2~,\\eqno(10.8)$$\nwhere the elongation $\\Delta L$ is related to the force $F$ through, $\\Delta L~=~F/K$ .\nConsequently,\n$$U=\\frac{1}{2}K(\\frac{F}{K})^2=\\frac{1}{2}\\frac{F^2}{K}~.\\eqno(10.9)$$",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            465,
            515,
            494
          ],
          "text": "We can therefore relate the elastic energy of a system subjected to the force $F$\ndirectly to the compliance of that system.",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            510,
            520,
            689
          ],
          "text": "Upper Bound for the Compliance Our arguments will be based on the geomet-\nrical picture we have of the spanning cluster when $p=p_c$ . The cluster consists\nof singly connected bonds, blobs, and dangling ends. The dangling ends do not\ninfluence the elastic behavior, and can be ignored in our discussion. It is only the\nbackbone that contribute to the elastic properties of the spanning cluster. We can\nfind an upper bound for the compliance by considering the singly connected bonds.\nThe system consists of blobs and singly connected bonds in series. The compliance\nmust include the effect of all the singly connected bonds in series. However, adding\nthe blobs in series as well will only contribute to lowering the compliance. We will\ntherefore get an upper bound on the compliance, by assuming all the blobs to be\ninfinitely stiff, and therefore only include the effects of the singly connected bonds.",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            689,
            520,
            736
          ],
          "text": "Let us therefore study the elastic energy in the singly connected bonds when the\ncluster is subjected to a force $F$ . The energy, $U$ , can be decomposed in a stretching\npart, $U_s$ , and a bending part, $U_b$ : $U=U_s+U_b$ .",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 175,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            58
          ],
          "text": "168",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            313,
            44,
            520,
            62
          ],
          "text": "10 Elastic Properties of Disordered Media",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            215
          ],
          "text": "For a singly connected bond from site $i$ to site $j$ , the change in length, $\\delta \\ell_{ij}$ , due\nto the applied force $F$ is $\\delta \\ell_{ij}=F/k$ , where $k$ is the force constant for a single bond.\nThe energy due to stretching, $U_s$ , is therefore\n$$\nU_s=\\sum_{ij}\\frac{1}{2} k\\delta \\ell^2_{ij}=\\sum_{ij}\\frac{1}{2} k(\\frac{F}{k})^2=\\frac{1}{2}\\frac{M_{SC}}{k} F^2~,\n$$\nwhere $M_{SC}$ is the mass of the singly connected bonds.",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            215,
            528,
            448
          ],
          "text": "We can find a similar expression for the bending terms. For a bond between sites $i$\nand $j$ , the change in angular orientation, $\\delta \\phi_{ij}$ is due to the torque $T=r_i F$ , where $r_i$\nis the distance to bond $i$ in the direction normal to the direction of the applied force\n$F$ : $\\delta \\phi_{ij}= T/\\kappa$ . The contribution from bending to the elastic energy is therefore\n$$U_b=\\sum_{ij}\\frac{1}{2}\\kappa(\\delta \\phi_{ij})^2=\\frac{1}{2}\\sum_{ij}\\kappa(\\frac{r_i F}{\\kappa})^2=\\frac{1}{2\\kappa}M_SCR_{SC}^2F^2~,\\eqno(10.11)$$\nwhere\n$$R_{SC}^2=\\frac{1}{M_{SC}}\\sum_{ij}r_i^2~,$$\nwhere the sum is taken over all the singly connected bonds.",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            448,
            520,
            627
          ],
          "text": "The elastic energy of the singly connected bonds is therefore:\n\\begin{equation}  U_{SC}=(\\frac{1}{2k}+\\frac{R^2_{SC}}{2\\kappa})M_{SC}F^2~,\\label{eq:SPC}\\end{equation} and the compliance of the singly connected bonds is\n\\begin{equation} K_{SC}=\\frac{F^2}{2U}=\\frac{1}{(1/k+R^2_{SC}/\\kappa)M_{SC}}~.\\label{eq:SPC}\\end{equation}",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            644,
            520,
            771
          ],
          "text": "Lower Bound for the Compliance We can make a similar argument for a lower\nbound for the compliance $K$ of the system. The minimal path on the spanning cluster\nprovides the minimal compliance. The addition of any bonds in parallel will only\nmake the system stiffer, and therefore increase the compliance. We can determine\nthe compliance of the minimal path by calculating the elastic energy of the minimal\npath. We can make an identical argument to what we did above, but we need to\nreplace $M_{SC}$ with the mass, $M_{min}$ , of the minimal path, and the radius of gyration\n$R^2_{SC}$ with the radius of gyration of the bonds on the minimal path $R^2_{min}$ .",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            771,
            520,
            806
          ],
          "text": "Kantor [ 20 ] has provided numerical evidence that both $R_{min}^2$ and $R_{SC}^2$ are\nproportional to $\\xi^2$ . When we are studying the spanning cluster at $p=p_c$",
          "reading_order": 6
        }
      ]
    },
    {
      "page_number": 176,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            197,
            62
          ],
          "text": "10.1 Rigidity Percolation",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            520,
            58
          ],
          "text": "169",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            128
          ],
          "text": "this corresponds to $R_{min}$ and $R_{SC}$ being proportional to $L$ . This shows that the\ndominating term for the energy is the bending and not the stretching energy when $p$\nis approaching $p_c$ .",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            143,
            520,
            295
          ],
          "text": "Bounded Expression for the Compliance K We have therefore determined the\nscaling relation\n\\[K_{min} \\leq K \\leq K_{SC}~,\\eqno(10.15)\\]\nwhere we have found that when $L \\gg 1$ , $K_{min} \\propto L^{-(D_{min}+2)}$ and $K_{SC} \\propto L^{-(D_{SC}+2)}$ . That is:",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            304,
            520,
            394
          ],
          "text": "Because $K(L)$ is bounded by two power-laws in $L$ (for all values of $L$ ), we have also\ndemonstrated that $K(L)$ also is a power-law in $L$ with an exponent $\\bar{\\zeta}_K$ satisfying the\nrelation\n$$-(D_{min}+2)\\leq \\bar{\\zeta}_K\\leq -(D_{SC}+2)~.\\eqno(10.17)$$",
          "reading_order": 4
        },
        {
          "label": "sec",
          "bbox": [
            72,
            420,
            287,
            439
          ],
          "text": "Finding Young’s Modulus E(p, L)",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            448,
            520,
            537
          ],
          "text": "This scaling relation gives us $K(p_c,L)$ . We use this expression to find $K(\\xi,\\xi)$ , the\ncompliance of a system of size $\\xi$ from ( 10.6 ):\n$$E(\\xi,L)=\\frac{K(\\xi,\\xi)}{\\xi^{d-2}}\\propto \\frac{\\xi^{\\tilde{\\zeta} K}}{\\xi^{d-2}}\\propto \\xi^{\\tilde{\\xi} \\bar{\\xi} \\bar{\\kappa}-(d-2)}.\\eqno(10.18)$$",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            546,
            520,
            609
          ],
          "text": "We have therefore found a relation for the scaling exponent $\\tau$ :\n$$E(p,L)=\\xi^{-(d-2-\\bar{\\zeta}_K)}\\propto (p-p_c)^{(d-2-\\bar{\\zeta}_K)v}\\propto (p-p_c)^\\tau~.\\eqno(10.19)$$",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            618,
            520,
            664
          ],
          "text": "The exponent $\\tau$ is therefore in the range:\n$$(d-2+D_{SC}+2)v\\leq \\tau\\leq (d-2+D_{min}+2)v~,\\eqno(10.20)$$",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            72,
            680,
            520,
            734
          ],
          "text": "Bounds on the Exponent τ The resulting bounds on the scaling exponents are:\n(DSC + 2) v ≤ τ ≤ (Dmin + 2) v, (10.21)",
          "reading_order": 9
        },
        {
          "label": "para",
          "bbox": [
            72,
            743,
            520,
            797
          ],
          "text": "For two-dimensional percolation the exponents are approximately\n\\[3.41 \\leq \\tau \\leq 3.77~,\\addtocounter{equation}{1}\\tag{\\theequation}\\label{equ:f20bound}\\]",
          "reading_order": 10
        }
      ]
    },
    {
      "page_number": 177,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            90,
            58
          ],
          "text": "170",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            321,
            44,
            520,
            62
          ],
          "text": "0 Elastic Properties of Disordered Media",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            286
          ],
          "text": "Similarity Between the Flow and the Elastic Problems We see that the bounds\nare similar to the bounds we found for the exponent $\\tilde{\\zeta}_R$ . This similarity lead Sahimi\n[ 29 ] and Roux [ 27 ] to conjecture that the elastic coefficient $E$ and the conductivity\n$g$ is related through\n$$\\frac{E}{g} \\propto \\xi^{-2} \\;. \\eqno(10.23)$$\nand therefore that\n$$\\tau=\\mu+2v=(d+\\tilde{\\zeta}_R)v\\;.\\eqno(10.24)$$\nwhich is well supported by numerical studies.",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            286,
            520,
            332
          ],
          "text": "In the limit of high dimensions, $d\\geq6$ , the relation $\\tau=\\mu+2v=4$ becomes\nexact. However, we can use as a rule of thumb that the exponent $\\tau\\simeq4$ in all\ndimensions $d\\geq2$ .",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            636,
            520,
            701
          ],
          "text": "Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0\nInternational License ( http://creativecommons.org/licenses/by/4.0/ ), which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as long as you give appropriate\ncredit to the original author(s) and the source, provide a link to the Creative Commons license and\nindicate if changes were made.",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            701,
            518,
            770
          ],
          "text": "The images or other third party material in this chapter are included in the chapter’s Creative\nCommons license, unless indicated otherwise in a credit line to the material. If material is not\nincluded in the chapter’s Creative Commons license and your intended use is not permitted by\nstatutory regulation or exceeds the permitted use, you will need to obtain permission directly from\nthe copyright holder.",
          "reading_order": 5
        }
      ]
    },
    {
      "page_number": 178,
      "elements": [
        {
          "label": "sec",
          "bbox": [
            72,
            98,
            358,
            116
          ],
          "text": "Diffusion in Disordered Media",
          "reading_order": 0
        },
        {
          "label": "sec",
          "bbox": [
            502,
            98,
            546,
            134
          ],
          "text": "11",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            304,
            520,
            483
          ],
          "text": "In this chapter we will study diffusional transport in disordered media. We can\nmodel diffusional transport either by solving the diffusion equation or by studying\nthe time developments of random walks — both approaches produce the same results.\nWe will use the statistical approach and study how random walkers spread with time\nin free space as well as on percolation clusters. We will introduce a scaling theory\nfor the behavior of this process in both space and time — extending our previous\nscaling approaches and proving us with new tools and insights. We will do this\nin several steps, starting with a brief introduction to random walks and diffusion\nin uniform media, then introduce a computational model for random walks on the\npercolation cluster, and finally apply our full set of tools to develop scaling theories\nfor the observed behavior [ 13 , 15 , 26 ] .",
          "reading_order": 2
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            510,
            484,
            531
          ],
          "text": "11.1 Diffusion and Random Walks in Homogeneous Media",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            546,
            520,
            612
          ],
          "text": "A typical example of a random walk is the random motion of a small dust particle\ndue to random collisions with air molecules, a process called Brownian motion.\nRandom walks are general processes that we often use as physical, theoretical or\nconceptual models.",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            627,
            520,
            764
          ],
          "text": "A Two-Dimensional Random Walk If a random walker starts at $\\mathbf{r}=0$ , its position\n$\\mathbf{r}_n$ after $n$ steps can be written as\n$$\\mathbf{r}_n=\\mathbf{r}_0+\\sum_{i=1}^n\\mathbf{u}_i~,\\eqno(11.1)$$\nwhere $\\mathbf{u}_i$ is step $i$ . We will usually assume that the steps $\\mathbf{u}_i$ are independent and\nisotropically distributed.",
          "reading_order": 5
        },
        {
          "label": "foot",
          "bbox": [
            72,
            806,
            396,
            845
          ],
          "text": "© The Author(s) 2024\nA. Malthe-Sørenssen, Percolation Theory Using Python, Lecture Notes\nin Physics 1029, https://doi.org/10.1007/978-3-031-59900-2_11",
          "reading_order": 6
        },
        {
          "label": "foot",
          "bbox": [
            501,
            806,
            520,
            816
          ],
          "text": "171",
          "reading_order": 7
        }
      ]
    },
    {
      "page_number": 179,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            50,
            89,
            62
          ],
          "text": "172",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            358,
            44,
            520,
            62
          ],
          "text": "1 Diffusion in Disordered Media",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_179_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_179_figure_002.png",
          "bbox": [
            72,
            80,
            520,
            268
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            277,
            439,
            295
          ],
          "text": "Fig. 11.1 Plots of 10 random walks of size $n=100$ (left) and $n=1000$ (right)",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            322,
            520,
            421
          ],
          "text": "Generating a Random Walk We can generate an example of random walk by\nselecting $\\mathbf{u}_i=(x_i,y_i)$ , where $x_i$ and $y_i$ are selected from e.g. a uniform random\ndistribution from $-1$ to $1$ . The following program calculates and visualizes a random\nwalk starting from the origin. The resulting path is shown in Fig. 11.1 . We notice\nthat the random walker spreads out gradually, leaving behind a trace with a complex\ngeometry.",
          "reading_order": 4
        },
        {
          "label": "code",
          "bbox": [
            79,
            439,
            291,
            519
          ],
          "text": "import numpy as np\nimport matplotlib.pyplot as plt\nn = 100\nu = 2*np.random.rand(n,2)-1\nr = np.cumsum(u,axis=0)\nplt.plot(r[:,0],r[:,1])",
          "reading_order": 5
        },
        {
          "label": "sec",
          "bbox": [
            72,
            561,
            415,
            576
          ],
          "text": "Theory for the Time Development of a Random Walk",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            591,
            520,
            761
          ],
          "text": "We can develop a theory for the position $\\mathbf{r}_n$ as a function of the number of steps $n$ .\nFor simplicity, we start the walker at the origin, so that $\\mathbf{r}_0=0$ . First, we see find the\naverage position after $n$ steps:\n$$\\langle \\mathbf{r}_n \\rangle = \\langle \\sum_{i=1}^n \\mathbf{u}_n \\rangle = \\sum_{i=1}^n \\langle \\mathbf{u}_i \\rangle = \\mathbf{0}~, \\eqno(11.2)$$\nwhere we have used that since $\\mathbf{u}_i$ are isotropic, $\\langle \\mathbf{u}_i \\rangle = 0$ . This is not surprising, the\nrandom walker has the same probability to walk in all directions and therefore does\nnot get anywhere on average.",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            761,
            520,
            797
          ],
          "text": "However, from Fig. 11.1 we see that the extent of the path increases with the\nnumber of steps $n$ . We can characterize this using the same measures we used to",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 180,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            358,
            62
          ],
          "text": "11.1 Diffusion and Random Walks in Homogeneous Media",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            512,
            58
          ],
          "text": "17",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            456
          ],
          "text": "describe the geometry of the percolation clusters, by measuring $r_n^2$ . We find the\naverage value of $r_n^2$ using\n\\[\n\t\\begin{aligned}\n\t\t\\langle r_n^2 \\rangle&=\\langle \\mathbf{r}_n\\cdot \\mathbf{r}_n \\rangle\\\\\n\t\t&=\\langle(\\sum_i\\mathbf{u}_i)\\cdot (\\sum_j\\mathbf{u}_j)\\rangle\\\\\n\t\t&=\\langle \\sum_i\\sum_j\\mathbf{u}_i\\cdot \\mathbf{u}_j\\rangle\\\\\n\t\t&=\\langle \\sum_{i=j}\\mathbf{u}_i\\cdot \\mathbf{u}_j\\rangle+\\langle \\sum_{i\\neq j}\\mathbf{u}_i\\cdot \\mathbf{u}_i\\rangle\\\\\n\t\t&=\\sum_i\\langle \\mathbf{u}_i\\cdot \\mathbf{u}_i\\rangle+\\sum_{i\\neq j}\\underbrace{\\langle \\mathbf{u}_i\\cdot \\mathbf{u}_i\\rangle}_{=0}\\\\\n\t\t&= n\\delta^2~,\n\t\\end{aligned}\n\t\\]\nwhere $\\langle \\mathbf{u}_i\\cdot \\mathbf{u}_i\\rangle=\\delta^2$ is a property of the distribution of $\\mathbf{u}_i$ corresponding to the\nvariance of the distribution. And where we have used that because $\\mathbf{u}_i$ and $\\mathbf{u}_j$ are\nindependent, the average of their product is equal to the product of their averages:\n\\[\n\t\\langle \\mathbf{u}_i\\cdot \\mathbf{u}_j\\rangle=\\langle \\mathbf{u}_i\\rangle\\cdot \\langle \\mathbf{u}_j\\rangle=\\mathbf{0}\\cdot \\mathbf{0}=0~.\n\t\\tag{11.4}\n\t\\]",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            465,
            520,
            564
          ],
          "text": "Consequently, we have shown that $r_n^2=n\\delta^2$ . This is a very general result . We\nhave found that the extent of the diffusion path increases slowly with the number\nof steps: $r_n=\\delta n^{1/2}$ . This result is valid in any dimension as long as the two basic\nassumptions are satisfied: The individual steps are independent and each individual\nstep has an isotropic distribution so that the average displacement from a single step\nis zero.",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            582,
            520,
            789
          ],
          "text": "Here Dimension of the Random Walk Here we have demonstrated that the size of\nthe random walk, measured as $r^2$ , is proportional to the number of elements in the\nrandom walk. This is similar to the way we measured the size of a cluster using the\nradius of gyration of the cluster. Indeed, it can be shown that these two definitions\ngive the same relation $r_n^2=b^2 n$ , where $b$ is a constant of unit length that describes\nthe distribution of a single step. We realize that $n$ is the number of elements in the\nrandom walk, corresponding to $s$ , the number of sites in a cluster. We have therefore\nfound that $r_n=bn^{1/2}$ , or similarly, that $n=(r_n/b)^2\\propto r^{D_w}$ . This implies that\nthe dimension, $D_w$ , of the random walk always is $D_w=2$ , independent of the\nembedding dimension $d$ . This means that for $d=1$ the random walk will overfill\nspace. Indeed, we expect it to step on top of itself repeatedly. For $d=2$ the random\nwalk will just fill space since $D_w=d$ , whereas for $d=3$ and higher dimensions the\nrandom walk will fill a diminishing portion of space. Just like the spanning cluster",
          "reading_order": 4
        }
      ]
    },
    {
      "page_number": 181,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            58
          ],
          "text": "174",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            358,
            44,
            520,
            62
          ],
          "text": "1 Diffusion in Disordered Media",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            116
          ],
          "text": "had a smaller scaling exponent than the spatial dimension, and hence the density of\nthe spanning cluster decreased for larger systems.",
          "reading_order": 2
        },
        {
          "label": "sec",
          "bbox": [
            72,
            143,
            360,
            161
          ],
          "text": "Continuum Description of a Random Walker",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            179,
            520,
            225
          ],
          "text": "We can also describe the motion of the random walker through the probability\ndensity $P(\\mathbf{r},t)$ , where $P(\\mathbf{r},t)\\mathop{\\mathrm{d}}\\!\\mathbf{r}\\mathop{\\mathrm{d}} t$ is the probability for the random walker to be in\nthe volume $\\mathbf{r}\\mathop{\\mathrm{d}}\\!\\mathbf{r}$ in the time period $t$ to $t+\\mathop{\\mathrm{d}}\\!t$ .",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            225,
            520,
            433
          ],
          "text": "For a random walker on a grid, the probability to be at a grid position $i$ is given\nas $P_{i}(t)$ . The probability for the walker to be at a position $i$ at the time $t=t+\\delta t$ is\nthen\n$$P_{i}(t+\\delta t)=P_{i}(t)+\\sum_{j}[\\sigma_{j,i} P_{j}(t)-\\sigma_{i,j} P_{i}(t)]\\delta t~,\\eqno(11.5)$$\nwhere the sum is over all neighbors $j$ of the site $i$ . The term $\\sigma_{i,j}$ is the transition\nprobability from site $i$ to site $j$ . The first term in the sum represents the probability\nthat the walker during the time period $\\delta t$ walks into site $i$ from site $j$ , and the second\nterm represents the probability that the walker during the time period $\\delta t$ walks from\nsite $i$ to one of the neighboring sites $j$ .",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            89,
            433,
            421,
            492
          ],
          "text": "$$\n\\frac{\\partial P_{i}}{\\partial t}=\\sum_{j}\\left[\\sigma_{j, i} P_{j}(t)-\\sigma_{i, j} P_{i}(t)\\right]\n$$",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            501,
            520,
            640
          ],
          "text": "If we assume that the transition probability is equal for all the neighbors, so that\n$\\sigma_{i,j}=1/Z$ , where $Z$ is the number of neighbors, the differential equation simplifies\nto\n$$\\frac{\\partial P}{\\partial t}=D\\nabla^2P~,$$\nwhich we recognize as the diffusion equation, where the diffusion constant $D$ is\nrelated to the transition probabilities $\\sigma_{i,j}$ and $Z$ .",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            642,
            430,
            735
          ],
          "text": "The general solution to this equation is\n$$P(\\mathbf{r},t)=\\frac{1}{(2\\pi Dt)^{d/2}}e^{-r^2/2Dt}=\\frac{1}{(2\\pi)^{d/2}|\\mathbf{R}|^2}e^{-\\frac{1}{2}(\\frac{r}{|\\mathbf{R}|})^2}~,$$ _\nwhere we have introduced $|\\mathbf{R}|=\\sqrt{Dt}$ .",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            89,
            735,
            394,
            788
          ],
          "text": "It can be shown that the moments of this distribution are\n\\[ \\langle r^{k}\\rangle=A_{k}R(t)^{k}\\propto t^{k/2}~,\\]",
          "reading_order": 9
        }
      ]
    },
    {
      "page_number": 182,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            227,
            62
          ],
          "text": "11.2 Random Walks on Clusters",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            520,
            62
          ],
          "text": "175",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            181,
            98
          ],
          "text": "and specifically, that",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            107,
            520,
            192
          ],
          "text": "_",
          "reading_order": 3
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            224,
            304,
            241
          ],
          "text": "11.2 Random Walks on Clusters",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            259,
            520,
            304
          ],
          "text": "We now have the basic tools to understand diffusion in homogeneous media: by\nstudying the position $\\mathbf{r}(t)$ of a random walker as a function of the number of steps\n$n$ or the time $t=n\\,\\Delta t$ , where $\\Delta t$ is the time for a single step.",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            304,
            520,
            369
          ],
          "text": "How can we use this method to study diffusion on a percolation cluster? We\nwant to address how a particle diffuses on the cluster. That is, we want to study how\na random walker moves on the occupied sites in the percolation system. We will\nassume that the walker only can move onto connected neighbor sites in each step.",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            369,
            520,
            448
          ],
          "text": "There are many different ways we can construct such measurements, and as\nalways, we need to be very precise when we define both the experiment and our\nset of measures. Our plan is to drop a random walker onto a random site in the\npercolation system and measure the position $\\mathbf{r}(t)$ of the walker as a function of\ntime.",
          "reading_order": 7
        },
        {
          "label": "sec",
          "bbox": [
            72,
            483,
            457,
            501
          ],
          "text": "Developing a Program to Study Random Walks on Clusters",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            72,
            517,
            520,
            564
          ],
          "text": "In order to study the behavior we need to develop a program to generate a random\nwalk on top of a percolation lattice, generate many such paths and collect, analyze\nand visualize the resulting behavior.",
          "reading_order": 9
        },
        {
          "label": "para",
          "bbox": [
            72,
            564,
            520,
            645
          ],
          "text": "The rules for such a walker would be that we select a position at random and then\nparachute the walker into this position. We start with a percolation system given by\nthe $L\\times L$ matrix cluster , where cluster is True in the points where the sites\nare present. The initial positions, ix , iy , in the x- and y -direction for the walker\nare therefore random numbers between 0 and $L-1$ respectively:",
          "reading_order": 10
        },
        {
          "label": "code",
          "bbox": [
            80,
            663,
            251,
            689
          ],
          "text": "ix = np.random.randint(L)\niy = np.random.randint(L)",
          "reading_order": 11
        },
        {
          "label": "para",
          "bbox": [
            72,
            707,
            520,
            736
          ],
          "text": "where L is the system size. If this site is empty, the walk stops immediately and its\nlength is zero:",
          "reading_order": 12
        },
        {
          "label": "code",
          "bbox": [
            80,
            752,
            224,
            779
          ],
          "text": "if not cluster[ix,iy]\nreturn",
          "reading_order": 13
        }
      ]
    },
    {
      "page_number": 183,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            58
          ],
          "text": "176",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            358,
            44,
            520,
            62
          ],
          "text": "1 Diffusion in Disordered Media",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            161
          ],
          "text": "Storing the Trajectory of the Walker We store the trace of the walker\nin two arrays (we need both to handle periodic boundary conditions later):\nwalker_map which consists of the positions ix,iy of the walker for each\nstep, and displacement , which consists of the positions relative to the initial\nposition of the walker.",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            179,
            520,
            225
          ],
          "text": "Random Selection of Next Step How do we select where the walker can move?\nThe walker is restricted to move to nearest neighbor sites that are present. There are\nseveral approaches:",
          "reading_order": 3
        },
        {
          "label": "list",
          "bbox": [
            88,
            241,
            520,
            290
          ],
          "text": "We may select a direction at random and try to move in this direction. If the\nwalker cannot move in this direction it stays put for this step, and then tries again\nin the next step. In this case, the walker may have many steps without any motion.",
          "reading_order": 4
        },
        {
          "label": "list",
          "bbox": [
            88,
            293,
            520,
            340
          ],
          "text": "We may find all the directions the walker can possibly move in, and then select\none of these directions at random. In this case the walker will move onto a new\nsite in each step.",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            357,
            520,
            421
          ],
          "text": "Both these methods effectively produce the same behavior. We will select the second\nmethod. We therefore need to create a list of the possible directions to move in. In\norder to make this list, we have a list called directions of possible movement\ndirections:",
          "reading_order": 6
        },
        {
          "label": "code",
          "bbox": [
            107,
            439,
            421,
            573
          ],
          "text": "directions = np.zeros((2, 4), dtype=np.int64)\n# X-dir: east and west, Y-dir: north and south\ndirections[0, 0] = 1\ndirections[1, 0] = 0\ndirections[0, 1] = -1\ndirections[1, 1] = 0\ndirections[0, 2] = 0\ndirections[1, 2] = 1\ndirections[0, 3] = 0\ndirections[1, 3] = -1",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            589,
            520,
            618
          ],
          "text": "For each step, we need to collect all the possible steps into a list called\nneighbor_arr . This is done by the following loop:",
          "reading_order": 8
        },
        {
          "label": "code",
          "bbox": [
            107,
            636,
            475,
            743
          ],
          "text": "neighbor = 0\nfor idir in range(directions.shape[1]):\ndr = directions[:,idir]\niix = ix + dr[0]\niiy = iy + dr[1]\nif 0<=iix<L and 0<=iiy< L and cluster[iix,iiy]\nneighbor_arr[neighbor] = idir\nneighbor += 1",
          "reading_order": 9
        },
        {
          "label": "para",
          "bbox": [
            72,
            761,
            520,
            807
          ],
          "text": "If this list is empty, that is, if neighbor is zero, there are no possible places to\nmove. This means that the walker has landed on a cluster of size $s=1$. In this case,\nwe stop and return with $n=1$.",
          "reading_order": 10
        }
      ]
    },
    {
      "page_number": 184,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            226,
            58
          ],
          "text": "11.2 Random Walks on Clusters",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            520,
            58
          ],
          "text": "177",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            112
          ],
          "text": "Finally, we select one of the neighbor directions at random, move the walker\ninto this site, update walker_map and displacement and repeat the process.",
          "reading_order": 2
        },
        {
          "label": "code",
          "bbox": [
            134,
            134,
            448,
            263
          ],
          "text": "# Select random direction from 0 to neighbor-1\nranddir = np.random.randint(neighbor)\ndir = neighbor_arr[randdir]\nix += directions[0, dir]\niy += directions[1, dir]\nstep += 1\nwalker_map[0, step] = ix\nwalker_map[1, step] = iy\ndisplacement[:,step]=displacement[:,step-1]+\\\ndirections[:,dir]",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            283,
            367,
            296
          ],
          "text": "Here, step corresponds to n, the current step number.",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            313,
            520,
            344
          ],
          "text": "Preparing the Function We put this into a function and use the numba library to\nspeed up simulation times.",
          "reading_order": 5
        },
        {
          "label": "code",
          "bbox": [
            80,
            366,
            202,
            389
          ],
          "text": "import numba\nimport numpy as np",
          "reading_order": 6
        },
        {
          "label": "code",
          "bbox": [
            80,
            403,
            511,
            564
          ],
          "text": "@numba.njit(cache=True)\ndef percwalk(cluster, max_steps):\n\"\"\"Function performing a random walk on the spanning cluster\nParameters\n----------\ncluster : np.ndarray\nBoolean array with 1’s signifying a present site\nmax_steps : int\nMaximum number of walker steps to perform.\nReturns\n-------\nwalker_map : np.ndarray",
          "reading_order": 7
        },
        {
          "label": "code",
          "bbox": [
            107,
            564,
            493,
            591
          ],
          "text": "A coordinate map of walk, x in [0] and y in [1]\ndisplacement: np.ndarray",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            107,
            591,
            495,
            630
          ],
          "text": "A coordinate map relative pos., x in [0] and y in [1]\nnum_steps: int\nNumber of steps performed.",
          "reading_order": 9
        },
        {
          "label": "code",
          "bbox": [
            107,
            634,
            421,
            806
          ],
          "text": "\"\"\"\nwalker_map = np.zeros((2, max_steps))\ndisplacement = np.zeros_like(walker_map)\ndirections = np.zeros((2, 4), dtype=np.int64)\nneighbor_arr = np.zeros(4, dtype=np.int64)\n# X-dir: east and west, Y-dir: north and south\ndirections[0, 0] = 1\ndirections[1, 0] = 0\ndirections[0, 1] = -1\ndirections[1, 1] = 0\ndirections[0, 2] = 0\ndirections[1, 2] = 1\ndirections[0, 3] = 0",
          "reading_order": 10
        }
      ]
    },
    {
      "page_number": 185,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            58
          ],
          "text": "178",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            358,
            44,
            520,
            62
          ],
          "text": "1 Diffusion in Disordered Media",
          "reading_order": 1
        },
        {
          "label": "code",
          "bbox": [
            106,
            80,
            493,
            525
          ],
          "text": "directions[1, 3] = -1\n# Initial random position\nLx, Ly = cluster.shape\nix = np.random.randint(Lx)\niy = np.random.randint(Ly)\nwalker_map[0, 0] = ix\nwalker_map[1, 0] = iy\nstep = 0\nif not cluster[ix, iy]: # Landed outside the cluster\nreturn walker_map, displacement, step\nwhile step < max_steps-1:\n# Make list of possible moves\nneighbor = 0\nfor idir in range(directions.shape[1]):\ndr = directions[:,idir]\niix = ix + dr[0]\niiy = iy + dr[1]\nif 0<=iix<Lx and 0<=iiy<Ly and cluster[iix,iiy]:\nneighbor_arr[neighbor] = idir\nneighbor += 1\nif neighbor == 0: # No way out, return\nreturn walker_map, displacement, step\n# Select random direction from 0 to neighbor-1\nranddir = np.random.randint(neighbor)\ndir = neighbor_arr[randdir]\nix += directions[0, dir]\niy += directions[1, dir]\nstep += 1\nwalker_map[0, step] = ix\nwalker_map[1, step] = iy\ndisplacement[:,step]=displacement[:,step-1]+\\\ndirections[:,dir]\nreturn walker_map, displacement, step",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            552,
            520,
            582
          ],
          "text": "Testing the Function Let us test the newly generated function on a few simplified\ncases. First, we try it on a system with $p=1$ , that is, on a homogeneous system.",
          "reading_order": 3
        },
        {
          "label": "code",
          "bbox": [
            79,
            600,
            421,
            725
          ],
          "text": "import numpy as np\nimport matplotlib.pyplot as plt\nL = 50\np = 1\nz = np.random.rand(L,L)<p\nplt.imshow(z,origin=\"lower\")\nwalker_map, displacement, steps = percwalk(z,200)\n# walker_map is oriented as row-column (ix, iy)\nplt.plot(walker_map[1,:steps],walker_map[0,:steps]",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            741,
            520,
            806
          ],
          "text": "Walks from 10 such simulations are shown in Fig. 11.2 . This looks reasonable\nand nice, but we do notice that quite a few of these walks reach the boundaries of\nthe system. We may wonder how this finite system size affects the behavior and\nstatistics of the system.",
          "reading_order": 5
        }
      ]
    },
    {
      "page_number": 186,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            227,
            62
          ],
          "text": "11.2 Random Walks on Clusters",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            520,
            58
          ],
          "text": "179",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_186_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_186_figure_002.png",
          "bbox": [
            287,
            71,
            528,
            304
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            80,
            197,
            134
          ],
          "text": "Fig. 11.2 Trajectories of 1\nrandom walks for a\n(homogeneous) system with\n$L=50$ and $p=1$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            322,
            520,
            376
          ],
          "text": "Measuring $r^2(t)$ for a Random Walker The function percwalk returns the\ndisplacements, $\\mathbf{r}_n$ , for the walking starting from $\\mathbf{r}_0=0$ . We find $r_n^2$ and visualize\nthe result for a single walk:",
          "reading_order": 4
        },
        {
          "label": "code",
          "bbox": [
            79,
            394,
            412,
            484
          ],
          "text": "L = 50\np = 1\nz = np.random.rand(L,L)<p\nwalker_map, displacement, steps = percwalk(z,200)\nr2 = np.sum(displacement**2,axis=0)\nt = np.arange(len(r2))\nplt.plot(t,r2)",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            500,
            520,
            546
          ],
          "text": "The resulting plot is shown in Fig. 11.3 . We do not really learn much from this plot.\nWe need to collect more statistics. We need to generate many different walks and\nthen average over all the walks to find a statistically better measure for $r^2(t)$ .",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            562,
            520,
            639
          ],
          "text": "We Statistics for r 2 ( t ) We therefore write a small function to generate a\ngiven number of clusters with the given p . For each such cluster we will generate\na given number of walks. Notice, that we must also specify the maximum number\nof steps that we model for each walk. The following function implements these\nfeatures:",
          "reading_order": 7
        },
        {
          "label": "code",
          "bbox": [
            80,
            654,
            489,
            827
          ],
          "text": "@numba.njit(cache=True)\ndef find_displacements(p,L,num_systems,num_walkers,max_steps\ndisplacements = np.zeros(max_steps)\nfor system in range(num_systems):\nz = np.random.rand(L,L)<p\nfor j in range(num_walkers):\nnum_steps = 0\nwhile num_steps <= 1:\nwalker_map,displacement,num_steps = \\\npercwalk(z,max_steps)\ndisplacements += np.sum(displacement**2, axis=0)\ndisplacements = displacements/(num_walkers*num_systems)\nreturn displacements",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 187,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            90,
            58
          ],
          "text": "180",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            358,
            44,
            520,
            62
          ],
          "text": "1 Diffusion in Disordered Media",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_187_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_187_figure_002.png",
          "bbox": [
            72,
            80,
            520,
            322
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            329,
            520,
            353
          ],
          "text": "Fig. 11.3 (a) Trajectory of a random walk for a (homogeneous) system with $L=50$ and $p=1$ .\n(b) Plot of the corresponding $r^2(t)$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            384,
            520,
            461
          ],
          "text": "Notice a few details: If the number of steps is 1 or smaller it means that the walker\nlanded either on an empty size ( $n=0$ ) or on a single site ( $n=1$ ). We do not\nwant to include these in our statistics since they provide little information about\nthe behavior of the random walker. We use this program to collect statistics from\n$M=500$ random walks of length $n=10,\\!000$ steps on a $L=100$ system:",
          "reading_order": 4
        },
        {
          "label": "code",
          "bbox": [
            79,
            483,
            439,
            618
          ],
          "text": "p = 1.0\nL = 100\nmax_steps = 10000\nnum_walkers = 500\nnum_systems = 100\ndisplacements = find_displacements(p,L,num_systems,\\\nnum_walkers,max_steps)\ndr1 = displacements[1:]\nt = np.arange(len(dr1))\nplt.loglog(t,dr1)",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            627,
            520,
            710
          ],
          "text": "The resulting plot in Fig. 11.4 shows that the system indeed behaves as we expect—\nfor small values of $t$ . However, as $t$ increases, we see that the effect of the finite\nsystem size $L$ starts to affect the results. This is because the random walker is limited\nby the wall and eventually we will be limited the $L\\times L$ system. This problem will\nalso arise when we study the percolation system. How can we reduce this problem?",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            725,
            520,
            807
          ],
          "text": "Introducing Periodic Boundary Condition One way of reducing this problem is\nby introducing periodic boundary conditions . The idea is that is the random walker\nsteps outside the lattice on the left side, it appears on the right-hand side instead.\nThat is, if ix becomes -1, it is instead set to $L-1$ . We implement this in the\npercwalk function in the following. The resulting plot of $r^2(t)$ in Fig. 11.4 shows",
          "reading_order": 7
        }
      ]
    },
    {
      "page_number": 188,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            233,
            62
          ],
          "text": "11.2 Random Walks on Clusters",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            512,
            58
          ],
          "text": "18",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_188_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_188_figure_002.png",
          "bbox": [
            242,
            80,
            520,
            268
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            80,
            197,
            135
          ],
          "text": "Fig. 11.4 Plot of $r^{2}(t)$ for\n$L=100$ system with\nnon-periodic and periodic\nboundary conditions",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            295,
            518,
            331
          ],
          "text": "that this solves the problem with the boundaries. This aspect will be even more\nimportant when we study percolation systems in non-uniform media.",
          "reading_order": 4
        },
        {
          "label": "code",
          "bbox": [
            80,
            349,
            457,
            387
          ],
          "text": "# With periodic boundary conditions for good statistics\nimport numba\nimport numpy as np",
          "reading_order": 5
        },
        {
          "label": "code",
          "bbox": [
            80,
            403,
            511,
            564
          ],
          "text": "@numba.njit(cache=True)\ndef percwalk(cluster, max_steps):\n\"\"\"Function performing a random walk on the spanning cluster\nParameters\n----------\ncluster : np.ndarray\nBoolean array with l’s signifying a site present\nmax_steps : int\nMaximum number of walker steps to perform.\nReturns\n--------\nwalker_map : np.ndarray",
          "reading_order": 6
        },
        {
          "label": "code",
          "bbox": [
            107,
            564,
            511,
            591
          ],
          "text": "A coordinate map of walk, x in [0] and y in [1]\ndisplacement: np.ndarray",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            107,
            591,
            511,
            629
          ],
          "text": "A coordinate map of relative pos, x in [0] and y in [1]\nnum_steps: int\nNumber of steps performed.",
          "reading_order": 8
        },
        {
          "label": "code",
          "bbox": [
            107,
            629,
            421,
            806
          ],
          "text": "\"\"\"\nwalker_map = np.zeros((2, max_steps))\ndisplacement = np.zeros_like(walker_map)\ndirections = np.zeros((2, 4), dtype=np.int64)\nneighbor_arr = np.zeros(4, dtype=np.int64)\n# X-dir: east and west, Y-dir: north and south\ndirections[0, 0] = 1\ndirections[1, 0] = 0\ndirections[0, 1] = -1\ndirections[1, 1] = 0\ndirections[0, 2] = 0\ndirections[1, 2] = 1\ndirections[0, 3] = 0",
          "reading_order": 9
        }
      ]
    },
    {
      "page_number": 189,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            58
          ],
          "text": "182",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            358,
            44,
            520,
            62
          ],
          "text": "1 Diffusion in Disordered Media",
          "reading_order": 1
        },
        {
          "label": "code",
          "bbox": [
            106,
            80,
            476,
            672
          ],
          "text": "directions[1, 3] = -1\n# Initial random position\nLx, Ly = cluster.shape\nix = np.random.randint(Lx)\niy = np.random.randint(Ly)\nwalker_map[0, 0] = ix\nwalker_map[1, 0] = iy\nstep = 0\n# Check if we landed outside the spanning cluster\nif not cluster[ix, iy]:\n# Return the map with starting pos and nr of steps\nreturn walker_map, displacement, step\nwhile step < max_steps-1:\n# Make list of possible moves\nneighbor = 0\nfor idir in range(directions.shape[1]):\ndr = directions[:,idir]\niix = ix + dr[0]\niiy = iy + dr[1]\n# Periodic BC\nif iix>=Lx:\niix = iix-Lx\nif iixc0:\niix = iix+Lx\nif iiy>=Ly:\niiy = iiy-Ly\nif iiy<0:\niiy = iiiy+Ly\nif cluster[iix, iiy]:\nneighbor_arr[neighbor] = idir\nneighbor += 1\nif neighbor == 0: # No way out, return\nreturn walker_map, displacement, step\n# Select random direction from 0 to neighbor-1\nranddir = np.random.randint(neighbor)\ndir = neighbor_arr[randdir]\nix += directions[0, dir]\niy += directions[1, dir]\nstep += 1\nwalker_map[0, step] = ix\nwalker_map[1, step] = iy\ndisplacement[:,step]=displacement[:,step-1]+\\\ndirections[:,dir]\nreturn walker_map, displacement, step",
          "reading_order": 2
        },
        {
          "label": "sec",
          "bbox": [
            72,
            707,
            323,
            726
          ],
          "text": "Diffusion on a Finite Cluster for $p<p_{c}$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            743,
            520,
            807
          ],
          "text": "We now have all the tools to start studying the behavior of a random walker on top\nof a percolation system. We select $p=p_c$ and drop the random walker on a random\nposition on the lattice. The resulting set of walks from such a simulation can be seen\nin Fig. 11.5 .",
          "reading_order": 4
        }
      ]
    },
    {
      "page_number": 190,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            227,
            62
          ],
          "text": "11.2 Random Walks on Clusters",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            520,
            58
          ],
          "text": "183",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_190_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_190_figure_002.png",
          "bbox": [
            251,
            80,
            520,
            331
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            80,
            206,
            107
          ],
          "text": "Fig. 11.5 Plot of 30 walks in\na $L=100$ system at $p=p_c$",
          "reading_order": 3
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_190_figure_004.png)",
          "figure_path": "figures/percolation_studies_page_190_figure_004.png",
          "bbox": [
            251,
            340,
            520,
            555
          ],
          "reading_order": 4
        },
        {
          "label": "cap",
          "bbox": [
            72,
            340,
            179,
            385
          ],
          "text": "Fig. 11.6 Plots of\n$r^{2}(t;\\,p,L)$ for\n$p=0.45,\\,0.50,\\,0.55,\\,p$",
          "reading_order": 5
        },
        {
          "label": "code",
          "bbox": [
            79,
            582,
            475,
            675
          ],
          "text": "L = 100\np = 0.5927\nz = np.random.rand(L,L)<p\nplt.imshow(z,origin=\"lower\")\nfor i in range(30):\nwalker_map, displacement, steps = percwalk(z,10000)\nplt.plot(walker_map[1,:steps],walker_map[0,:steps],'o'",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            698,
            520,
            761
          ],
          "text": "Understanding Behavior for $p>p_c$ We then simulate a larger set of walks for\n$p=0.45,\\,0.50,\\,0.55$ , $p_c$ . The resulting plots of $r^2(t)$ are shown in Fig. . We see\nthat when $p<p_c, r^2(t)\\propto t^x$ for some time, but then after some time, $r^2(t)$ crosses\nover to a constant instead. How can we understand this behavior?",
          "reading_order": 7
        }
      ]
    },
    {
      "page_number": 191,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            58
          ],
          "text": "184",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            358,
            44,
            520,
            62
          ],
          "text": "1 Diffusion in Disordered Media",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            295
          ],
          "text": "Long-Term Behavior When $p<p_c$ For a single walker that lands on a cluster\nof size $s$ , we expect that the walker will be limited to walk on this cluster and\ntherefore cannot reach positions that are much further away than $R_s$ . Thus, after\na long time, we expect $r^2(t)\\propto R_s^2$ . If we repeat this experiment many times, each\ntime dropping the walker onto a random occupied point in the system, we need to\ntake the average over all clusters of size $s$ and over all starting positions, to find\nthe average of $r^2(t)$ for all these different walks. If we drop the walker at a random\nposition, the probability for that walker to land on a cluster of size $s$ is $sn(s,\\, p)$ ,\nand the contribution from this cluster to $r^2(t)$ after a long time is $R_s^2$ . Therefore, the\naverage $\\langle r^2(t)\\rangle$ for the walker is:\n$$\\left[\\langle r^2\\rangle\\right]\\propto\\left[R_s^2\\right]=\\sum_{s}R_s^2sn(s,\\, p)~.\\eqno(11.11)$$",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            304,
            520,
            386
          ],
          "text": "We approximate this sum by an integral and replace $n(s,\\,p)$ by the scaling ansatz\n$n(s,\\,p)=s^{-\\tau}F(s/s_{\\xi})$ , getting\n$$\\left[R_{s}^{2}\\right]=\\int_{1}^{\\infty}R_{s}^{2}ss^{-\\tau}F(s/s_{\\xi})ds~.\\eqno(11.12)$$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            403,
            520,
            501
          ],
          "text": "We realize that the function $F(s/s_\\xi)$ falls to zero very rapidly when $s>s_\\xi$ and it is\neffectively constant below that, we therefore replace the integral with an integral up\nto $s_\\xi$ :\n$$\\left[R^2_s\\right]=\\int_1^{s_\\xi} R^2_ss^{-\\tau}ds~.$$",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            510,
            520,
            663
          ],
          "text": "We now insert that $R_s^2\\propto s^{2/D}$ and perform the integral, getting:\n$$\\left[ R_s^2\\right]\\propto s_\\xi^{2/D+2-\\tau}\\propto s_\\xi^{2/D}s_\\xi^{2-\\tau}~.~\\eqno(11.14)$$\nwhere we recognize the first factor as $\\xi^2\\propto (p-p_c)^{-2\\nu}$ and the second factor from\n( 4.33 ) as $(p-p_c)^\\beta$ so that\n$$\\left[ R_s^2\\right]\\propto (p-p_c)^{\\beta-2\\nu}~.$$",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            678,
            520,
            743
          ],
          "text": "We notice that in this case the average is of $R_s^2$ over $sn(s,\\,p)$ , but when we calculated\nthe correlation length in ( 5.18 ) the average was of $R_s^2$ over $s^2n(s,\\,p)$ , and this is the\nreason for the appearance of the exponent $\\beta-2\\nu$ and not simply $-2\\nu$ as we got for\nthe correlation length.",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            752,
            513,
            791
          ],
          "text": "Short Term Behavior There is a transition in $r^2(t)$ to $\\left[R^2\\right]$ after some crossover\ntime $t_0$ . For times shorter than $t_0$ we see from Fig. 11.6 that the behavior appear",
          "reading_order": 7
        }
      ]
    },
    {
      "page_number": 192,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            227,
            62
          ],
          "text": "11.2 Random Walks on Clusters",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            520,
            58
          ],
          "text": "185",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            134
          ],
          "text": "to be that $r^2(t)\\propto t^{2k}$ for some exponent $2k$ . We notice that as $p$ approaches $p_c$ ,\nthe crossover time $t_0$ increases. All the curves for various $p$ -values appear to have\nsimilar, or possibly the same behavior for $t<t_0$ .",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            134,
            520,
            232
          ],
          "text": "In Fig. 11.6 we notice that the exponent $2k$ is not 1, as we found for the\nhomogeneous case. It is clearly lower than 1. If we measure it, we find that\n$2k\\simeq0.66$ and $k\\simeq0.33$ . We call this behavior anomalous diffusion because the\nmean squared distance $r^2(t)$ does not grow linearly with time, but with an exponent\ndifferent than 1. What can we say about the crossover time $t_0$ ? We will return to this\nafter examining the case when $p>p_c$ .",
          "reading_order": 3
        },
        {
          "label": "sec",
          "bbox": [
            72,
            259,
            197,
            277
          ],
          "text": "Diffusion at $p=p_{c}$",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            286,
            520,
            421
          ],
          "text": "From Fig. 11.6 we also see that for $p=p_c$ the random walk follows $r^2(t)\\propto t^{2k}$ .\nThis behavior is as expected. For times shorter than $t_0$ , the walker behaves as if\nit is on $p_c$ , whereas after a long time, $t>t_0$ , we start noticing that the walker\nis restricted when it diffuses on the finite clusters. Another way to think of this\nis that the crossover time $t_0$ increases as $p\\to p_c$ , and diverges at $p=p_c$ . The\nexponent $k$ is a universal exponent for diffusion on percolation systems. It does not\ndepend on the lattice structure or the rules for connectivity, but it does depend on\nthe embedding dimension $d$ .",
          "reading_order": 5
        },
        {
          "label": "sec",
          "bbox": [
            72,
            448,
            197,
            469
          ],
          "text": "Diffusion for $p>p$",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            483,
            520,
            600
          ],
          "text": "We can use the same computational approach to study the behavior of the random\nwalker when $p>p_c$ . The resulting plots for $p=0.8$ , $0.75$ , $0.70$ , $0.65$ and $p_c$ are\nshown in Fig. 11.7 . The plots show that when $p>p_c$ , for short times the $r^2(t)$ curve\nfollows the behavior for $p=p_c$ with $r^2(t)\\propto t^{2k}$ as shown by the solid line. But\nfor a crossover time $t_0$ , the behavior changes and crosses over to a behavior where\n$r^2(t)\\propto t^1$ , that is, it crosses over to the behavior of a homogeneous system. How\ncan we understand this?",
          "reading_order": 7
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_192_figure_008.png)",
          "figure_path": "figures/percolation_studies_page_192_figure_008.png",
          "bbox": [
            251,
            618,
            520,
            806
          ],
          "reading_order": 8
        },
        {
          "label": "cap",
          "bbox": [
            72,
            627,
            197,
            665
          ],
          "text": "Fig. 11.7 Plots of\n$r^{2}(t;\\,p,\\,L)$ for",
          "reading_order": 9
        }
      ]
    },
    {
      "page_number": 193,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            58
          ],
          "text": "186",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            358,
            44,
            520,
            58
          ],
          "text": "1 Diffusion in Disordered Media",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            161
          ],
          "text": "Developing a Model for p > p c We know that when p = 1, the system is\nhomogeneous, and ⟨ r 2 ⟩ = D (1) t . We will therefore write the general relation for\n$p > p_c$ :\n\\[\n    \\langle r^2 \\rangle = D(p)t~,r \\gg \\xi~.\n  \\addtocounter{equation}{1}{\\theequation}\\label{eq:Dew-bound}\n  \\]",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            179,
            520,
            259
          ],
          "text": "What behavior do we expect from $D(p)$ ? We expect $D(p)$ to increase in a way\nsimilar to the density of the backbone or the conductivity $g$ . In fact, the Einstein\nrelation for diffusion relates the diffusion constant to the conductance through:\n\\[ D(p) \\propto g(p) \\propto (p-p_c)^{\\mu}~. \\eqno(11.17) \\]",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            277,
            520,
            370
          ],
          "text": "We therefore expect that when $p>p_c$ , and the time is larger than a crossover time\n$t_0(p)$ , that the behavior is scaling with exponent $\\mu$ , identical to that of conductivity.\nAnd for a time shorter than the crossover time, the behavior is identical to the\nbehavior the walker at does $p=p_c$ still . not We experience understand that this the in characteristic same way clusters as are above: limited When by $t<t_c$ a",
          "reading_order": 4
        },
        {
          "label": "sec",
          "bbox": [
            72,
            403,
            170,
            421
          ],
          "text": "Scaling Theory",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            435,
            520,
            531
          ],
          "text": "Let us develop a scaling theory for the behavior of $\\langle r^2\\rangle$ . We will assume that when\nthe time is smaller than a cross-over time, the behavior is according to a power-law\nwith exponent $2k$ , and that when the time is larger than the cross-over time, the\nbehavior reaches a either constant that plateau of diffusion for the case with diffusion $p<p_c$ constant . $D(p)$",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            88,
            531,
            377,
            564
          ],
          "text": "$$\n\\left\\langle r^{2}\\right\\rangle=t^{2 k} f\\left[\\left(p-p_{c}\\right) t^{x}\\right] .\n$$",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            582,
            520,
            727
          ],
          "text": "Notice that we could have started from any of the end-points, such as from the\nassumption that\n\\[ \\langle r^2 \\rangle = (p_c - p)^{\\beta-2v} G_1(\\frac{t}{t_0})~,\\]\nor\n\\[ \\langle r^2 \\rangle = (p - p_c)^\\mu G_2(\\frac{t}{t_0})~.\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:thm:bdd3}\\]",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 194,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            227,
            62
          ],
          "text": "11.2 Random Walks on Clusters",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            512,
            58
          ],
          "text": "18",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            188
          ],
          "text": "We have two unknown exponents $k$ and $x$ that must be determined from independent\nknowledge. We will assume that the function $f(u)$ has the behavior\n$$f(u)=\\left\\{\\begin{array}{ll}\n\\text { const. } & \\text { for }|u| \\ll 1 \\\\\nu^{\\mu} & \\text { for } u \\gg 1 \\\\\n(-u)^{\\beta-2 v} & \\text { for } u \\ll-1\n\\end{array}\\right.\\qquad\\qquad\\qquad(11.21)$$",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            197,
            520,
            228
          ],
          "text": "Let us now address the various limits in order to determine the scaling exponents k\nand x in terms of known exponents.",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            241,
            520,
            376
          ],
          "text": "Scaling Behavior in the Limit p > p c First, we know that when p > p c, that is\nwhen u ≫ 1, we have that\n\\[\n    \\langle r^2\\rangle \\propto (p-p_c)^{\\mu}t~,\\eqno(11.22)\n  \\]\nwhich should correspond to the functional form from the ansatz:",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            392,
            520,
            519
          ],
          "text": "This results in the exponent relation\n\\begin{equation} 2k=1-\\mu x~,\\\\& (11.24)  \\\\ $$x=\\frac{1-\\mu x}{2}~. \\end{equation}",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            528,
            520,
            672
          ],
          "text": "Similarly, Behavior in the Limit p < p c Similarly, we know that the behavior in the\nlimit of $u\\ll-1$ should be proportional to $(p_c-p)^{\\beta-2v}$ . Consequently, the scaling\nansatz gives\n$$(p_c-p)^{\\beta-2v}\\propto t^{2k}f((p-p_c)t^x)\\propto t^{2k}[(p_c-p)t^x]^{\\beta-2v}\\,,\\eqno(11.26)$$\nwhich results in the exponent relation:\n$$2k+x(\\beta-2v)=0\\;.\\eqno(11.27)$$",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            689,
            520,
            752
          ],
          "text": "Solving to Find the Exponents We solve the two equations for $x$ and $k$, finding\n\\[ k=\\frac{1}{2}[1-\\frac{\\mu}{2v+\\mu-\\beta}]\\;,\\eqno(11.28)\\]",
          "reading_order": 7
        }
      ]
    },
    {
      "page_number": 195,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            58
          ],
          "text": "188",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            358,
            44,
            520,
            62
          ],
          "text": "1 Diffusion in Disordered Media",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_195_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_195_figure_002.png",
          "bbox": [
            242,
            80,
            528,
            277
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            80,
            207,
            145
          ],
          "text": "Fig. 11.8 Plots of\n$r^2(t;\\,p,L)$ for\n$p=0.45$ , $0.50$ , $0.55$ rescaled\naccording to the scaling\ntheory",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            304,
            91,
            316
          ],
          "text": "and",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            242,
            331,
            349,
            367
          ],
          "text": "x = \\frac { 1 } { 2 v + \\mu - \\beta } ~ .",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            376,
            520,
            423
          ],
          "text": "Our argument therefore shows that the scaling ansatz is indeed consistent with the\nlimiting behaviors we have already determined, and it allows us to make a prediction\nfor $k$ and $x$ .",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            439,
            520,
            573
          ],
          "text": "Testing the Scaling Ansatz We can test the scaling function by a direct plot of the\nsimulated result. The scaling relation states that $r^2(t)= t^{2k}f[(p-p_c)t^x]$ , which\nmeans that $r^2(t)t^{-2k}= f[(p-p_c)t^x]$ . If we therefore plot $r^2(t)t^{-2k}$ on one axis\nand $(p-p_c)t^x$ on the other axis, all the data for the various values of $p$ should\nfall onto a common curve corresponding to the function $f(u)$ . This is illustrated in\nFig. 11.8 , which shows that the scaling ansatz is in good correspondence with the\ndata. Indeed, the plot also shows that the assumptions about the shape of the scaling\nfunction $f(u)$ are correct.",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            590,
            520,
            645
          ],
          "text": "Interpreting the Dimension of the Walk at $p=p_{c}\\,$ When $p=p_{c},$ we find that",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            72,
            654,
            520,
            806
          ],
          "text": "We can write this relation in the same way as we wrote the behavior of an ordinary\nrandom walk,\n\\[t \\propto r^{d_w}~,\\eqno(11.31)\\]\nwhere $d_w$ is the dimension of the random walk. We have therefore found that\n\\[d_w=\\frac{1}{k}=2+\\frac{\\mu}{v-\\frac{\\beta}{2}}~,\\eqno(11.32)\\]",
          "reading_order": 9
        }
      ]
    },
    {
      "page_number": 196,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            227,
            62
          ],
          "text": "11.2 Random Walks on Clusters",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            520,
            58
          ],
          "text": "189",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            116
          ],
          "text": "which is a number larger than 2. This means that for a given time, the walk remains\nmore compact, which is consistent with our intuition.",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            125,
            528,
            259
          ],
          "text": "Defining the Cross-Over Time We have introduced a cross-over time, $t_0$ , which is\ndefined so that\n\\[(p-p_c) t^x_0 \\simeq 1~,\\eqno{(11.33)}\\]\nwhich gives\n\\[t_0 \\propto |p-p_c|^{-1/x} \\propto |p-p_c|^{-(2v+\\mu-\\beta)}~.\\addtocounter{equation}{1}\\tag{\\theequation}\\label{e:defnoc}\\]",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            277,
            520,
            421
          ],
          "text": "Interpreting the Crossover Time How can we interpret this relation? We could\ndecompose the relation to be:\n\\[t_0 \\propto \\frac{|p-p_c|^{\\beta-2v}}{|p-p_c|^{\\mu}}~,\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:Condr}\\]\nwhere we know that the average radius of gyration for clusters are\n\\[[R_s^2] \\propto |p-p_c|^{\\beta-2v}~,\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:Condr}\\]",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            437,
            520,
            582
          ],
          "text": "This gives us an interpretation of the cross-over time for diffusion:\n\\[t_0(p) \\propto \\frac{[R_s^2]}{D}~,\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:defnoctrineq}\\]\nwhere $D$ is the diffusion constant. Why is this time not proportional to $\\xi^2/D$ ,\nthe time it takes to diffuse a distance proportional to the correlation length? The\ndifference comes from the particular way we devised the experiment: the walker\nwas dropped onto a randomly selected occupied site.",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            598,
            520,
            806
          ],
          "text": "Interpreting the Behavior for $p>p_c$ Let us now address what happens when\n$p>\\ p_c$ . In this case, the contributions to the variance of the position has two main\nterms: one term from the spanning cluster and one term from the finite clusters.\n$$[\\langle r^2\\rangle]=Dt=\\frac{P}{p}D't+R_s^2\\;,\\eqno(11.38)$$\nwhere the first term, $P/p D' t$ is the contribution from the random walker on the\ninfinite cluster. This term consists of the diffusion constant $D'$ for a walker on the\nspanning cluster, and the prefactor $P/p$ which comes from the probability for the\nwalker to land on the spanning cluster: For a random walker placed randomly on an\noccupied site in the system, the probability for the walker to land on the spanning\ncluster is $P/p$ , and the probability to land on any of the finite clusters is $1-P/p$ .",
          "reading_order": 6
        }
      ]
    },
    {
      "page_number": 197,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            90,
            58
          ],
          "text": "190",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            358,
            44,
            520,
            62
          ],
          "text": "1 Diffusion in Disordered Media",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            323
          ],
          "text": "The second term is due to the finite cluster. This term reaches a constant value for\nlarge times $t$ . The only time dependence is therefore in the first term, and we can\nwrite:\n\\[D t=\\frac{P}{p} D' t~,\\tag*{11.39}\\]\nfor long times, $t$ . That is:\n\\[D'=\\frac{D p}{P}\\propto(p-p_c)^{\\mu-\\beta}\\propto\\xi^{-\\frac{\\mu-\\beta}{v}}\\propto\\xi^{-\\theta}~.\\tag*{11.40}\\]\nwhere we have introduce the exponent\n\\[\\theta=\\frac{\\mu-\\beta}{v}~.\\tag*{11.41}\\]",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            340,
            518,
            439
          ],
          "text": "Interpreting the Crossover Time for $p>p_c$ We have therefore found an\ninterpretation of the cross-over time $t_0$ , and, in particular for the appearance of the\n$\\beta$ in the exponent. We see that the cross-over time is\n$$t_0\\propto \\frac{|p-p_c|^{\\beta-2v}}{|p-p_c|^{\\mu}}\\propto \\frac{\\xi^2}{D'}~.$$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            448,
            511,
            483
          ],
          "text": "The interpretation of $t_0$ is therefore that $t_0$ is the time the walker needs to travel\ndistance $\\xi$ when it is diffusing with diffusion constant $D'$ on the spanning cluster.",
          "reading_order": 4
        },
        {
          "label": "sec",
          "bbox": [
            72,
            510,
            296,
            529
          ],
          "text": "Diffusion on the Spanning Cluster",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            546,
            520,
            618
          ],
          "text": "How does the random walker behave on the spanning cluster? We have found that\nfor $p>p_c$ and for $t>t_0$ the mean square displacement increases according to\n\\[\n    \\langle r^2\\rangle=D' t\\propto(p-p_c)^{\\mu-\\beta}t~,\\eqno(11.43)\n  \\]",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            627,
            287,
            708
          ],
          "text": "For $t<t_0$ , we expect the behavior to be\n$$\\langle r^2\\rangle$$\nas illustrated in Fig. 11.6 .",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            725,
            520,
            808
          ],
          "text": "Interpretation of t 0 for Walks on the Spanning Cluster We expect the relations\nto be valid up to the point ( $t_0$ , $\\xi^2$ ), where both descriptions should provide the same\nresult. Therefore we expect\n$$\\xi \\propto t_0^{2k'} \\propto D' t_0~, \\eqno(11.45)$$",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 198,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            227,
            62
          ],
          "text": "11.2 Random Walks on Clusters",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            512,
            58
          ],
          "text": "19",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            152
          ],
          "text": "and therefore that\n\\[t_{0} \\propto \\frac{\\xi^{2}}{D^{\\prime}} \\propto \\frac{\\left(p-p_{c}\\right)^{-2 v}}{\\left(p-p_{c}\\right)^{\\mu-\\beta}} \\propto\\left(p-p_{c}\\right)^{-(2 v+\\mu-\\beta)}~.\\]",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            161,
            520,
            241
          ],
          "text": "Consequently, the value of $t_0$ is the same for diffusion on the spanning cluster\nas for diffusion on any cluster including the spanning cluster. In general, we can\ninterpret $t_0$ as the time it takes for the walker to diffuse to the end of the cluster\nwhen $p<p_c$ , and the time it takes to diffuse to a distance $\\xi$ on the spanning cluster\nwhen $p>p_c$ .",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            250,
            520,
            441
          ],
          "text": "Interpretation of k for Walks on the Spanning Cluster Let us check the other\nexponent, $k'$ . We find that\n\\[\n    \\xi^2 \\propto (p-p_c)^{-2(2v+\\mu-\\beta)k'}\\,,\\eqno(11.47)\n  \\]\nand therefore that\n\\[\n    k'=\\frac{v}{2v+\\mu-\\beta}\\;,\\eqno(11.48)\n  \\]\nwhich is not the same as we found in ( 11.28 ) for all clusters. We find that $k'$ is\nslightly larger than $k$ .",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            456,
            520,
            682
          ],
          "text": "What of k ′ and k What is the interpretation of k ′ ? If we consider random\nwalks on the spanning cluster only, the behavior at p = p c is described by\n(11.49)\nthis gives\nh",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            698,
            520,
            744
          ],
          "text": "The fractal dimension is larger than 2. This corresponds to the walker getting stuck\non the percolation cluster, and the structure of the walk is therefore more dense or\ncompact.",
          "reading_order": 6
        }
      ]
    },
    {
      "page_number": 199,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            58
          ],
          "text": "192",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            358,
            44,
            520,
            58
          ],
          "text": "1 Diffusion in Disordered Media",
          "reading_order": 1
        },
        {
          "label": "sec",
          "bbox": [
            72,
            80,
            238,
            98
          ],
          "text": "The Diffusion Constant D",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            116,
            528,
            259
          ],
          "text": "We can use the theory we have developed so far to address the behavior of the\ndiffusion constant with time. Fick's law can generally be formulated as\n\\[ \\langle r^2 \\rangle = {\\mathscr D}t~, \\eqno(11.52)\\]\nor, equivalently, we can find the diffusion constant for Fick's law from:\n\\[ {\\mathscr D} = \\frac{\\partial}{\\partial t} \\langle r^2 \\rangle~. \\eqno(11.53)\\]",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            268,
            520,
            350
          ],
          "text": "Now, we have established that for diffusion on the spanning cluster for $p=p_c$ , the\ndiffusion is anomalous. That is, the relation between the square distance and time is\nnot linear, but a more complicated power-law relationship\n\\[\n    \\langle r^2 \\rangle \\propto t^{2k'}~. \\eqno(11.54)\n  \\]",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            367,
            520,
            448
          ],
          "text": "As a result, we find that the diffusion constant $\\mathcal{D}'$ for diffusion on the spanning\ncluster defined through Fick's law is\n$$\\mathcal{D}' \\propto \\frac{\\partial}{\\partial t}t^{2k'} \\propto t^{2k'-1}~. \\eqno(11.55)$$",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            456,
            520,
            492
          ],
          "text": "We can therefore interpret the process as a diffusion process where $\\mathcal{D}$ decays with\ntime.",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            78,
            492,
            322,
            609
          ],
          "text": "In the anomalous regime, we find that\n$$r\\propto t^{k'}~,$$\nnd therefore that\n$$r^{1/k'} \\propto t~.$$",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            618,
            377,
            672
          ],
          "text": "We can therefore also write the diffusion constant $\\mathcal{D}'$ as\n$$\\mathcal{D}' \\propto t^{2k'-1} \\propto r^{2-1/k'} \\propto r^{-\\theta}~.$$",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            72,
            689,
            520,
            735
          ],
          "text": "We could therefore also say that the diffusion constant is decreasing with distance.\nThe reverse is also generally true: Whenever $\\mathcal{D}$ depends on the distance, we will\nend up with anomalous diffusion.",
          "reading_order": 9
        }
      ]
    },
    {
      "page_number": 200,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            108,
            58
          ],
          "text": "Exercise",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            520,
            58
          ],
          "text": "193",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            317
          ],
          "text": "We can rewrite the dimension, $d_w$ , of the walk to make the relation between the\nrandom walker and the dimensionality of the space on which it is moving more\nobvious:\n\\[ d_w=2-d+\\frac{\\mu}{v}+d-\\frac{\\beta}{v}~,\\eqno(11.59)\\]\nwhere we recognize the first term as\n\\[\\tilde{\\zeta}_R=2-d+\\frac{\\mu}{v}~,\\eqno(11.60)\\]\nand the second term as the fractal dimension, $D$ , of the spanning cluster:\n\\[ D=d-\\frac{\\beta}{v}~.\\eqno(11.61)\\]",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            331,
            520,
            385
          ],
          "text": "We have therefore established the relation\n\\[d_{w}=\\tilde{\\zeta}_{R}+D~.\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:lorenz2}\\]",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            394,
            520,
            465
          ],
          "text": "This relation is actually generalizable, so that for a random walker restricted to only\nwalk on the backbone, the dimension of the walker is\n\\begin{equation}  d_{w,B}=\\tilde{\\zeta}_R+D_B~.\\end{equation}",
          "reading_order": 4
        },
        {
          "label": "sec",
          "bbox": [
            72,
            492,
            134,
            505
          ],
          "text": "Exercises",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            527,
            520,
            591
          ],
          "text": "Exercise 11.1 (Random Walks on the Spanning Cluster) In this exercise we will\nuse and modify the program percwalk from the text to study random walks in\npercolation systems, and on the spanning cluster in particular. We want to find the\ndimension $d_w$ of a two-dimensional random walk on the spanning cluster.",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            600,
            520,
            637
          ],
          "text": "(a) Find the distance $\\langle r^2\\rangle$ as a function of the number of steps $N$ for random walks\non the spanning cluster for $p=p_c$ .",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            71,
            637,
            457,
            654
          ],
          "text": "(b) Find the dimension, $d_{w}$ of the walk, from the relation $\\langle r^{2}\\rangle \\propto N^{2/d_{w}}$",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            72,
            654,
            520,
            689
          ],
          "text": "(c) Find the distribution $P(r,N)$ for the position $r$ as a function of the number of\nsteps $N$ for a random walker on the percolation cluster.",
          "reading_order": 9
        },
        {
          "label": "para",
          "bbox": [
            71,
            689,
            484,
            702
          ],
          "text": "(d) (Advanced) Can you produce a data-collapse for the distribution $P(r,N)$",
          "reading_order": 10
        },
        {
          "label": "para",
          "bbox": [
            72,
            705,
            520,
            734
          ],
          "text": "(e) (Advanced) Can you determine the functional form of the distribution $P(r,N)$ .\nIs it a Gaussian?",
          "reading_order": 11
        },
        {
          "label": "para",
          "bbox": [
            72,
            752,
            520,
            799
          ],
          "text": "Exercise 11.2 (Random Walks on Percolation Clusters) In this exercise we will\nuse and modify the program percwalk to study random walks on the spanning\ncluster of a percolation system.",
          "reading_order": 12
        }
      ]
    },
    {
      "page_number": 201,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            58
          ],
          "text": "194",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            358,
            44,
            520,
            62
          ],
          "text": "1 Diffusion in Disordered Media",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            131
          ],
          "text": "(a) Find the distance $\\langle r^2\\rangle$ as a function of the number of steps $N$ for random walks\non the spanning cluster for $p<p_c$ and for $p>p_c$ .\n(b) Plot log $\\langle R^2\\rangle$ as a function of $N$ for various values of $p$ .",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            134,
            458,
            147
          ],
          "text": "(c) Can you find the behavior of the correlation length $\\xi$ from this plot?",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            71,
            150,
            511,
            163
          ],
          "text": "(d) Discuss the behavior of the characteristic cross-over time $t_0$ based on the plot.",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            179,
            520,
            244
          ],
          "text": "Exercise 11.3 (Self-Avoiding Walks on Fractals) (Advanced) In this exercise we\nwill use the program percwalk to study a self-avoiding random walker on the\nspanning cluster. In this exercise you will need to collect extensive statistics to be\nable to determine the scaling behavior.",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            259,
            520,
            307
          ],
          "text": "(a) Find the distance $\\langle R^2\\rangle$ as a function of the number of steps $N$ for random walks\non the spanning cluster for $p=p_c$ .\n(b) Find the dimension, $d_w$ of the walk, from the relation $\\langle R^2\\rangle\\propto N^{2/d_w}$ .",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            636,
            520,
            701
          ],
          "text": "Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0\nInternational License ( http://creativecommons.org/licenses/by/4.0/ ), which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as long as you give appropriate\ncredit to the original author(s) and the source, provide a link to the Creative Commons license and\nindicate if changes were made.",
          "reading_order": 9
        },
        {
          "label": "para",
          "bbox": [
            72,
            704,
            520,
            770
          ],
          "text": "The images or other third party material in this chapter are included in the chapter's Creative\nCommons license, unless indicated otherwise in a credit line to the material. If material is not\nincluded in the chapter's Creative Commons license and your intended use is not permitted by\nstatutory regulation or exceeds the permitted use, you will need to obtain permission directly from\nthe copyright holder.",
          "reading_order": 10
        }
      ]
    },
    {
      "page_number": 202,
      "elements": [
        {
          "label": "sec",
          "bbox": [
            72,
            98,
            448,
            116
          ],
          "text": "Dynamic Processes in Disordered Media",
          "reading_order": 0
        },
        {
          "label": "sec",
          "bbox": [
            502,
            98,
            555,
            143
          ],
          "text": "12",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            304,
            520,
            421
          ],
          "text": "In this chapter we start to address dynamical processes that generate percolation-\nlike disordered structures. We will address the scaling behavior of diffusion fronts\nfor diffusion in disordered media, and develop a theory for the front width. We\nwill address the slow displacement of fluids in porous media with the invasion-\npercolation model. For this model, we will map the model onto a percolation system\nand demonstrate how the model changes with the introduction of an additional\naspects, gravity.",
          "reading_order": 2
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            448,
            206,
            465
          ],
          "text": "12.1 Introduction",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            483,
            520,
            564
          ],
          "text": "So far, we have studied the behavior and properties of systems with disorder , such as\na model porous material in the form of a percolation system. That is, we have studied\nproperties that depend on the existing disorder of the material. In this chapter, we\nwill start to address dynamical processes that generate percolation-like disordered\nstructures, but where the structures evolve, develop, and change in time.",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            564,
            520,
            612
          ],
          "text": "The first dynamic problem we will address is the formation diffusion fronts, and\nwe will demonstrate that the front of a system of diffusing particles can be described\nas a percolation system.",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            612,
            520,
            725
          ],
          "text": "The second dynamic problem we will address is the slow displacement of one\nfluid by another in a porous medium. We will in particular demonstrate that the\ninvasion percolation process generates a fractal structure similar to the percolation\ncluster by itself - it is a process that drives itself to a critical state, similar to the\nnotion of Self-Organized Criticality [ 3 ] . We will then address how we can study\nsimilar processes in the gravity field, and, in particular, the influence of stabilizing\nand destabilizing mechanisms.",
          "reading_order": 6
        },
        {
          "label": "foot",
          "bbox": [
            72,
            806,
            396,
            845
          ],
          "text": "© The Author(s) 2024\nA. Malthe-Sørenssen, Percolation Theory Using Python, Lecture Notes\nin Physics 1029, https://doi.org/10.1007/978-3-031-59900-2_12",
          "reading_order": 7
        },
        {
          "label": "foot",
          "bbox": [
            501,
            806,
            520,
            816
          ],
          "text": "195",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 203,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            58
          ],
          "text": "196",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            304,
            44,
            520,
            62
          ],
          "text": "12 Dynamic Processes in Disordered Media",
          "reading_order": 1
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            80,
            233,
            98
          ],
          "text": "12.2 Diffusion Fronts",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            116,
            520,
            179
          ],
          "text": "The first dynamical problem we will address is the structure of a diffusion front [ 31 ]\non a square lattice. One example of such a process is the two-dimensional diffusion\nof particles from a source at $x=0$ into the $x>0$ plane, when particles are not\nallowed to overlap. The system of diffusing particles is illustrated in Fig. 12.1 .",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            197,
            528,
            403
          ],
          "text": "Exact Solution For this problem we know the exact solution for the concentration,\n$c(x,t)$ , of particles, corresponding to the occupation probability $P(x,t)$ . The\nsolution to the diffusion equation with a constant concentration at one boundary,\nhere $P(x=0,t)=1$ , is the error function, which is the integral over a Gaussian\nfunction:\n\\[ P(x,t)=1-\\mathrm{erf}(\\frac{x}{\\sqrt{D t}})~,\\eqno(12.1)\\]\nwhere the error function is defined as the integral:\n\\[\\mathrm{erf}(u)=\\frac{2}{\\sqrt{2\\pi}}\\int_{0}^{u}e^{\\frac{-v^2}{2}}dv~.\\eqno(12.2)\\]",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            412,
            520,
            448
          ],
          "text": "This solution produces the expected variance $\\langle x^2 \\rangle=Dt$ , where $D$ is the diffusion\nconstant for the particles. There is no $y$ (or $z$ ) dependence for the solution.",
          "reading_order": 5
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_203_figure_006.png)",
          "figure_path": "figures/percolation_studies_page_203_figure_006.png",
          "bbox": [
            72,
            483,
            513,
            707
          ],
          "reading_order": 6
        },
        {
          "label": "cap",
          "bbox": [
            72,
            716,
            520,
            797
          ],
          "text": "Fig. 12.1 Illustration of the diffusion front. Particles are diffusing from a source at the left\nside. We address the front separating the particles connected to the source from the particles not\nconnected to the source. ( a ) The average distance is given by $x_c$ shown in the figure. The width\nof the front, $\\xi(x_c)$ , as $x_c$ is also illustrated. The different clusters are colored to distinguish them\nfrom each other. The close-up in figure ( b ) illustrates the finer details of the diffusion fronts and\nthe local cluster geometries",
          "reading_order": 7
        }
      ]
    },
    {
      "page_number": 204,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            179,
            58
          ],
          "text": "12.2 Diffusion Fronts",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            512,
            58
          ],
          "text": "19",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            322
          ],
          "text": "Structure of Clusters Connected to Diffusion Front We will address the struc-\nture of connected clusters of diffusing particles. Two particles are connected if they\nare neighbors so that they inhibit each others diffusion in a particular direction.\nIf we fix $t$ , we notice that the system will be compact close to $x=0$ , and that\nthere only will be a few thinly spread particles when $x\\gg\\sqrt{Dt}$ . In this system,\nthe occupation probability varies with both time $t$ and spatial position $x$ . However,\nwe expect the system of diffusing particles to be connected to the source out to a\ndistance $x_c$ corresponding to the point where the occupation probability is equal to\nthe percolation threshold $p_c$ for the lattice type studied. That is:\n$$P(x_c, t)=p_c~, ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            340,
            520,
            537
          ],
          "text": "With of the Diffusion Front What is the width of the diffusion front? For a given\ntime $t$ , the occupation probability decreases with distance from $x_c$ . The correlation\nlength will therefore depend on the distance $\\delta x=x-x_c$ to $x_c$ . We expect that\na cluster may be connected to the front if it is within a distance $\\xi$ of $x_c$ . Particles\nthat are further away than the local correlation length, $\\xi$ , will not be connected over\nsuch distances, and will therefore not be connected. Particles that are closer to $x_c$\nthan $\\xi$ will typically by connected through some connecting path. We will therefore\nintroduce $\\xi$ as the width of the front, corresponding to the distance at which the\nlocal correlation length, due to the occupation probability $P(x,t)$ , is equal to the\ndistance from $x_c$ . The local correlation length at a position $x$ , $\\xi(x)$ , is given as\n$$\\xi(x)=\\xi_0|P(x,t)-p_c|^{-v}~,\\eqno(12.4)$$",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            546,
            520,
            618
          ],
          "text": "The distance $w$ at which $\\xi(x_c+w)=w$ gives the width of the front. We can write\nthis self-consistency equation for $w$ as\n$$w=\\xi_0|P(x+w,t)-p_c|^{-v}~.\\eqno(12.5)$$",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            627,
            520,
            780
          ],
          "text": "Let us introduce a Taylor expansion of $P(x)$ around $x=x_c$ :\n\\begin{equation}\n P(x,t)\\simeq P(x_c,t)+\\left.\\frac{dP}{dx}\\right|_{x_c}(x-x_c)~,\\label{eq:p2}\n\\end{equation}$$\nwhere we recognize that $x_c\\propto \\sqrt{Dt}$ gives\n\\begin{equation}\n\\left.\\frac{dP}{dx}\\right|_{x_c}\\propto \\frac{1}{\\sqrt{Dt}}\\propto \\frac{1}{x_c}~.\\label{eq:p3}\n\\end{equation}",
          "reading_order": 5
        }
      ]
    },
    {
      "page_number": 205,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            58
          ],
          "text": "198",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            304,
            44,
            512,
            62
          ],
          "text": "12 Dynamic Processes in Disordered Medi",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            394,
            215
          ],
          "text": "We insert this into the self-consistency Eq. 12.5 ) getting\n\\[w=\\xi_0|w~\\frac{dP}{dx}\\bigg|_{x_c}~|^{-v}\\propto(w/x_c)^{-v}~,\\]\nwhich gives\n\\[w\\propto x_c^{\\nu/(1+\\nu)}~.\\]",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            484,
            116,
            520,
            134
          ],
          "text": "(12.8)",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            231,
            520,
            277
          ],
          "text": "The width of the front therefore scales with the average position of the front, and\nthe scaling exponent is related to the scaling exponent of the correlation length for\nthe percolation problem.",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            295,
            520,
            376
          ],
          "text": "What Development What happens in this system with time? Since $x_c$ is increasing\nwith time, we see that the relative width decreases:\n\\[\n    \\frac{w}{x_c} \\propto \\frac{x^{v/(1+v)}_c}{x_c} \\propto x^{-\\frac{1}{1+v}}_c~.\n\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:thmbound}\n  \\]",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            385,
            520,
            456
          ],
          "text": "This effect will also become apparent under renormalization. Applying a renor-\nmalization scheme with length $b$ , will result in a change in the front width by a\nfactor $b^{v/(1+v)}$ , but along the $y$ -direction the rescaling will simply be by a factor $b$ .\nSuccessive applications will therefore make the front narrower and narrower.",
          "reading_order": 6
        },
        {
          "label": "sub_sec",
          "bbox": [
            72,
            483,
            260,
            501
          ],
          "text": "12.3 Invasion Percolation",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            519,
            520,
            566
          ],
          "text": "We will now study the slow injection of a non-wetting fluid into a porous medium\nsaturated with a wetting fluid. In the limit of infinitely slow injection, this process is\ntermed invasion percolation for reasons that will soon become obvious [ 12 , 38 ] .",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            72,
            582,
            520,
            806
          ],
          "text": "Physical System: Fluid Saturated Porous Medium When a non-wetting fluid is\ninjected slowly into a saturated porous medium, the pressure in the non-wetting fluid\nmust exceed the capillary pressure in a pore-throat for the fluid to propagate from\none pore to the next, as illustrated in Fig. 12.2 . The pressure difference, $\\delta P$ needed\ncorresponds to the capillary pressure $P_c$ , given as\n$$P_c=\\frac{\\Gamma}{\\epsilon}~, ~~~~~~~~~~~~~~~(12.11)$$\nwhere $\\Gamma$ is the interfacial surface tension, and $\\epsilon$ is the characteristic size of the\npore-throats in the porous medium. However, there will be some disorder present in\nthe porous medium corresponding to local variation in the characteristic pore sizes\n$\\epsilon$ . This will lead to a distribution of the capillary pressure thresholds, $P_c$ , needed\nto invade a particular pore. We will assume that the medium can be described as",
          "reading_order": 9
        }
      ]
    },
    {
      "page_number": 206,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            197,
            62
          ],
          "text": "12.3 Invasion Percolation",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            520,
            58
          ],
          "text": "199",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            448,
            520,
            547
          ],
          "text": "a set of pores connected with pore throats with a uniform distribution of capillary\npressure thresholds, and we will assume that the capillary pressure thresholds are\nnot correlated but statistically independent. We can therefore rescale the pressure\nscale, by subtracting the minimum pressure threshold and dividing by the range\nof pressure thresholds, and describe the system as a matrix of critical pressures $P_i$\nrequired to invade a particular site.",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            564,
            520,
            692
          ],
          "text": "Modeling the Fluid Displacement Process The fluid displacement process can be\nmodeled by assuming that all the sites on the left side of the matrix are in contact\nwith the invading fluid. The pressure in the invading fluid is increased slowly,\nuntil the fluid invades the connected site with the lowest pressure threshold. This\ngenerates a new set of invaded sites in contact with the inlet, and a new set of\nneighboring sites. The invasion process continues until the invading fluid reaches the\nopposite side. Further injection will then not produce any further fluid displacement,\nthe fluid will flow through the system through the open path generated.",
          "reading_order": 3
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_206_figure_004.png)",
          "figure_path": "figures/percolation_studies_page_206_figure_004.png",
          "bbox": [
            71,
            80,
            520,
            304
          ],
          "reading_order": 4
        },
        {
          "label": "cap",
          "bbox": [
            72,
            313,
            520,
            421
          ],
          "text": "Fig. 12.2 Illustration of the invasion percolation process in which a non-wetting fluid is slowly\ndisplacing a wetting fluid. The left figure shows the interface in a pore throat: the pressure in the\ninvading fluid must exceed the pressure in the displaced fluid by an amount corresponding to the\ncapillary pressure $P_c=\\varGamma/\\epsilon$ , where $\\varGamma$ is the interfacial surface tension, and $\\epsilon$ is a characteristic\nlength for the pore throat. The right figure illustrates the invasion front after injection has started.\nThe fluid may invade any of the sites along the front indicated by small circles. The site with the\nsmallest capillary pressure threshold will be invaded first, changing the front and exposing new\nboundary sites",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            707,
            520,
            806
          ],
          "text": "Computational Implementation How can we transfer this model description to a\ncomputational model? We introduce a lattice of pores to represent the pore throat\nsizes. For each lattice site, there is a critical pore size into that pore, with a critical\npressure, $p_i$ , needed to push the fluid into this pore. We map the pressure onto a\nscale from 0.0 to 1.0, where 1.0 represents the pressure needed to invade all pores\nin the lattice.",
          "reading_order": 6
        }
      ]
    },
    {
      "page_number": 207,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            90,
            58
          ],
          "text": "200",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            304,
            44,
            520,
            62
          ],
          "text": "12 Dynamic Processes in Disordered Media",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            143
          ],
          "text": "We then start to gradually increase the pressure in the fluid and allow the fluid to\ninvade from the left side of the lattice. Let us say we have increased the pressure to\nthe value $p$ ( $0\\leq p\\leq1$ ). This would mean that all sites that have $p_i\\leq p$ and that\nare connected to the left side would be invaded.",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            143,
            520,
            209
          ],
          "text": "This corresponds to a percolation problem. If we make a percolation system with\noccupation probability $p$ , then the fluid will have invaded all the clusters that are\nconnected to the left side. Thus, we have mapped the invasion percolation problem\nonto a percolation problem. Let us implement this approach.",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            212,
            520,
            241
          ],
          "text": "First, we generate a random lattice of critical pressures and an array of pressures\n$p$ that we will loop through:",
          "reading_order": 4
        },
        {
          "label": "code",
          "bbox": [
            79,
            259,
            484,
            341
          ],
          "text": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.ndimage import measurements\nL = 400\nz = np.random.rand(L,L) # Random distribution of thresholds\np = np.arange(0.0,0.7,0.01)",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            358,
            520,
            390
          ],
          "text": "We step gradually through this set of p-values, finding the clusters of connected\nsites that have p-values smaller than p [npstep]",
          "reading_order": 6
        },
        {
          "label": "code",
          "bbox": [
            80,
            412,
            322,
            449
          ],
          "text": "for nstep in range(len(p)-1):\nzz = z<p[nstep]\nlw,num = measurements.label(zz)",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            465,
            520,
            547
          ],
          "text": "Then, we find the labels of all the clusters on the left side of the lattice. All the\nclusters with these labels are connected to the left side and are part of the invasion\npercolation cluster called cluster . We do this in two steps. First, we find a list of\nunique labels that are on the left side. Then we find all the clusters with labels that\nare in this list using the numpy-function isin:",
          "reading_order": 8
        },
        {
          "label": "code",
          "bbox": [
            107,
            570,
            405,
            620
          ],
          "text": "leftside = lw[:,0]\nleftnonzero = leftside[np.where(leftside>0)]\nuniqueleftside = np.unique(leftnonzero)\ncluster = np.isin(lw,uniqueleftside)",
          "reading_order": 9
        },
        {
          "label": "para",
          "bbox": [
            72,
            636,
            520,
            702
          ],
          "text": "Then we make a matrix that stores at what time t (pressure value p(t)) a particular\nsite was invaded. This is done by simply adding a 1 for all set sites at time t to a\nmatrix pcluster. The first clusters invaded will then have the highest value in the\npcluster matrix. We use the pcluster matrix to visualize the dynamics.",
          "reading_order": 10
        },
        {
          "label": "para",
          "bbox": [
            107,
            724,
            332,
            734
          ],
          "text": "pcluster = pcluster + 1.0*cluster",
          "reading_order": 11
        },
        {
          "label": "para",
          "bbox": [
            72,
            752,
            520,
            784
          ],
          "text": "Finally, we check if the fluid has reached the right-hand side by comparing the labels\non the left-hand side with those on the right-hand side. If any labels are the same,",
          "reading_order": 12
        }
      ]
    },
    {
      "page_number": 208,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            197,
            62
          ],
          "text": "12.3 Invasion Percolation",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            520,
            58
          ],
          "text": "201",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            112
          ],
          "text": "there is a cluster connecting the two sides (a spanning cluster), and the fluid invasion\nprocess stops:",
          "reading_order": 2
        },
        {
          "label": "code",
          "bbox": [
            107,
            134,
            415,
            183
          ],
          "text": "# Check if it has reached the right hand side\nspan = np.intersect1d(lw[:,1],lw[:,-1])\nif (len(span[np.where(span > 0)])>0):\nbreak",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            205,
            520,
            232
          ],
          "text": "The whole program for the simulation, including initialization of pcluster is\nthen:",
          "reading_order": 4
        },
        {
          "label": "code",
          "bbox": [
            79,
            250,
            490,
            537
          ],
          "text": "# Example program for studying invasion percolation problems\n# NOTE: This is not an optimal but an educational algorithm\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.ndimage import measurements\nL = 400\np = np.arange(0.0,0.7,0.01)\nz = np.random.rand(L,L) # Random distribution of thresholds\npcluster = np.zeros((L,L),float)\nfor nstep in range(len(p)-1):\nzz = z<p[nstep]\nlw,num = measurements.label(zz)\nleftside = lw[:,0]\nleftnonzero = leftside[np.where(leftside>0)]\nuniqueleftside = np.unique(leftnonzero)\ncluster = np.isin(lw,uniqueleftside)\npcluster = pcluster + 1.0*cluster\n# Check if it has reached the right hand side\nspan = np.intersect1d(lw[:,1],lw[:,-1]) # Test perc\nif (len(span[np.where(span > 0)])>0): break\nplt.imshow(np.log(pcluster),origin=\"lower\")",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            563,
            520,
            707
          ],
          "text": "Results for Fluid Displacement Process The resulting pattern of injected nodes is\nillustrated in Fig. 12.3 , where the colors indicate the pressure at which the injection\ntook place. It can be seen from the figure that the injection occurs in bursts. When\na site is injected, many new connected neighbors are available as possible sites to\ninvade. As the pressure approaches the pressure needed to percolate to the other\nside, these newly appearing sites of the front will typically also be invaded, and\ninvasion will occur in gradually larger regions. These bursts have been characterized\nby Furuberg et al. [ 12 ] , and it can be argued that the distribution of burst sizes as\nwell as the time between bursts are power-law distributed.",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            724,
            520,
            800
          ],
          "text": "Mapping Invasion Percolation onto Percolation Based on this algorithmic model\nfor the fluid displacement process, it is also easy to relate the invasion percolation\nproblem to ordinary percolation. For an injection pressure of $p$ , all sites with critical\npressure below or equal to $p$ are in principle available for the injection process.\nHowever, it is only the clusters of such sites connected to the left side that will",
          "reading_order": 7
        }
      ]
    },
    {
      "page_number": 209,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            62
          ],
          "text": "202",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            304,
            44,
            520,
            62
          ],
          "text": "12 Dynamic Processes in Disordered Media",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_209_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_209_figure_002.png",
          "bbox": [
            72,
            80,
            520,
            528
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            537,
            520,
            567
          ],
          "text": "Fig. 12.3 Illustration of the invasion percolation cluster. The color-scale indicates normalized\npressure at which the site was invaded",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            599,
            520,
            806
          ],
          "text": "actually be invaded, since the invasion process requires a connected path from the\ninlet to the site for a site to be filled. We will therefore expect that the width of the\ninvasion percolation front corresponds to the correlation length $\\xi=\\xi_0(p_c-p)^{-v}$\nas $p$ approaches the percolation threshold $p_c$ , because this is the length at which\nclusters are connected. That is, clusters that are a distance $\\xi$ from the left side will\ntypically be connected to the left side, and therefore connected, whereas clusters that\nare further away than $\\xi$ will typically not be connected and therefore not invaded.\nThis shows that the critical pressure will correspond to $p_c$ . This also shows that\nwhen the fluid reaches the opposite side, the system is exactly at $p_c$ , and we expect\nthe invasion percolation cluster to have the same scaling properties as the spanning\ncluster at $p=p_c$ . There will be small differences, because the invasion percolation\ncluster also contains smaller clusters connected to the left side, but we do not expect\nthese to change the scaling behavior of the cluster. That is, we expect the fractal",
          "reading_order": 4
        }
      ]
    },
    {
      "page_number": 210,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            197,
            62
          ],
          "text": "12.3 Invasion Percolation",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            520,
            58
          ],
          "text": "203",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            511,
            112
          ],
          "text": "dimension of the invasion percolation cluster to be $D$ . This implies that the densit\nof the displaced fluid decreases with system size.",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            125,
            520,
            254
          ],
          "text": "Invasion Percolation with and Without Trapping The process outlined above\ndoes, however, not contain all the essential physics of the fluid displacement process.\nFor displacement of an incompressible fluid, a region that is fully bounded by the\ninvading fluid cannot be invaded, since the displaced fluid does not have any place to\ngo. Instead, we should study the process called invasion percolation with trapping. It\nhas been found that when trapping is included, the fractal dimension of the invasion\npercolation cluster is slightly smaller [ 10 ] . In two dimensions, the dimension is $D\\simeq$\n1.82.",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            259,
            520,
            340
          ],
          "text": "This difference between the process with and without trapping disappears for\nthree-dimensional geometries because trapping become unlikely in dimensions\nhigher than 2. Indeed, direct numerical modeling shows that the fractal dimension\nfor both the ordinary percolation system and invasion percolation is $D\\simeq 2.5$ for\ninvasion percolation with and without trapping.",
          "reading_order": 4
        },
        {
          "label": "sec",
          "bbox": [
            72,
            367,
            206,
            386
          ],
          "text": "Gravity Stabilization",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            403,
            520,
            627
          ],
          "text": "The invasion percolation cluster displays self-similar scaling similar to that of\nordinary percolation. This implies that the position $h(x,\\,p)$ of the fluid front as\na function of the non-dimensional applied pressure $p$ is given as the correlation\nlength — since this is how far clusters connected to the left side typically are\nconnected. That is, when $p$ approaches $p_c$ , the average position of the front is\n$\\bar{h}(x,\\,p)=\\xi(p)=\\xi_0(p_c-p)^{-v}$ . The width, $w(p)$ of the front is also given as\nthe correlation length:\n$$ w(p)=\\xi_0(p_c-p)^{-v}~, \\eqno{(12.12)}$$\nas $p$ approaches $p_c$ both the front position and the front width diverges, that is, both\nthe front position $\\bar{h}$ and the width, $w$ , are proportional to the system size $L$ :\n$$\\bar{h}\\propto w\\propto L~, \\eqno{(12.13)}$$",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            645,
            520,
            757
          ],
          "text": "However, when the system size increases, we would expect other stabilizing effects\nto become important. For a very small, but finite fluid injection velocity, the viscous\npressure drop will eventually become important and comparable to the capillary\npressure. Also, for any deviation from a completely flat system for a system with a\nslight different in densities, the effect of the hydrostatic pressure term will eventually\nbecome important. We will now demonstrate how we may address the effect of such\na stabilizing (or destabilizing) effect [ 6 , 25 ] .",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            770,
            520,
            806
          ],
          "text": "Invasion Percolation in a Gravity Field Let us assume that the invasion perco-\nlation occurs in the gravity field. This implies that the pressure needed to invade a",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 211,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            58
          ],
          "text": "204",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            304,
            44,
            520,
            62
          ],
          "text": "12 Dynamic Processes in Disordered Media",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            520,
            161
          ],
          "text": "pore depends both on the capillary pressure, and on a hydrostatic term. The pressure\n$P_{i}^{c}$ needed to invade site $i$ at vertical position $x_{i}$ in the gravity field is:",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            176,
            520,
            331
          ],
          "text": "We can again normalize the pressures, resulting in\n\\[p_i^C=p_i^0+\\frac{\\Delta \\rho g}{\\varGamma \\epsilon^2}x_i'~,\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:powerlaw}\\]\nwhere the coordinates are measured in units of the pore size, $\\epsilon$ , which is the unit of\nlength in our system. The last term is called the Bond number:\n\\[Bo=\\frac{\\Delta \\rho g}{\\varGamma \\epsilon^2}~,\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:powerlaw}\\]",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            340,
            520,
            439
          ],
          "text": "Here, we will include the effect of the bond number in a single number $g$ , so that\nthe critical pressure at site $i$ is:\n\\[p_{i}^c=p_{i}^0+g x_{i}^{'}~,\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:fondrvc}\\]\nwhere $p_{i}^0$ is a random number between 0 and 1.",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            454,
            520,
            483
          ],
          "text": "Computational Implementation We implement this by changing the values of the\npressure threshold $p_i$ in the computational code:",
          "reading_order": 5
        },
        {
          "label": "code",
          "bbox": [
            79,
            501,
            367,
            540
          ],
          "text": "g = 0.001\ngrad = g*np.meshgrid(range(L),range(L))[0]\nz = z + grad",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            563,
            254,
            576
          ],
          "text": "The whole program then becomes",
          "reading_order": 7
        },
        {
          "label": "code",
          "bbox": [
            79,
            598,
            511,
            797
          ],
          "text": "# Now we add the effect on gravity\n- modifying the values of z\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.ndimage import measurements\nL = 400\np = np.arange(0.0,0.7,0.01)\nz = np.random.rand(L,L) # Random distribution of thresholds\ng = 0.001\ngrad = g*np.meshgrid(range(L),range(L))[0]\nz = z + grad\npcluster = np.zeros((L,L),float)\nfor nstep in range(len(p)-1):\nzz = z<p[nstep]\nlw,num = measurements.label(zz)\nleftside = lw[:,0]",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 212,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            197,
            62
          ],
          "text": "12.3 Invasion Percolation",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            520,
            58
          ],
          "text": "205",
          "reading_order": 1
        },
        {
          "label": "code",
          "bbox": [
            79,
            80,
            457,
            206
          ],
          "text": "leftnonzero = leftside[np.where(leftside>0)]\nuniqueleftside = np.unique(leftnonzero)\ncluster = np.isin(1w,uniqueleftside)\npcluster = pcluster + 1.0*cluster\n# Check if it has reached the right hand side\nspan = np.intersect1d(1w[:,1],1w[:,-1]) # Test perc\nif (len(span[np.where(span > 0)])>0):\nbreak\nplt.imshow(np.log(pcluster),origin=\"lower\")",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            224,
            520,
            277
          ],
          "text": "Visualization of Results The resulting invasion percolation fronts for various\nnumbers of $g$ is illustrated in Fig. 12.4 . How can we understand the gradual\nflattening of the front as $g$ increases from $g$ ?",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            294,
            520,
            376
          ],
          "text": "Front Width Analysis This problem is similar to the diffusion front problem. For\nan applied pressure $p$ the front will typically be connected up to an average distance\n$x_c$ given as\n\\[ p=p^0+x_cg~.\\addtocounter{equation}{1}\\tag{\\theequation}\\label{eq:fondr}\\]",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            385,
            520,
            519
          ],
          "text": "The front will also extend beyond the average front position. The occupation\nprobability at a distance $a$ from the front is $p'=p_c-ag$ , since fewer sites will be\nset beyond the front due to the stabilizing term $g$ . A site at a distance $a$ is connected\nto the front if this distance $a$ is shorter to or equal to the correlation length for the\noccupation probability $p'$ at this distance. The maximum distance $a$ for which a site\nis connected back to the front therefore occurs when\n\\[\na=\\xi(p')=\\xi_0(p_c-p')^{-v}~.~\\eqno{(12.19)}\n\\]",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            536,
            520,
            645
          ],
          "text": "This gives\n\\[a=\\xi(p^{'})=\\xi_0(p_c-p^{'})^{-v}=\\xi_0(p_c-(p_c-ag))^{-v}=\\xi_0(ag)^{-v}a~,\\qquad (12.20)\\]\nand\n\\[a\\propto g^{-v/(1+v)}~,\\qquad \\qquad \\qquad \\qquad \\qquad (12.21)\\]",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            663,
            520,
            743
          ],
          "text": "We leave it as an exercise to find the form of the position $h(p,\\,g)$ , and the width,\n$w(p,\\,g)$ , as a function of $p$ and $g$ . We observe that the width has a reasonable\ndependence on $g$ . When $g$ approaches 0, the width diverges. This is exactly what\nwe expect since the limit $g=0$ corresponds to the limit of ordinary invasion\npercolation.",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            743,
            520,
            807
          ],
          "text": "This discussion demonstrates a general principle that we can use to study several\nstabilizing effects, such as the effect of viscosity or other material or process\nparameters that affect the pressure needed to advance the front. The introduction\nof a finite width or characteristic length $\\xi$ that can systematically be varied in order",
          "reading_order": 8
        }
      ]
    },
    {
      "page_number": 213,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            58
          ],
          "text": "206",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            304,
            44,
            520,
            62
          ],
          "text": "12 Dynamic Processes in Disordered Media",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_213_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_213_figure_002.png",
          "bbox": [
            72,
            80,
            520,
            564
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            573,
            520,
            611
          ],
          "text": "Fig. 12.4 Illustration of the gravity stabilized invasion percolation cluster for $g=0$ , $g=10^{-4}$ ,\n$g=10^{-3}$ , and $g=10^{-2}$ . The color-scale indicates the normalized pressure at which the site was\ninvaded",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            636,
            511,
            672
          ],
          "text": "to address the behavior of the system when the characteristic length diverges is als\na powerful method of both experimental and theoretical use.",
          "reading_order": 4
        },
        {
          "label": "sec",
          "bbox": [
            72,
            705,
            224,
            720
          ],
          "text": "Gravity Destabilization",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            734,
            520,
            816
          ],
          "text": "The gravity destabilized invasion percolation process corresponds to the case when\na less dense fluid is injected at the bottom of a denser fluid. This is similar to the\nprocess known as secondary migration, where the produced oil is migrating up\nthrough the sediments filled with denser water. Examples of the destabilizing front\nis shown in Fig. 12.5 .",
          "reading_order": 6
        }
      ]
    },
    {
      "page_number": 214,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            197,
            62
          ],
          "text": "12.3 Invasion Percolation",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            493,
            44,
            512,
            58
          ],
          "text": "20",
          "reading_order": 1
        },
        {
          "label": "fig",
          "text": "![Figure](figures/percolation_studies_page_214_figure_002.png)",
          "figure_path": "figures/percolation_studies_page_214_figure_002.png",
          "bbox": [
            72,
            80,
            520,
            564
          ],
          "reading_order": 2
        },
        {
          "label": "cap",
          "bbox": [
            72,
            573,
            520,
            618
          ],
          "text": "Fig. $g=-10^{-4}$ Illustration of the gravity de-stabilized invasion percolation cluster for $g=0$ , , $g=-10^{-3}$ , and $g=-10^{-2}$ . The color-scale indicates normalized pressure at which the\nsite was invaded",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            645,
            520,
            824
          ],
          "text": "We can make a similar argument for the case when $g<0$ , but in this case the\nfront is destabilized, and the correlation length $\\xi\\propto(-g)^{-v/(1+v)}$ corresponds to the\nwidth of the finger extending front the front. The extending finger can be modeled\nas a sequence of blobs of size $\\xi$ extending from the flat surface. This implies that the\nregion responsible for the transport of oil in secondary migration is essentially a one-\ndimensional structure: lines with a finite width $w$ . The amount of hydrocarbons left\nin the sediments during this process is therefore negligible. However, there will be\nother effects, such as the finite viscosity and the rate of production compared to the\nrate of flow, which will induce more than one finger.Gravity destabilized invasion\npercolation is used as a modeling tool in studies of petroleum plays and commercial\nsoftware packages are available for such simulation.",
          "reading_order": 4
        }
      ]
    },
    {
      "page_number": 215,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            58
          ],
          "text": "208",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            304,
            44,
            512,
            62
          ],
          "text": "12 Dynamic Processes in Disordered Medi",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            63,
            80,
            520,
            162
          ],
          "text": "Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0\nInternational License ( http://creativecommons.org/licenses/by/4.0/ ), which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as long as you give appropriate\ncredit to the original author(s) and the source, provide a link to the Creative Commons license and\nindicate if changes were made.\nThe images or other third party material in this chapter are included in the chapter's Creative",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            162,
            518,
            216
          ],
          "text": "Commons license, unless indicated otherwise in a credit line to the material. If material is not\nincluded in the chapter's Creative Commons license and your intended use is not permitted by\nstatutory regulation or exceeds the permitted use, you will need to obtain permission directly from\nthe copyright holder.",
          "reading_order": 3
        }
      ]
    },
    {
      "page_number": 216,
      "elements": [
        {
          "label": "sec",
          "bbox": [
            72,
            98,
            179,
            116
          ],
          "text": "References",
          "reading_order": 0
        },
        {
          "label": "para",
          "bbox": [
            79,
            259,
            520,
            286
          ],
          "text": "1. J. Adler, Y. Meir, A. Aharony, A.B. Harris, L. Klein, Low-concentration series in general\ndimension. J. Stat. Phys. 58 (3), 511–538 (1990)",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            78,
            286,
            520,
            313
          ],
          "text": "2. A. Aharony, Y. Gefen, A. Kapitulnik, Scaling at the percolation threshold above six dimen-\nsions. J. Phys A Math. General 17 (4), L197–L202 (1984)",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            78,
            313,
            520,
            350
          ],
          "text": "3. P. Bak, How Nature Works: The Science of Self-Organized Criticality (Copernicus, Göttingen,\n1996)\n4. D.J. Bergman, Y. Kantor, Critical properties of an elastic fractal. Phys. Rev. Lett. 53 (6), 511–",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            77,
            350,
            520,
            377
          ],
          "text": "514 (1984)\n5. H.A. Bethe, Statistical theory of superlattices. Proc. R. Soc. Lond. A 150 , 552–575 (1935)",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            78,
            378,
            520,
            429
          ],
          "text": "6. A. Birovljev, L. Furuberg, J. Feder, T. Jssang, KJ. Mly, A. Aharony, Gravity invasion\npercolation in two dimensions: Experiment and simulation. Phys. Rev. Lett. 67 (5), 584–587\n(1991)\n7. J.L. Cardy, Introduction to theory of finite-size scaling, in Current Physics–Sources and",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            79,
            429,
            520,
            458
          ],
          "text": "Comments. Finite-Size Scaling, vol. 2 (Elsevier, Amsterdam, 1988), pp. 1–7\n8. K. Christensen, N.R. Moloney, Complexity and Criticality (Imperial College Press, London,",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            78,
            458,
            520,
            470
          ],
          "text": "2015年,\n中国大陆在中国大陆的广东省人民政府驻华南地区下辖的批复(川府)。",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            78,
            473,
            475,
            484
          ],
          "text": "9. P.G. de Gennes, La percolation: Un concept unificateur. La Recherche 7, 919 (1976)",
          "reading_order": 9
        },
        {
          "label": "para",
          "bbox": [
            72,
            484,
            520,
            510
          ],
          "text": "10. M.M. Dias, D. Wilkinson, Percolation with trapping. J. Phys. A Math. General 19(15), 3131-\n3146 (1986)",
          "reading_order": 10
        },
        {
          "label": "para",
          "bbox": [
            72,
            510,
            520,
            537
          ],
          "text": "11. S. Feng, P.N. Sen, Percolation on elastic networks: new exponent and threshold. Phys. Rev.\nLett. 52 (3), 216–219 (1984)",
          "reading_order": 11
        },
        {
          "label": "para",
          "bbox": [
            72,
            537,
            520,
            564
          ],
          "text": "12. L. Furuberg, J. Feder, A. Aharony, T. Jøssang, Dynamics of invasion percolation. Phys. Rev.\nLett. 61 (18), 2117–2120 (1988)",
          "reading_order": 12
        },
        {
          "label": "para",
          "bbox": [
            72,
            564,
            520,
            591
          ],
          "text": "13. Y. Gefen, A. Aharony, S. Alexander, Anomalous diffusion on percolating clusters. Phys. Rev.\nLett. 50 (1), 77–80 (1983)",
          "reading_order": 13
        },
        {
          "label": "para",
          "bbox": [
            72,
            591,
            520,
            619
          ],
          "text": "14. G.R. Grimmett, Percolation. Grundlehren der mathematischen Wissenschaften, 2nd edn.\n(Springer, Berlin/Heidelberg, 1999)",
          "reading_order": 14
        },
        {
          "label": "para",
          "bbox": [
            72,
            619,
            520,
            645
          ],
          "text": "15. S. Havlin, D. Ben-Avraham, Diffusion in disordered media. Adv. Phys. 36 (6), 695–798 (1987)\n16. H.J. Herrmann, H.E. Stanley, The fractal dimension of the minimum path in two- and three-",
          "reading_order": 15
        },
        {
          "label": "para",
          "bbox": [
            72,
            645,
            520,
            672
          ],
          "text": "dimensional percolation. J. Phys. A Math. General 21 (17), L829-L833 (1988)\n17. D.C. Hong, H.E. Stanley, Cumulant renormalisation group and its application to the incipient",
          "reading_order": 16
        },
        {
          "label": "para",
          "bbox": [
            72,
            672,
            520,
            685
          ],
          "text": "(a) A new model of a single-qubit system with an energy source, and its potential for",
          "reading_order": 17
        },
        {
          "label": "para",
          "bbox": [
            72,
            688,
            520,
            712
          ],
          "text": "18. A. Hunt, R. Ewing, B. Ghanbarian, Percolation Theory for Flow in Porous Media . Lecture\nNotes in Physics, 3rd edn. (Springer, Berlin, 2014)",
          "reading_order": 18
        },
        {
          "label": "para",
          "bbox": [
            72,
            715,
            520,
            738
          ],
          "text": "19. L.P. Kadanoff, Scaling laws for ising models near ${T}_{c}$ . Phys. Phys. Fizika 2 (6), 263–\n272 (1966)",
          "reading_order": 19
        },
        {
          "label": "para",
          "bbox": [
            72,
            741,
            520,
            765
          ],
          "text": "20. Y. Kantor, I. Webman, Elastic properties of random percolating systems. Phys. Rev. Lett.\n52 (21), 1891–1894 (1984)",
          "reading_order": 20
        },
        {
          "label": "foot",
          "bbox": [
            72,
            806,
            396,
            845
          ],
          "text": "© The Author(s) 2024\nA. Malthe-Sørenssen, Percolation Theory Using Python, Lecture Notes\nin Physics 1029, https://doi.org/10.1007/978-3-031-59900-2",
          "reading_order": 21
        },
        {
          "label": "foot",
          "bbox": [
            501,
            806,
            520,
            816
          ],
          "text": "209",
          "reading_order": 22
        }
      ]
    },
    {
      "page_number": 217,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            90,
            58
          ],
          "text": "210",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            466,
            44,
            520,
            58
          ],
          "text": "References",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            512,
            108
          ],
          "text": "21. H. Kesten, Percolation Theory for Mathematicians. Progress in Probability (Birkhäuser, Base\n1982)",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            108,
            520,
            134
          ],
          "text": "22. P.R. King, M. Masihi, Percolation Theory in Reservoir Engineering (World Scientific (Europe),\nLondon, 2018)",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            134,
            475,
            160
          ],
          "text": "23. S. Kirkpatrick, Percolation and conduction. Rev. Mod. Phys. 45 (4), 574–588 (1973)\n24. B.J. Last, D.J. Thouless, Percolation theory and electrical conductivity. Phys. Rev. Let",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            160,
            520,
            189
          ],
          "text": "1719-1721 (1971)\n25. P. Meakin, A. Birovljev, V. Frette, J. Feder, T. Jøssang, Gradient stabilized and destabilized",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            189,
            520,
            214
          ],
          "text": "invasion percolation. Phys. A Stat. Mech. Appl. 191 (1), 227–239 (1992)\n26. Y. Meir, R. Blumenfeld, A. Aharony, A.B. Harris, Series analysis of randomly diluted nonlinear",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            214,
            520,
            232
          ],
          "text": "_",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            232,
            520,
            269
          ],
          "text": "27. S. Roux, Relation between elastic and scalar transport exponent in percolation. J. Numer. Math.\n19 (6), L351–L356 (1986)\n28. M. Sahimi, Relation between the critical exponent of elastic percolation networks and the",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            72,
            269,
            520,
            296
          ],
          "text": "conductivity and geometrical exponents. J. Phys. C Solid State Phys. 19 (4), L79–L83 (1986)\n29. M. Sahimi, J.D. Goddard, Elastic percolation models for cohesive mechanical failure in",
          "reading_order": 9
        },
        {
          "label": "para",
          "bbox": [
            72,
            296,
            520,
            323
          ],
          "text": "heterogeneous systems. Phys. Rev. B Condens. Matter Mater. Phys. 33 (11), 7848–7851 (1986)\n30. M. Sahini, M. Sahimi, Applications Of Percolation Theory (Wiley Press, Hoboken, 2003)",
          "reading_order": 10
        },
        {
          "label": "para",
          "bbox": [
            72,
            324,
            520,
            350
          ],
          "text": "31. B. Sapoval, M. Rosso, J.F. Gouyet, The fractal nature of a diffusion front and the relation to\npercolation. J. Phys. Lett. 46 (4), 149–156 (1985)",
          "reading_order": 12
        },
        {
          "label": "para",
          "bbox": [
            72,
            350,
            520,
            376
          ],
          "text": "32. W. Sierpinski, Sur une courbe dont tout point est un point de ramification. Comp. Rend. Acad.\nSci. Paris 160 , 302–305 (1915)",
          "reading_order": 13
        },
        {
          "label": "para",
          "bbox": [
            72,
            376,
            520,
            403
          ],
          "text": "33. S. Solomon, G. Weisbuch, L. de Arcangelis, N. Jan, D. Stauffer, Social percolation models.\nPhys. A Stat. Mech. Appl. 277 (1), 239–247 (2000)",
          "reading_order": 14
        },
        {
          "label": "para",
          "bbox": [
            72,
            403,
            520,
            443
          ],
          "text": "34. H.E. Stanley, Cluster shapes at the percolation threshold: and effective cluster dimensionality\nand its connection with critical-point exponents. J. Phys. A Math. General 10 (11), L211–L220\n(1977)",
          "reading_order": 15
        },
        {
          "label": "para",
          "bbox": [
            72,
            446,
            520,
            470
          ],
          "text": "35. H.E. Stanley, Introduction to Phase Transitions and Critical Phenomena , Reprint edn. (Oxford\nUniversity Press USA, New York, 1987).",
          "reading_order": 16
        },
        {
          "label": "para",
          "bbox": [
            72,
            473,
            520,
            510
          ],
          "text": "36. H.E. Stanley, A. Coniglio, Fractal structure of the incipient infinite cluster in percolation, in\nPercolation Structures and Processes , ed. by G. Deutscher, R. Zallen, J. Adler (Adam Hilger,\nBristol, 1983)",
          "reading_order": 17
        },
        {
          "label": "para",
          "bbox": [
            72,
            510,
            520,
            537
          ],
          "text": "37. D. Stauffer, A. Aharony, Introduction To Percolation Theory, 2nd edn. (Wiley Press, Hoboken,\n1992)",
          "reading_order": 18
        },
        {
          "label": "para",
          "bbox": [
            72,
            537,
            520,
            564
          ],
          "text": "38. D. Wilkinson, J.F. Willemsen, Invasion percolation: a new form of percolation theory. J. Numer.\nMath. 16 (14), 3365–3376 (1983)",
          "reading_order": 19
        },
        {
          "label": "para",
          "bbox": [
            72,
            564,
            520,
            591
          ],
          "text": "39. K.G. Wilson, Renormalization group and critical phenomena. I. Renormalization group and the\nkadanoff scaling picture. Phys. Rev. B Condens. Matter Mater. Phys. 4 (9), 3174–3183 (1971)",
          "reading_order": 20
        },
        {
          "label": "para",
          "bbox": [
            72,
            591,
            520,
            618
          ],
          "text": "40. J.G. Zabolitzky, D.J. Bergman, D. Stauffer, Precision calculation of elasticity for percolation.\nJ. Stat. Phys. 44 (1), 211–223 (1986)",
          "reading_order": 21
        }
      ]
    },
    {
      "page_number": 218,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            98,
            125,
            116
          ],
          "text": "Index",
          "reading_order": 0
        },
        {
          "label": "para",
          "bbox": [
            72,
            259,
            154,
            797
          ],
          "text": "Symbols\nD, 68, 79, 80, 90\nD(p), 185\nDB, 122\nDw, 173\nDSAP, 121\nDSC, 120\nDmax, 121\nDmin, 121\nE, 164\nG, 136, 138\nG(ξ, ξ), 148\nG(p, L), 138\nGi, 139\nGi, j, 139\nIi, 139\nIi, j, 139\nL, 30\nLmin, 121\nMSAP, 121\nMmax, 121\nMmin, 121\nNs, 20\nP, 17, 28, 36\nP(p, L), 10, 57, 8\nQ(p), 34\nR(p), 103\nRs, 63, 183\nRSC, 148\nRblob, 148\nS, 39, 56\nS(p, L), 91\nZ, 3, 33\nA, 106\nLambda, 107\nΠ, 8, 12\nΠ(p, L), 94\nβ, 38\nγ, 39, 57, 91\nκ, 164",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            303,
            259,
            457,
            734
          ],
          "text": "r, 172\nmu, 149\nν, 77\nn(s, p), 21\nφ, 1\nσ, 42\nτ, 57, 165\nzeta, 148\nξκ, 166\nξ, 86\nc, 1, 2\ndw, 191\ng, 136\ng(c), 12\ng(r), 29\ng(r; p), 71\ng(s, t), 47\ngs,t, 39, 48\ni,b, 156\nk, 184\nk′\n, 191\nki j, 164\nn(ib), 156\nn(s, p), 17, 19, 21, 28, 29, 40, 48,\n54\np, 2, 3, 5, 36\npε, 3, 4, 34, 59, 97\nr2\ń(t), 178\nr n, 172\ns, 17, 20\nsx, 52\nsξ, 23, 42\nsn(s, p), 17\nt, 47\nt0, 184",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            303,
            758,
            421,
            797
          ],
          "text": "A\nAnomalous diffusion, 185\nAverage cluster radius, 69",
          "reading_order": 3
        },
        {
          "label": "foot",
          "bbox": [
            72,
            806,
            396,
            845
          ],
          "text": "© The Author(s) 2024\nA. Malthe-Sørenssen, Percolation Theory Using Python, Lecture Notes\nin Physics 1029, https://doi.org/10.1007/978-3-031-59900-2",
          "reading_order": 4
        },
        {
          "label": "foot",
          "bbox": [
            501,
            806,
            520,
            816
          ],
          "text": "211",
          "reading_order": 5
        }
      ]
    },
    {
      "page_number": 219,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            62
          ],
          "text": "212",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            492,
            44,
            512,
            58
          ],
          "text": "Inde",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            235,
            107
          ],
          "text": "Average cluster size, 25, 27, 38, 39\n56",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            80,
            107,
            163,
            135
          ],
          "text": "first moment, 27\nverage path, 121",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            161,
            80,
            174
          ],
          "text": "B",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            178,
            143,
            188
          ],
          "text": "Backbone, 122",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            188,
            179,
            214
          ],
          "text": "Bending stiffness, 163\nBethe lattice, 33",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            215,
            164,
            232
          ],
          "text": "Binary mixture, 158",
          "reading_order": 9
        },
        {
          "label": "para",
          "bbox": [
            72,
            232,
            148,
            241
          ],
          "text": "Blob model, 124",
          "reading_order": 10
        },
        {
          "label": "para",
          "bbox": [
            72,
            241,
            143,
            259
          ],
          "text": "Bond lattice, 11",
          "reading_order": 11
        },
        {
          "label": "para",
          "bbox": [
            72,
            259,
            173,
            269
          ],
          "text": "Box counting, 81, 128",
          "reading_order": 12
        },
        {
          "label": "para",
          "bbox": [
            72,
            295,
            80,
            308
          ],
          "text": "C",
          "reading_order": 13
        },
        {
          "label": "para",
          "bbox": [
            72,
            312,
            179,
            323
          ],
          "text": "Capillary pressure, 198",
          "reading_order": 14
        },
        {
          "label": "para",
          "bbox": [
            72,
            323,
            143,
            340
          ],
          "text": "Cayley tree, 33",
          "reading_order": 15
        },
        {
          "label": "para",
          "bbox": [
            72,
            340,
            216,
            349
          ],
          "text": "Characteristic cluster radius, 68",
          "reading_order": 16
        },
        {
          "label": "para",
          "bbox": [
            72,
            349,
            233,
            375
          ],
          "text": "Characteristic cluster size, 23, 42, 5\nCharacteristic length, 29",
          "reading_order": 17
        },
        {
          "label": "para",
          "bbox": [
            72,
            377,
            126,
            388
          ],
          "text": "Cluster, 5, 8",
          "reading_order": 19
        },
        {
          "label": "para",
          "bbox": [
            72,
            392,
            161,
            403
          ],
          "text": "Cluster coloring, 6",
          "reading_order": 20
        },
        {
          "label": "para",
          "bbox": [
            72,
            403,
            161,
            428
          ],
          "text": "Cluster geometry, 6\nCluster number der",
          "reading_order": 21
        },
        {
          "label": "para",
          "bbox": [
            72,
            428,
            278,
            468
          ],
          "text": "_",
          "reading_order": 22
        },
        {
          "label": "para",
          "bbox": [
            72,
            473,
            152,
            483
          ],
          "text": "Cluster radius, 63",
          "reading_order": 23
        },
        {
          "label": "para",
          "bbox": [
            72,
            483,
            143,
            495
          ],
          "text": "Cluster size, 20",
          "reading_order": 24
        },
        {
          "label": "para",
          "bbox": [
            72,
            500,
            192,
            510
          ],
          "text": "Cluster size distribution, 8",
          "reading_order": 25
        },
        {
          "label": "para",
          "bbox": [
            72,
            510,
            179,
            522
          ],
          "text": "Cluster visualization, 6",
          "reading_order": 26
        },
        {
          "label": "para",
          "bbox": [
            72,
            526,
            126,
            537
          ],
          "text": "Colormap, 6",
          "reading_order": 27
        },
        {
          "label": "para",
          "bbox": [
            72,
            537,
            143,
            549
          ],
          "text": "coltomat, 14",
          "reading_order": 28
        },
        {
          "label": "para",
          "bbox": [
            72,
            553,
            144,
            564
          ],
          "text": "Compliance, 16",
          "reading_order": 29
        },
        {
          "label": "para",
          "bbox": [
            72,
            564,
            197,
            578
          ],
          "text": "Conditional probability, 12",
          "reading_order": 30
        },
        {
          "label": "para",
          "bbox": [
            72,
            580,
            199,
            591
          ],
          "text": "Conductance, 136, 138, 146",
          "reading_order": 31
        },
        {
          "label": "para",
          "bbox": [
            72,
            591,
            179,
            602
          ],
          "text": "Conductivity, 136, 138",
          "reading_order": 32
        },
        {
          "label": "para",
          "bbox": [
            72,
            607,
            152,
            618
          ],
          "text": "Configuration, 12",
          "reading_order": 33
        },
        {
          "label": "para",
          "bbox": [
            72,
            618,
            134,
            629
          ],
          "text": "Connected, 8",
          "reading_order": 34
        },
        {
          "label": "para",
          "bbox": [
            72,
            634,
            170,
            645
          ],
          "text": "Connected clusters, 5",
          "reading_order": 35
        },
        {
          "label": "para",
          "bbox": [
            72,
            645,
            143,
            656
          ],
          "text": "Connectivity, 3",
          "reading_order": 36
        },
        {
          "label": "para",
          "bbox": [
            72,
            660,
            197,
            672
          ],
          "text": "Conservation of current, 13",
          "reading_order": 37
        },
        {
          "label": "para",
          "bbox": [
            72,
            672,
            197,
            683
          ],
          "text": "Coordination number, 3, 33",
          "reading_order": 38
        },
        {
          "label": "para",
          "bbox": [
            72,
            687,
            233,
            698
          ],
          "text": "Correlation function, 29,71,72,76",
          "reading_order": 39
        },
        {
          "label": "para",
          "bbox": [
            72,
            698,
            233,
            725
          ],
          "text": "Correlation length, 29, 71, 76, 77,\n86",
          "reading_order": 40
        },
        {
          "label": "para",
          "bbox": [
            72,
            725,
            170,
            736
          ],
          "text": "Cross-over length, 69",
          "reading_order": 41
        },
        {
          "label": "para",
          "bbox": [
            72,
            741,
            161,
            752
          ],
          "text": "Cross-over time, 18",
          "reading_order": 42
        },
        {
          "label": "para",
          "bbox": [
            72,
            752,
            143,
            763
          ],
          "text": "Cubic lattice, 3",
          "reading_order": 43
        },
        {
          "label": "para",
          "bbox": [
            72,
            768,
            125,
            779
          ],
          "text": "Current, 13",
          "reading_order": 44
        },
        {
          "label": "para",
          "bbox": [
            72,
            779,
            125,
            790
          ],
          "text": "Cut-off, 23",
          "reading_order": 45
        },
        {
          "label": "para",
          "bbox": [
            303,
            80,
            313,
            93
          ],
          "text": "D",
          "reading_order": 46
        },
        {
          "label": "para",
          "bbox": [
            303,
            98,
            386,
            107
          ],
          "text": "Dangling ends, 12",
          "reading_order": 47
        },
        {
          "label": "para",
          "bbox": [
            303,
            107,
            379,
            135
          ],
          "text": "Darcy's law, 138\nData-collapse, 2",
          "reading_order": 48
        },
        {
          "label": "para",
          "bbox": [
            303,
            136,
            403,
            152
          ],
          "text": "Data-collapse plot, 89",
          "reading_order": 50
        },
        {
          "label": "para",
          "bbox": [
            303,
            152,
            376,
            162
          ],
          "text": "Degeneracy, 48",
          "reading_order": 51
        },
        {
          "label": "para",
          "bbox": [
            303,
            162,
            511,
            188
          ],
          "text": "Density of the spanning cluster, 10, 28, 29, 34\n146",
          "reading_order": 52
        },
        {
          "label": "para",
          "bbox": [
            303,
            188,
            421,
            214
          ],
          "text": "Deterministic fractal, 126\nDiffusion, 172",
          "reading_order": 53
        },
        {
          "label": "para",
          "bbox": [
            303,
            215,
            404,
            232
          ],
          "text": "Diffusion constant, 19",
          "reading_order": 55
        },
        {
          "label": "para",
          "bbox": [
            303,
            232,
            412,
            243
          ],
          "text": "Diffusion equation, 196",
          "reading_order": 56
        },
        {
          "label": "para",
          "bbox": [
            303,
            243,
            394,
            267
          ],
          "text": "Diffusion front, 196\nDiffusion in homoge",
          "reading_order": 57
        },
        {
          "label": "para",
          "bbox": [
            304,
            269,
            387,
            281
          ],
          "text": "Dimension, 68, 79",
          "reading_order": 59
        },
        {
          "label": "para",
          "bbox": [
            322,
            286,
            358,
            295
          ],
          "text": "mass, 81",
          "reading_order": 60
        },
        {
          "label": "para",
          "bbox": [
            303,
            295,
            450,
            313
          ],
          "text": "Dimension of random walk, 173",
          "reading_order": 61
        },
        {
          "label": "para",
          "bbox": [
            303,
            313,
            367,
            322
          ],
          "text": "Disorder, 195",
          "reading_order": 62
        },
        {
          "label": "para",
          "bbox": [
            304,
            322,
            439,
            334
          ],
          "text": "Distribution of cluster sizes, 2",
          "reading_order": 63
        },
        {
          "label": "para",
          "bbox": [
            303,
            366,
            313,
            376
          ],
          "text": "E",
          "reading_order": 64
        },
        {
          "label": "para",
          "bbox": [
            303,
            376,
            460,
            403
          ],
          "text": "Effective percolation threshold, 94\nEstimator, 9",
          "reading_order": 65
        },
        {
          "label": "para",
          "bbox": [
            303,
            430,
            310,
            442
          ],
          "text": "F",
          "reading_order": 66
        },
        {
          "label": "para",
          "bbox": [
            304,
            447,
            376,
            456
          ],
          "text": "FIND CON, 14",
          "reading_order": 67
        },
        {
          "label": "para",
          "bbox": [
            304,
            456,
            449,
            471
          ],
          "text": "find_displacements, 179",
          "reading_order": 68
        },
        {
          "label": "para",
          "bbox": [
            303,
            473,
            376,
            483
          ],
          "text": "Finite cluster, 8",
          "reading_order": 69
        },
        {
          "label": "para",
          "bbox": [
            304,
            483,
            440,
            497
          ],
          "text": "Finite-dimensional percolation",
          "reading_order": 70
        },
        {
          "label": "para",
          "bbox": [
            322,
            500,
            425,
            511
          ],
          "text": "average cluster size, 56",
          "reading_order": 71
        },
        {
          "label": "para",
          "bbox": [
            319,
            511,
            439,
            535
          ],
          "text": "cluster number density, 54\nscaling ansatz, 54",
          "reading_order": 72
        },
        {
          "label": "para",
          "bbox": [
            319,
            537,
            412,
            549
          ],
          "text": "scaling function, 54",
          "reading_order": 74
        },
        {
          "label": "para",
          "bbox": [
            303,
            553,
            376,
            564
          ],
          "text": "Finite lattice, 87",
          "reading_order": 75
        },
        {
          "label": "para",
          "bbox": [
            304,
            564,
            439,
            576
          ],
          "text": "Finite size scaling, 28, 30, 86",
          "reading_order": 76
        },
        {
          "label": "para",
          "bbox": [
            322,
            580,
            421,
            591
          ],
          "text": "average cluster size, 9",
          "reading_order": 77
        },
        {
          "label": "para",
          "bbox": [
            322,
            591,
            359,
            602
          ],
          "text": "mass, 90",
          "reading_order": 78
        },
        {
          "label": "para",
          "bbox": [
            322,
            607,
            493,
            618
          ],
          "text": "moments of cluster number density, 91",
          "reading_order": 79
        },
        {
          "label": "para",
          "bbox": [
            321,
            618,
            376,
            631
          ],
          "text": "$P(p,L)$, 87",
          "reading_order": 80
        },
        {
          "label": "para",
          "bbox": [
            303,
            634,
            450,
            645
          ],
          "text": "Finite size scaling ansatz, 86 , 88",
          "reading_order": 81
        },
        {
          "label": "para",
          "bbox": [
            304,
            645,
            367,
            658
          ],
          "text": "Fixpoint, 104",
          "reading_order": 82
        },
        {
          "label": "para",
          "bbox": [
            322,
            660,
            377,
            672
          ],
          "text": "marginal, 10",
          "reading_order": 83
        },
        {
          "label": "para",
          "bbox": [
            322,
            672,
            385,
            683
          ],
          "text": "non-trivial, 10",
          "reading_order": 84
        },
        {
          "label": "para",
          "bbox": [
            319,
            687,
            368,
            698
          ],
          "text": "stable, 105",
          "reading_order": 85
        },
        {
          "label": "para",
          "bbox": [
            322,
            698,
            385,
            710
          ],
          "text": "rivial, 104, 10",
          "reading_order": 86
        },
        {
          "label": "para",
          "bbox": [
            322,
            714,
            403,
            725
          ],
          "text": "instable, 105, 106",
          "reading_order": 87
        },
        {
          "label": "para",
          "bbox": [
            304,
            725,
            349,
            736
          ],
          "text": "Flow, 136",
          "reading_order": 88
        },
        {
          "label": "para",
          "bbox": [
            303,
            741,
            349,
            752
          ],
          "text": "Flux, 137",
          "reading_order": 89
        },
        {
          "label": "para",
          "bbox": [
            304,
            752,
            385,
            763
          ],
          "text": "Fractal, 68, 80, 10",
          "reading_order": 90
        },
        {
          "label": "para",
          "bbox": [
            303,
            768,
            448,
            779
          ],
          "text": "Fractal dimension, 68 , 79 , 80 , 90",
          "reading_order": 91
        },
        {
          "label": "para",
          "bbox": [
            304,
            779,
            406,
            790
          ],
          "text": "Fractional current, 155",
          "reading_order": 92
        }
      ]
    },
    {
      "page_number": 220,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            98,
            58
          ],
          "text": "Index",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            501,
            44,
            520,
            62
          ],
          "text": "213",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            80,
            93
          ],
          "text": "G",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            98,
            98,
            109
          ],
          "text": "7,28",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            109,
            215,
            125
          ],
          "text": "Gravity destabilization, 203, 20",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            151,
            81,
            161
          ],
          "text": "и",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            161,
            136,
            189
          ],
          "text": "Histogram, 51\nHyper-scaling",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            215,
            80,
            232
          ],
          "text": "I",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            72,
            232,
            197,
            243
          ],
          "text": "Incompressible fluid, 203",
          "reading_order": 9
        },
        {
          "label": "para",
          "bbox": [
            72,
            243,
            233,
            484
          ],
          "text": "Inf-dimensional percolation\naverage cluster size, 38\n$\\beta$ , 38\ncharacteristic cluster size, 42\ncluster number density, 40\ndensity of spanning cluster, 34\n$\\gamma$ , 39\n$n(s,\\,p)$ , 40\noccupation probability, 34\n$p$ , 34 , 36\n$p_c$ , 39\npercolation threshold, 36\n$S$ , 38\nscaling ansatz, 45 , 55\nscaling relations, 46\n$\\sigma$ , 42\nspanning cluster, 34\n$s_{\\xi}$ , 42",
          "reading_order": 10
        },
        {
          "label": "para",
          "bbox": [
            72,
            484,
            216,
            511
          ],
          "text": "Interfacial surface tension, 198\nInvasion percolation, 198",
          "reading_order": 11
        },
        {
          "label": "para",
          "bbox": [
            72,
            511,
            188,
            537
          ],
          "text": "invperc, 201\ninvpercgrad, 205",
          "reading_order": 12
        },
        {
          "label": "para",
          "bbox": [
            72,
            537,
            164,
            549
          ],
          "text": "Iterative fractal, 126",
          "reading_order": 13
        },
        {
          "label": "para",
          "bbox": [
            72,
            580,
            80,
            591
          ],
          "text": "L",
          "reading_order": 14
        },
        {
          "label": "para",
          "bbox": [
            72,
            591,
            143,
            602
          ],
          "text": "Lacunarity, 128",
          "reading_order": 15
        },
        {
          "label": "para",
          "bbox": [
            72,
            607,
            179,
            618
          ],
          "text": "Logarithmic binning, 51",
          "reading_order": 16
        },
        {
          "label": "para",
          "bbox": [
            72,
            645,
            82,
            656
          ],
          "text": "M",
          "reading_order": 17
        },
        {
          "label": "para",
          "bbox": [
            72,
            660,
            207,
            672
          ],
          "text": "Mandelbrot-Given curve, 126",
          "reading_order": 18
        },
        {
          "label": "para",
          "bbox": [
            72,
            672,
            172,
            685
          ],
          "text": "Marging fixpoint, 107",
          "reading_order": 19
        },
        {
          "label": "para",
          "bbox": [
            72,
            688,
            107,
            698
          ],
          "text": "Mass, &",
          "reading_order": 20
        },
        {
          "label": "para",
          "bbox": [
            72,
            698,
            197,
            712
          ],
          "text": "Mass of spanning cluster, 8",
          "reading_order": 21
        },
        {
          "label": "para",
          "bbox": [
            72,
            715,
            107,
            725
          ],
          "text": "Matrix,",
          "reading_order": 22
        },
        {
          "label": "para",
          "bbox": [
            72,
            725,
            161,
            738
          ],
          "text": "Maximum path, 12",
          "reading_order": 23
        },
        {
          "label": "para",
          "bbox": [
            72,
            741,
            161,
            752
          ],
          "text": "Minimal path, 121",
          "reading_order": 24
        },
        {
          "label": "para",
          "bbox": [
            72,
            752,
            126,
            763
          ],
          "text": "Moments, 9",
          "reading_order": 25
        },
        {
          "label": "para",
          "bbox": [
            72,
            768,
            215,
            779
          ],
          "text": "Moments of a distribution, 129",
          "reading_order": 26
        },
        {
          "label": "para",
          "bbox": [
            72,
            779,
            251,
            790
          ],
          "text": "Moments of cluster number density, 91",
          "reading_order": 27
        },
        {
          "label": "para",
          "bbox": [
            303,
            80,
            385,
            98
          ],
          "text": "Multifractal, 157",
          "reading_order": 28
        },
        {
          "label": "para",
          "bbox": [
            303,
            98,
            376,
            109
          ],
          "text": "Multiplicity, 12",
          "reading_order": 29
        },
        {
          "label": "para",
          "bbox": [
            303,
            134,
            313,
            147
          ],
          "text": "N",
          "reading_order": 30
        },
        {
          "label": "para",
          "bbox": [
            303,
            151,
            385,
            162
          ],
          "text": "Nearest neighbor,",
          "reading_order": 31
        },
        {
          "label": "para",
          "bbox": [
            303,
            162,
            450,
            187
          ],
          "text": "Nearest neighbor connectivity, 3\nNext-nearest neighbor, 3, 23",
          "reading_order": 32
        },
        {
          "label": "para",
          "bbox": [
            303,
            189,
            475,
            214
          ],
          "text": "Next-nearest neighbor connectivity, 3\nNon-wetting fluid, 198",
          "reading_order": 34
        },
        {
          "label": "para",
          "bbox": [
            303,
            216,
            385,
            232
          ],
          "text": "Normalization, 21",
          "reading_order": 36
        },
        {
          "label": "para",
          "bbox": [
            303,
            232,
            431,
            243
          ],
          "text": "Normalization of $n(s,\\,p)$ , 19",
          "reading_order": 37
        },
        {
          "label": "para",
          "bbox": [
            304,
            243,
            359,
            267
          ],
          "text": "v, 29, 69, 76\nNumber of r",
          "reading_order": 38
        },
        {
          "label": "para",
          "bbox": [
            303,
            295,
            313,
            308
          ],
          "text": "o",
          "reading_order": 40
        },
        {
          "label": "para",
          "bbox": [
            303,
            312,
            439,
            323
          ],
          "text": "Occupation probability, 3, 34",
          "reading_order": 41
        },
        {
          "label": "para",
          "bbox": [
            303,
            323,
            358,
            348
          ],
          "text": "Occupied, 2\nOhm's law.",
          "reading_order": 42
        },
        {
          "label": "para",
          "bbox": [
            303,
            349,
            452,
            455
          ],
          "text": "One-dimensional percolation, 17\naverage cluster size, 25\ncharacteristic cluster size, 23\ncharacteristic length, 29\ncluster number density, 17\ncorrelation function, 29 , 72\ncorrelation length, 29\nfinite size scaling, 30",
          "reading_order": 44
        },
        {
          "label": "para",
          "bbox": [
            322,
            457,
            358,
            470
          ],
          "text": "$\\mathrm{z}(r), 29$",
          "reading_order": 46
        },
        {
          "label": "para",
          "bbox": [
            313,
            473,
            376,
            484
          ],
          "text": "g(r; p), 72",
          "reading_order": 47
        },
        {
          "label": "para",
          "bbox": [
            322,
            484,
            343,
            495
          ],
          "text": "28",
          "reading_order": 48
        },
        {
          "label": "para",
          "bbox": [
            322,
            500,
            342,
            510
          ],
          "text": "29",
          "reading_order": 49
        },
        {
          "label": "para",
          "bbox": [
            322,
            510,
            432,
            535
          ],
          "text": "_",
          "reading_order": 50
        },
        {
          "label": "para",
          "bbox": [
            321,
            537,
            349,
            549
          ],
          "text": "R. 64",
          "reading_order": 52
        },
        {
          "label": "para",
          "bbox": [
            313,
            553,
            421,
            564
          ],
          "text": "scaling ansatz, 24, 55",
          "reading_order": 53
        },
        {
          "label": "para",
          "bbox": [
            319,
            564,
            340,
            576
          ],
          "text": "$\\sigma,2$",
          "reading_order": 54
        },
        {
          "label": "para",
          "bbox": [
            319,
            580,
            404,
            591
          ],
          "text": "spanning cluster, 2",
          "reading_order": 55
        },
        {
          "label": "para",
          "bbox": [
            313,
            591,
            349,
            604
          ],
          "text": "$s_{xi},23$",
          "reading_order": 56
        },
        {
          "label": "para",
          "bbox": [
            303,
            634,
            313,
            645
          ],
          "text": "P",
          "reading_order": 57
        },
        {
          "label": "para",
          "bbox": [
            303,
            645,
            403,
            656
          ],
          "text": "perccorrfunc, 72",
          "reading_order": 58
        },
        {
          "label": "para",
          "bbox": [
            303,
            660,
            403,
            672
          ],
          "text": "Percolating cluster, 7",
          "reading_order": 59
        },
        {
          "label": "para",
          "bbox": [
            304,
            672,
            421,
            685
          ],
          "text": "Percolation probability, 8",
          "reading_order": 60
        },
        {
          "label": "para",
          "bbox": [
            303,
            687,
            475,
            698
          ],
          "text": "Percolation threshold, 3, 4, 59, 94, 97",
          "reading_order": 61
        },
        {
          "label": "para",
          "bbox": [
            303,
            698,
            403,
            710
          ],
          "text": "percwalk, 177, 181",
          "reading_order": 62
        },
        {
          "label": "para",
          "bbox": [
            303,
            714,
            457,
            725
          ],
          "text": "Periodic boundary conditions, 186",
          "reading_order": 63
        },
        {
          "label": "para",
          "bbox": [
            304,
            725,
            385,
            736
          ],
          "text": "Permeability, 137",
          "reading_order": 64
        },
        {
          "label": "para",
          "bbox": [
            304,
            742,
            331,
            752
          ],
          "text": "Π, 17",
          "reading_order": 65
        },
        {
          "label": "para",
          "bbox": [
            304,
            752,
            331,
            763
          ],
          "text": "Pore,",
          "reading_order": 66
        },
        {
          "label": "para",
          "bbox": [
            303,
            768,
            362,
            779
          ],
          "text": "Porosity, 2, 5",
          "reading_order": 67
        },
        {
          "label": "para",
          "bbox": [
            304,
            779,
            376,
            790
          ],
          "text": "Porous media, 1",
          "reading_order": 68
        }
      ]
    },
    {
      "page_number": 221,
      "elements": [
        {
          "label": "header",
          "bbox": [
            72,
            44,
            89,
            58
          ],
          "text": "214",
          "reading_order": 0
        },
        {
          "label": "header",
          "bbox": [
            492,
            44,
            513,
            62
          ],
          "text": "Inde",
          "reading_order": 1
        },
        {
          "label": "para",
          "bbox": [
            72,
            80,
            137,
            98
          ],
          "text": "Power-law, 23",
          "reading_order": 2
        },
        {
          "label": "para",
          "bbox": [
            72,
            98,
            161,
            109
          ],
          "text": "Pressure drop, 137",
          "reading_order": 3
        },
        {
          "label": "para",
          "bbox": [
            72,
            134,
            80,
            152
          ],
          "text": "R",
          "reading_order": 4
        },
        {
          "label": "para",
          "bbox": [
            72,
            152,
            190,
            162
          ],
          "text": "Radius of gyration, 63, 65",
          "reading_order": 5
        },
        {
          "label": "para",
          "bbox": [
            72,
            162,
            144,
            179
          ],
          "text": "Random media,",
          "reading_order": 6
        },
        {
          "label": "para",
          "bbox": [
            72,
            179,
            197,
            189
          ],
          "text": "Random porous medium, 2",
          "reading_order": 7
        },
        {
          "label": "para",
          "bbox": [
            72,
            189,
            215,
            214
          ],
          "text": "Random resistor networks, 136\nRandom walk, 171",
          "reading_order": 8
        },
        {
          "label": "para",
          "bbox": [
            72,
            214,
            161,
            227
          ],
          "text": "dimension, 173",
          "reading_order": 9
        },
        {
          "label": "para",
          "bbox": [
            72,
            232,
            174,
            241
          ],
          "text": "Real conductivity, 158",
          "reading_order": 10
        },
        {
          "label": "para",
          "bbox": [
            72,
            241,
            170,
            269
          ],
          "text": "Renormalization, 102\nRenormalization map",
          "reading_order": 11
        },
        {
          "label": "para",
          "bbox": [
            72,
            270,
            208,
            294
          ],
          "text": "Rigidity percolation, 163 , 165\nRigidity threshold, 165",
          "reading_order": 13
        },
        {
          "label": "para",
          "bbox": [
            72,
            296,
            101,
            313
          ],
          "text": "Rs, 65",
          "reading_order": 15
        },
        {
          "label": "para",
          "bbox": [
            72,
            313,
            107,
            322
          ],
          "text": "$R_{v},68$",
          "reading_order": 16
        },
        {
          "label": "sec",
          "bbox": [
            72,
            349,
            80,
            361
          ],
          "text": "s",
          "reading_order": 17
        },
        {
          "label": "para",
          "bbox": [
            72,
            366,
            98,
            376
          ],
          "text": "S. 27",
          "reading_order": 18
        },
        {
          "label": "para",
          "bbox": [
            72,
            376,
            215,
            401
          ],
          "text": "Saturated porous medium, 198\nScaling ansatz, 42, 45, 54, 89",
          "reading_order": 19
        },
        {
          "label": "para",
          "bbox": [
            72,
            403,
            163,
            430
          ],
          "text": "Scaling argument, 6\nScaling exponents",
          "reading_order": 21
        },
        {
          "label": "para",
          "bbox": [
            88,
            431,
            144,
            442
          ],
          "text": "bounds, 149",
          "reading_order": 23
        },
        {
          "label": "para",
          "bbox": [
            72,
            446,
            162,
            457
          ],
          "text": "Scaling function, 54",
          "reading_order": 24
        },
        {
          "label": "para",
          "bbox": [
            72,
            457,
            198,
            468
          ],
          "text": "Scaling relations, 46, 56, 57",
          "reading_order": 25
        },
        {
          "label": "para",
          "bbox": [
            72,
            473,
            143,
            483
          ],
          "text": "Self-affine, 198",
          "reading_order": 26
        },
        {
          "label": "para",
          "bbox": [
            72,
            483,
            206,
            509
          ],
          "text": "Self-avoiding path (SAP), 12\nSelf-similar, 101, 198",
          "reading_order": 27
        },
        {
          "label": "para",
          "bbox": [
            72,
            510,
            179,
            522
          ],
          "text": "Self-similar scaling, 80",
          "reading_order": 29
        },
        {
          "label": "para",
          "bbox": [
            72,
            526,
            161,
            537
          ],
          "text": "Shear modulus, 164",
          "reading_order": 30
        },
        {
          "label": "para",
          "bbox": [
            72,
            537,
            125,
            564
          ],
          "text": "Shuffling, 6\nSiepinski s",
          "reading_order": 31
        },
        {
          "label": "para",
          "bbox": [
            72,
            565,
            98,
            576
          ],
          "text": "σ,23",
          "reading_order": 33
        },
        {
          "label": "para",
          "bbox": [
            72,
            580,
            170,
            591
          ],
          "text": "Singly connected, 126",
          "reading_order": 34
        },
        {
          "label": "para",
          "bbox": [
            72,
            591,
            197,
            602
          ],
          "text": "Singly connected site, 119",
          "reading_order": 35
        },
        {
          "label": "para",
          "bbox": [
            72,
            607,
            101,
            618
          ],
          "text": "Site, 2",
          "reading_order": 36
        },
        {
          "label": "para",
          "bbox": [
            72,
            618,
            143,
            629
          ],
          "text": "Site lattice, 109",
          "reading_order": 37
        },
        {
          "label": "para",
          "bbox": [
            72,
            635,
            163,
            645
          ],
          "text": "sitetobond, 140",
          "reading_order": 38
        },
        {
          "label": "para",
          "bbox": [
            303,
            80,
            385,
            98
          ],
          "text": "Small systems, 12",
          "reading_order": 39
        },
        {
          "label": "para",
          "bbox": [
            303,
            98,
            376,
            107
          ],
          "text": "Solid fraction, 2",
          "reading_order": 40
        },
        {
          "label": "para",
          "bbox": [
            303,
            107,
            358,
            135
          ],
          "text": "Spanning, 5\nSpanning cl",
          "reading_order": 41
        },
        {
          "label": "para",
          "bbox": [
            303,
            135,
            478,
            162
          ],
          "text": "_",
          "reading_order": 42
        },
        {
          "label": "para",
          "bbox": [
            303,
            163,
            387,
            179
          ],
          "text": "Stable fixpoint, 10",
          "reading_order": 44
        },
        {
          "label": "para",
          "bbox": [
            303,
            179,
            358,
            188
          ],
          "text": "Stress, 164",
          "reading_order": 45
        },
        {
          "label": "para",
          "bbox": [
            303,
            188,
            413,
            216
          ],
          "text": "Stretching stiffness, 163\nSuperconductor network",
          "reading_order": 46
        },
        {
          "label": "para",
          "bbox": [
            303,
            217,
            396,
            232
          ],
          "text": "Surface tension, 198",
          "reading_order": 48
        },
        {
          "label": "para",
          "bbox": [
            304,
            268,
            326,
            294
          ],
          "text": "24\nTavle",
          "reading_order": 50
        },
        {
          "label": "para",
          "bbox": [
            304,
            296,
            421,
            321
          ],
          "text": "Thermodynamic limit, 86\nTriangular lattice, 111",
          "reading_order": 52
        },
        {
          "label": "sec",
          "bbox": [
            303,
            349,
            313,
            361
          ],
          "text": "u",
          "reading_order": 54
        },
        {
          "label": "para",
          "bbox": [
            304,
            366,
            403,
            376
          ],
          "text": "Uncorrelated media, 1",
          "reading_order": 55
        },
        {
          "label": "para",
          "bbox": [
            304,
            376,
            394,
            388
          ],
          "text": "Unifractal, 129, 157",
          "reading_order": 56
        },
        {
          "label": "para",
          "bbox": [
            304,
            392,
            403,
            403
          ],
          "text": "Universal exponent, 6",
          "reading_order": 57
        },
        {
          "label": "para",
          "bbox": [
            304,
            403,
            404,
            430
          ],
          "text": "Universal number, 69\nUnstable fixpoint, 105",
          "reading_order": 58
        },
        {
          "label": "sec",
          "bbox": [
            303,
            456,
            313,
            468
          ],
          "text": "V",
          "reading_order": 60
        },
        {
          "label": "para",
          "bbox": [
            304,
            473,
            367,
            484
          ],
          "text": "Viscosity, 137",
          "reading_order": 61
        },
        {
          "label": "sec",
          "bbox": [
            303,
            510,
            314,
            522
          ],
          "text": "w",
          "reading_order": 62
        },
        {
          "label": "para",
          "bbox": [
            304,
            526,
            439,
            537
          ],
          "text": "Width of diffusion front, 197",
          "reading_order": 63
        },
        {
          "label": "sec",
          "bbox": [
            303,
            564,
            313,
            576
          ],
          "text": "X",
          "reading_order": 64
        },
        {
          "label": "para",
          "bbox": [
            303,
            580,
            358,
            591
          ],
          "text": "$\\xi$ , 29, 69, 71",
          "reading_order": 65
        },
        {
          "label": "sec",
          "bbox": [
            303,
            618,
            313,
            629
          ],
          "text": "Y",
          "reading_order": 66
        },
        {
          "label": "para",
          "bbox": [
            304,
            634,
            403,
            645
          ],
          "text": "Young’s modulus, 164",
          "reading_order": 67
        }
      ]
    }
  ]
}